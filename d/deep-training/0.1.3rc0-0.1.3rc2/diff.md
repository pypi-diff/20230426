# Comparing `tmp/deep_training-0.1.3rc0-py3-none-any.whl.zip` & `tmp/deep_training-0.1.3rc2-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,24 +1,25 @@
-Zip file size: 267297 bytes, number of entries: 155
+Zip file size: 280028 bytes, number of entries: 159
 -rw-rw-rw-  2.0 fat       47 b- defN 23-Mar-22 07:43 deep_training/__init__.py
--rw-rw-rw-  2.0 fat      900 b- defN 23-Apr-23 01:18 deep_training/setup.py
+-rw-rw-rw-  2.0 fat      900 b- defN 23-Apr-26 05:05 deep_training/setup.py
 -rw-rw-rw-  2.0 fat       55 b- defN 22-Dec-09 05:30 deep_training/cv/__init__.py
 -rw-rw-rw-  2.0 fat      195 b- defN 23-Jan-29 01:07 deep_training/data_helper/__init__.py
 -rw-rw-rw-  2.0 fat    29088 b- defN 23-Apr-06 04:11 deep_training/data_helper/data_helper.py
 -rw-rw-rw-  2.0 fat     4926 b- defN 23-Feb-17 02:41 deep_training/data_helper/data_module.py
 -rw-rw-rw-  2.0 fat     1383 b- defN 23-Jan-29 01:07 deep_training/data_helper/data_writer.py
 -rw-rw-rw-  2.0 fat    12557 b- defN 23-Apr-19 09:13 deep_training/data_helper/training_args.py
 -rw-rw-rw-  2.0 fat       70 b- defN 22-Dec-13 03:17 deep_training/nlp/__init__.py
 -rw-rw-rw-  2.0 fat       56 b- defN 22-Nov-10 08:28 deep_training/nlp/layers/__init__.py
 -rw-rw-rw-  2.0 fat      241 b- defN 23-Mar-13 05:48 deep_training/nlp/layers/activate.py
 -rw-rw-rw-  2.0 fat    13271 b- defN 22-Nov-14 00:17 deep_training/nlp/layers/crf.py
 -rw-rw-rw-  2.0 fat     4653 b- defN 22-Dec-12 00:12 deep_training/nlp/layers/handshakingkernel.py
 -rw-rw-rw-  2.0 fat      435 b- defN 22-Dec-02 00:22 deep_training/nlp/layers/mask.py
 -rw-rw-rw-  2.0 fat     1319 b- defN 22-Dec-12 00:12 deep_training/nlp/layers/mhslayer.py
 -rw-rw-rw-  2.0 fat     5911 b- defN 22-Dec-08 00:08 deep_training/nlp/layers/norm.py
+-rw-rw-rw-  2.0 fat     1390 b- defN 23-Apr-23 07:16 deep_training/nlp/layers/ppo.py
 -rw-rw-rw-  2.0 fat     1220 b- defN 22-Jul-21 00:57 deep_training/nlp/layers/prefix_encoder.py
 -rw-rw-rw-  2.0 fat     7259 b- defN 22-Dec-14 02:36 deep_training/nlp/layers/seq_pointer.py
 -rw-rw-rw-  2.0 fat     3550 b- defN 22-Dec-15 00:57 deep_training/nlp/layers/w2ner.py
 -rw-rw-rw-  2.0 fat       72 b- defN 23-Apr-11 00:30 deep_training/nlp/layers/lora_v1/__init__.py
 -rw-rw-rw-  2.0 fat    15095 b- defN 23-Apr-11 00:30 deep_training/nlp/layers/lora_v1/layers.py
 -rw-rw-rw-  2.0 fat     1819 b- defN 23-Apr-11 00:30 deep_training/nlp/layers/lora_v1/utils.py
 -rw-rw-rw-  2.0 fat       72 b- defN 23-Apr-11 00:30 deep_training/nlp/layers/lora_v2/__init__.py
@@ -62,39 +63,39 @@
 -rw-rw-rw-  2.0 fat      562 b- defN 22-Nov-25 06:44 deep_training/nlp/losses/loss_splinker.py
 -rw-rw-rw-  2.0 fat    10822 b- defN 23-Jan-09 09:00 deep_training/nlp/losses/loss_spn4re.py
 -rw-rw-rw-  2.0 fat     5644 b- defN 22-Dec-12 00:12 deep_training/nlp/losses/loss_tplinker.py
 -rw-rw-rw-  2.0 fat     2466 b- defN 23-Jan-18 09:12 deep_training/nlp/losses/utils.py
 -rw-rw-rw-  2.0 fat       71 b- defN 22-Dec-13 03:17 deep_training/nlp/metrics/__init__.py
 -rw-rw-rw-  2.0 fat      655 b- defN 22-Dec-02 00:22 deep_training/nlp/metrics/pointer.py
 -rw-rw-rw-  2.0 fat       58 b- defN 22-Nov-22 08:00 deep_training/nlp/models/__init__.py
--rw-rw-rw-  2.0 fat     6811 b- defN 22-Dec-23 00:05 deep_training/nlp/models/casrel.py
--rw-rw-rw-  2.0 fat     5078 b- defN 22-Dec-22 08:21 deep_training/nlp/models/crf_cascad.py
--rw-rw-rw-  2.0 fat     1573 b- defN 22-Dec-22 08:21 deep_training/nlp/models/crf_model.py
--rw-rw-rw-  2.0 fat    12970 b- defN 23-Jan-18 06:52 deep_training/nlp/models/diffcse.py
--rw-rw-rw-  2.0 fat     5388 b- defN 23-Mar-30 00:20 deep_training/nlp/models/esimcse.py
--rw-rw-rw-  2.0 fat     4194 b- defN 23-Mar-09 01:21 deep_training/nlp/models/gec_model.py
--rw-rw-rw-  2.0 fat    10824 b- defN 22-Dec-26 02:03 deep_training/nlp/models/gplinker.py
--rw-rw-rw-  2.0 fat     3799 b- defN 23-Jan-17 08:25 deep_training/nlp/models/infonce.py
--rw-rw-rw-  2.0 fat     2444 b- defN 22-Dec-22 08:21 deep_training/nlp/models/mhs_ner.py
--rw-rw-rw-  2.0 fat     5976 b- defN 22-Dec-22 08:21 deep_training/nlp/models/mhslinker.py
--rw-rw-rw-  2.0 fat     4646 b- defN 23-Jan-18 06:52 deep_training/nlp/models/onerel_model.py
--rw-rw-rw-  2.0 fat     2735 b- defN 23-Apr-03 00:32 deep_training/nlp/models/pointer.py
--rw-rw-rw-  2.0 fat    13317 b- defN 23-Apr-03 00:32 deep_training/nlp/models/prefixtuning.py
--rw-rw-rw-  2.0 fat    15900 b- defN 23-Jan-18 06:52 deep_training/nlp/models/prgc_model.py
--rw-rw-rw-  2.0 fat    16100 b- defN 23-Jan-29 01:07 deep_training/nlp/models/promptbert_cse.py
--rw-rw-rw-  2.0 fat     5134 b- defN 23-Jan-18 06:52 deep_training/nlp/models/pure_model.py
--rw-rw-rw-  2.0 fat     3934 b- defN 23-Jan-16 07:30 deep_training/nlp/models/simcse.py
--rw-rw-rw-  2.0 fat     6007 b- defN 23-Apr-03 00:32 deep_training/nlp/models/span_ner.py
--rw-rw-rw-  2.0 fat    14439 b- defN 23-Jan-18 06:52 deep_training/nlp/models/spn4re.py
--rw-rw-rw-  2.0 fat    11368 b- defN 22-Dec-22 08:17 deep_training/nlp/models/tplinker.py
--rw-rw-rw-  2.0 fat     8142 b- defN 22-Dec-22 08:17 deep_training/nlp/models/tplinkerplus.py
--rw-rw-rw-  2.0 fat     6609 b- defN 23-Apr-11 06:40 deep_training/nlp/models/transformer.py
--rw-rw-rw-  2.0 fat    25490 b- defN 23-Apr-11 06:55 deep_training/nlp/models/transformer_base.py
--rw-rw-rw-  2.0 fat     7953 b- defN 23-Jan-15 03:09 deep_training/nlp/models/tsdae_model.py
--rw-rw-rw-  2.0 fat     9025 b- defN 23-Apr-03 00:32 deep_training/nlp/models/w2ner.py
+-rw-rw-rw-  2.0 fat     6826 b- defN 23-Apr-25 03:34 deep_training/nlp/models/casrel.py
+-rw-rw-rw-  2.0 fat     5093 b- defN 23-Apr-25 03:34 deep_training/nlp/models/crf_cascad.py
+-rw-rw-rw-  2.0 fat     1588 b- defN 23-Apr-25 03:34 deep_training/nlp/models/crf_model.py
+-rw-rw-rw-  2.0 fat    12985 b- defN 23-Apr-25 03:34 deep_training/nlp/models/diffcse.py
+-rw-rw-rw-  2.0 fat     5403 b- defN 23-Apr-25 03:34 deep_training/nlp/models/esimcse.py
+-rw-rw-rw-  2.0 fat     4209 b- defN 23-Apr-25 03:34 deep_training/nlp/models/gec_model.py
+-rw-rw-rw-  2.0 fat    10854 b- defN 23-Apr-25 03:34 deep_training/nlp/models/gplinker.py
+-rw-rw-rw-  2.0 fat     3814 b- defN 23-Apr-25 03:34 deep_training/nlp/models/infonce.py
+-rw-rw-rw-  2.0 fat     2459 b- defN 23-Apr-25 03:34 deep_training/nlp/models/mhs_ner.py
+-rw-rw-rw-  2.0 fat     5991 b- defN 23-Apr-25 03:34 deep_training/nlp/models/mhslinker.py
+-rw-rw-rw-  2.0 fat     4661 b- defN 23-Apr-25 03:34 deep_training/nlp/models/onerel_model.py
+-rw-rw-rw-  2.0 fat     2750 b- defN 23-Apr-25 03:34 deep_training/nlp/models/pointer.py
+-rw-rw-rw-  2.0 fat    13392 b- defN 23-Apr-25 03:34 deep_training/nlp/models/prefixtuning.py
+-rw-rw-rw-  2.0 fat    15915 b- defN 23-Apr-25 03:34 deep_training/nlp/models/prgc_model.py
+-rw-rw-rw-  2.0 fat    16115 b- defN 23-Apr-25 03:34 deep_training/nlp/models/promptbert_cse.py
+-rw-rw-rw-  2.0 fat     5149 b- defN 23-Apr-25 03:34 deep_training/nlp/models/pure_model.py
+-rw-rw-rw-  2.0 fat     3949 b- defN 23-Apr-25 03:34 deep_training/nlp/models/simcse.py
+-rw-rw-rw-  2.0 fat     6022 b- defN 23-Apr-25 03:34 deep_training/nlp/models/span_ner.py
+-rw-rw-rw-  2.0 fat    14454 b- defN 23-Apr-25 03:34 deep_training/nlp/models/spn4re.py
+-rw-rw-rw-  2.0 fat    11383 b- defN 23-Apr-25 03:34 deep_training/nlp/models/tplinker.py
+-rw-rw-rw-  2.0 fat     8157 b- defN 23-Apr-25 03:34 deep_training/nlp/models/tplinkerplus.py
+-rw-rw-rw-  2.0 fat     6624 b- defN 23-Apr-25 03:34 deep_training/nlp/models/transformer.py
+-rw-rw-rw-  2.0 fat    25966 b- defN 23-Apr-25 03:33 deep_training/nlp/models/transformer_base.py
+-rw-rw-rw-  2.0 fat     7968 b- defN 23-Apr-25 03:34 deep_training/nlp/models/tsdae_model.py
+-rw-rw-rw-  2.0 fat     9040 b- defN 23-Apr-25 03:34 deep_training/nlp/models/w2ner.py
 -rw-rw-rw-  2.0 fat    16500 b- defN 23-Mar-27 00:33 deep_training/nlp/models/LLaMA/__init__.py
 -rw-rw-rw-  2.0 fat     5087 b- defN 23-Mar-13 01:04 deep_training/nlp/models/LLaMA/configuration.py
 -rw-rw-rw-  2.0 fat    19183 b- defN 23-Mar-27 00:33 deep_training/nlp/models/LLaMA_parallel/__init__.py
 -rw-rw-rw-  2.0 fat     5087 b- defN 23-Mar-10 00:30 deep_training/nlp/models/LLaMA_parallel/configuration.py
 -rw-rw-rw-  2.0 fat    31627 b- defN 23-Mar-13 06:15 deep_training/nlp/models/PaLM/__init__.py
 -rw-rw-rw-  2.0 fat     5890 b- defN 23-Mar-13 06:15 deep_training/nlp/models/PaLM/configuration.py
 -rw-rw-rw-  2.0 fat    60508 b- defN 23-Apr-19 01:01 deep_training/nlp/models/chatglm/__init__.py
@@ -112,32 +113,35 @@
 -rw-rw-rw-  2.0 fat    11281 b- defN 23-Apr-11 06:27 deep_training/nlp/models/lora/v2/configuration.py
 -rw-rw-rw-  2.0 fat    11745 b- defN 23-Apr-18 01:24 deep_training/nlp/models/lora/v2/lora_model.py
 -rw-rw-rw-  2.0 fat    10265 b- defN 23-Apr-11 01:58 deep_training/nlp/models/lora/v2/lora_wrapper.py
 -rw-rw-rw-  2.0 fat     4889 b- defN 23-Apr-11 00:30 deep_training/nlp/models/lora/v2/save_and_load.py
 -rw-rw-rw-  2.0 fat      467 b- defN 23-Apr-21 04:29 deep_training/nlp/models/moss/__init__.py
 -rw-rw-rw-  2.0 fat     5097 b- defN 23-Apr-23 01:11 deep_training/nlp/models/moss/configuration_moss.py
 -rw-rw-rw-  2.0 fat     6735 b- defN 23-Apr-23 01:05 deep_training/nlp/models/moss/custom_autotune.py
--rw-rw-rw-  2.0 fat    30926 b- defN 23-Apr-23 01:04 deep_training/nlp/models/moss/modeling_moss.py
+-rw-rw-rw-  2.0 fat    31079 b- defN 23-Apr-23 02:08 deep_training/nlp/models/moss/modeling_moss.py
 -rw-rw-rw-  2.0 fat    18866 b- defN 23-Apr-23 01:02 deep_training/nlp/models/moss/quantization.py
--rw-rw-rw-  2.0 fat    14782 b- defN 23-Apr-21 04:15 deep_training/nlp/models/moss/tokenization_moss.py
+-rw-rw-rw-  2.0 fat    15939 b- defN 23-Apr-24 00:32 deep_training/nlp/models/moss/tokenization_moss.py
 -rw-rw-rw-  2.0 fat       55 b- defN 23-Apr-20 03:02 deep_training/nlp/models/rlhf/__init__.py
 -rw-rw-rw-  2.0 fat       55 b- defN 23-Apr-20 03:02 deep_training/nlp/models/rlhf/ppo/__init__.py
--rw-rw-rw-  2.0 fat      212 b- defN 23-Apr-20 09:24 deep_training/nlp/models/rlhf/ppo/configuration.py
--rw-rw-rw-  2.0 fat       55 b- defN 23-Apr-20 03:05 deep_training/nlp/models/rlhf/ppo/ppo.py
+-rw-rw-rw-  2.0 fat     2238 b- defN 23-Apr-23 06:11 deep_training/nlp/models/rlhf/ppo/configuration.py
+-rw-rw-rw-  2.0 fat     2691 b- defN 23-Apr-24 00:19 deep_training/nlp/models/rlhf/ppo/data_type.py
+-rw-rw-rw-  2.0 fat     8064 b- defN 23-Apr-24 01:34 deep_training/nlp/models/rlhf/ppo/ppo.py
+-rw-rw-rw-  2.0 fat    16349 b- defN 23-Apr-24 03:30 deep_training/nlp/models/rlhf/ppo/ppo_dataset.py
+-rw-rw-rw-  2.0 fat    10496 b- defN 23-Apr-24 00:19 deep_training/nlp/models/rlhf/ppo/utils.py
 -rw-rw-rw-  2.0 fat      102 b- defN 22-Nov-22 08:00 deep_training/nlp/models/splinker/__init__.py
--rw-rw-rw-  2.0 fat     2851 b- defN 22-Dec-22 08:14 deep_training/nlp/models/splinker/splinker.py
+-rw-rw-rw-  2.0 fat     2866 b- defN 23-Apr-25 03:34 deep_training/nlp/models/splinker/splinker.py
 -rw-rw-rw-  2.0 fat    14478 b- defN 23-Feb-11 09:07 deep_training/nlp/models/t5decoder/__init__.py
 -rw-rw-rw-  2.0 fat     6646 b- defN 23-Feb-09 00:28 deep_training/nlp/models/t5encoder/__init__.py
 -rw-rw-rw-  2.0 fat       56 b- defN 22-Dec-14 08:02 deep_training/nlp/optimizer/__init__.py
 -rw-rw-rw-  2.0 fat     5225 b- defN 23-Mar-08 00:14 deep_training/nlp/optimizer/lamb.py
 -rw-rw-rw-  2.0 fat       99 b- defN 23-Mar-02 05:27 deep_training/nlp/optimizer/lion/__init__.py
 -rw-rw-rw-  2.0 fat     2295 b- defN 23-Mar-02 05:27 deep_training/nlp/optimizer/lion/lion.py
 -rw-rw-rw-  2.0 fat     2198 b- defN 23-Mar-02 05:27 deep_training/nlp/optimizer/lion/triton.py
 -rw-rw-rw-  2.0 fat     2868 b- defN 22-Dec-14 08:00 deep_training/nlp/scheduler/__init__.py
--rw-rw-rw-  2.0 fat     6982 b- defN 23-Apr-03 00:32 deep_training/nlp/utils/__init__.py
+-rw-rw-rw-  2.0 fat     7277 b- defN 23-Apr-26 05:05 deep_training/nlp/utils/__init__.py
 -rw-rw-rw-  2.0 fat     6323 b- defN 23-Jan-29 01:07 deep_training/nlp/utils/adversarial.py
 -rw-rw-rw-  2.0 fat    15256 b- defN 23-Jan-03 01:54 deep_training/nlp/utils/nlputils.py
 -rw-rw-rw-  2.0 fat      795 b- defN 23-Jan-11 07:02 deep_training/nlp/utils/spearman.py
 -rw-rw-rw-  2.0 fat       53 b- defN 23-Mar-07 01:25 deep_training/tfnlp/__init__.py
 -rw-rw-rw-  2.0 fat       53 b- defN 23-Mar-07 01:25 deep_training/tfnlp/layers/__init__.py
 -rw-rw-rw-  2.0 fat       53 b- defN 23-Mar-07 01:25 deep_training/tfnlp/losses/__init__.py
 -rw-rw-rw-  2.0 fat       53 b- defN 23-Mar-07 01:25 deep_training/tfnlp/metrics/__init__.py
@@ -146,12 +150,12 @@
 -rw-rw-rw-  2.0 fat       53 b- defN 23-Mar-07 01:25 deep_training/tfnlp/scheduler/__init__.py
 -rw-rw-rw-  2.0 fat       53 b- defN 23-Mar-07 01:26 deep_training/tfnlp/utils/__init__.py
 -rw-rw-rw-  2.0 fat       55 b- defN 23-Mar-07 01:20 deep_training/utils/__init__.py
 -rw-rw-rw-  2.0 fat     1941 b- defN 23-Mar-07 01:20 deep_training/utils/distributed.py
 -rw-rw-rw-  2.0 fat     1724 b- defN 23-Mar-07 01:22 deep_training/utils/func.py
 -rw-rw-rw-  2.0 fat     5117 b- defN 23-Feb-21 09:01 deep_training/utils/maskedlm.py
 -rw-rw-rw-  2.0 fat     7469 b- defN 23-Mar-20 00:27 deep_training/utils/trainer.py
--rw-rw-rw-  2.0 fat      626 b- defN 23-Apr-23 01:18 deep_training-0.1.3rc0.dist-info/METADATA
--rw-rw-rw-  2.0 fat       92 b- defN 23-Apr-23 01:18 deep_training-0.1.3rc0.dist-info/WHEEL
--rw-rw-rw-  2.0 fat       14 b- defN 23-Apr-23 01:18 deep_training-0.1.3rc0.dist-info/top_level.txt
-?rw-rw-r--  2.0 fat    15020 b- defN 23-Apr-23 01:18 deep_training-0.1.3rc0.dist-info/RECORD
-155 files, 912959 bytes uncompressed, 242935 bytes compressed:  73.4%
+-rw-rw-rw-  2.0 fat      626 b- defN 23-Apr-26 05:05 deep_training-0.1.3rc2.dist-info/METADATA
+-rw-rw-rw-  2.0 fat       92 b- defN 23-Apr-26 05:05 deep_training-0.1.3rc2.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat       14 b- defN 23-Apr-26 05:05 deep_training-0.1.3rc2.dist-info/top_level.txt
+?rw-rw-r--  2.0 fat    15420 b- defN 23-Apr-26 05:05 deep_training-0.1.3rc2.dist-info/RECORD
+159 files, 956851 bytes uncompressed, 255028 bytes compressed:  73.3%
```

## zipnote {}

```diff
@@ -42,14 +42,17 @@
 
 Filename: deep_training/nlp/layers/mhslayer.py
 Comment: 
 
 Filename: deep_training/nlp/layers/norm.py
 Comment: 
 
+Filename: deep_training/nlp/layers/ppo.py
+Comment: 
+
 Filename: deep_training/nlp/layers/prefix_encoder.py
 Comment: 
 
 Filename: deep_training/nlp/layers/seq_pointer.py
 Comment: 
 
 Filename: deep_training/nlp/layers/w2ner.py
@@ -363,17 +366,26 @@
 
 Filename: deep_training/nlp/models/rlhf/ppo/__init__.py
 Comment: 
 
 Filename: deep_training/nlp/models/rlhf/ppo/configuration.py
 Comment: 
 
+Filename: deep_training/nlp/models/rlhf/ppo/data_type.py
+Comment: 
+
 Filename: deep_training/nlp/models/rlhf/ppo/ppo.py
 Comment: 
 
+Filename: deep_training/nlp/models/rlhf/ppo/ppo_dataset.py
+Comment: 
+
+Filename: deep_training/nlp/models/rlhf/ppo/utils.py
+Comment: 
+
 Filename: deep_training/nlp/models/splinker/__init__.py
 Comment: 
 
 Filename: deep_training/nlp/models/splinker/splinker.py
 Comment: 
 
 Filename: deep_training/nlp/models/t5decoder/__init__.py
@@ -447,20 +459,20 @@
 
 Filename: deep_training/utils/maskedlm.py
 Comment: 
 
 Filename: deep_training/utils/trainer.py
 Comment: 
 
-Filename: deep_training-0.1.3rc0.dist-info/METADATA
+Filename: deep_training-0.1.3rc2.dist-info/METADATA
 Comment: 
 
-Filename: deep_training-0.1.3rc0.dist-info/WHEEL
+Filename: deep_training-0.1.3rc2.dist-info/WHEEL
 Comment: 
 
-Filename: deep_training-0.1.3rc0.dist-info/top_level.txt
+Filename: deep_training-0.1.3rc2.dist-info/top_level.txt
 Comment: 
 
-Filename: deep_training-0.1.3rc0.dist-info/RECORD
+Filename: deep_training-0.1.3rc2.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## deep_training/setup.py

```diff
@@ -1,15 +1,15 @@
 #! -*- coding: utf-8 -*-
 
 from setuptools import setup, find_packages
 
 ignore = ['test','tests']
 setup(
     name='deep_training',
-    version='0.1.3rc0',
+    version='0.1.3rc2',
     description='an easy training architecture',
     long_description='torch_training: https://github.com/ssbuild/deep_training.git',
     license='Apache License 2.0',
     url='https://github.com/ssbuild/deep_training',
     author='ssbuild',
     author_email='9727464@qq.com',
     install_requires=['pytorch-lightning>=2',
```

## deep_training/nlp/models/casrel.py

```diff
@@ -50,15 +50,15 @@
         self.object_layer = nn.Linear(config.hidden_size, 2 * config.num_labels)
 
         self.sigmoid = nn.Sigmoid()
         self.cond_norm_layer = LayerNorm(hidden_size=config.hidden_size,
                                          cond_dim=config.hidden_size * 2)
         self.loss_fn = LossForCasRel(reduction='none')
 
-    def get_model_lr(self):
+    def get_model_lr(self,*args,**kwargs):
         return super(TransformerForHphtlinker, self).get_model_lr() + [
             (self.subject_layer, self.config.task_specific_params['learning_rate_for_task']),
             (self.object_layer, self.config.task_specific_params['learning_rate_for_task']),
             (self.cond_norm_layer, self.config.task_specific_params['learning_rate_for_task']),
             (self.sigmoid, self.config.task_specific_params['learning_rate_for_task']),
             (self.dropout, self.config.task_specific_params['learning_rate_for_task']),
             (self.loss_fn, self.config.task_specific_params['learning_rate_for_task'])
```

## deep_training/nlp/models/crf_cascad.py

```diff
@@ -85,15 +85,15 @@
         self.dropout = nn.Dropout(config.hidden_dropout_prob)
         self.seqs_classifier = nn.Linear(config.hidden_size, len(seqs2id))
         self.crf = CRF(num_tags=len(seqs2id))
         self.ents_classifier = nn.Linear(config.hidden_size, len(ents2id))
         self.cross_loss = nn.CrossEntropyLoss(reduction='none')
 
 
-    def get_model_lr(self):
+    def get_model_lr(self,*args,**kwargs):
         return super(TransformerForCascadCRF, self).get_model_lr() + [
             (self.dropout, self.config.task_specific_params['learning_rate_for_task']),
             (self.seqs_classifier, self.config.task_specific_params['learning_rate_for_task']),
             (self.ents_classifier, self.config.task_specific_params['learning_rate_for_task']),
             (self.crf, self.config.task_specific_params['learning_rate_for_task']),
         ]
```

## deep_training/nlp/models/crf_model.py

```diff
@@ -12,15 +12,15 @@
     def __init__(self, *args,**kwargs):
         super(TransformerForCRF, self).__init__(*args,**kwargs)
         config = self.config
         self.dropout = nn.Dropout(config.hidden_dropout_prob)
         self.classifier = nn.Linear(config.hidden_size, config.num_labels)
         self.crf = CRF(num_tags=config.num_labels)
 
-    def get_model_lr(self):
+    def get_model_lr(self,*args,**kwargs):
         return super(TransformerForCRF, self).get_model_lr() + [
             (self.classifier, self.config.task_specific_params['learning_rate']),
             (self.crf, self.config.task_specific_params['learning_rate_for_task']),
         ]
 
     def compute_loss(self, *args,**batch) -> tuple:
         labels: torch.Tensor = batch.pop('labels',None)
```

## deep_training/nlp/models/diffcse.py

```diff
@@ -228,15 +228,15 @@
         else:
             self.classifier2, self.decoder, self.loss_fn = None, None, None
 
         self.loss_fn = nn.CrossEntropyLoss(ignore_index=self.generator_config.pad_token_id,reduction='none')
         self.loss_fn_cse = MultipleNegativesRankingLoss()
 
 
-    def get_model_lr(self):
+    def get_model_lr(self,*args,**kwargs):
         return super(TransformerForDiffcse, self).get_model_lr() + [
             (self.dropout, self.config.task_specific_params['learning_rate_for_task']),
             (self.discriminator, self.config.task_specific_params['learning_rate_for_task']),
         ]
 
 
     def pooling_output(self, outputs,num_layers):
```

## deep_training/nlp/models/esimcse.py

```diff
@@ -22,15 +22,15 @@
         self.pooling = pooling
         self.gamma = gamma
         # config = self.config
         # self.dropout = nn.Dropout(config.hidden_dropout_prob)
         self.momentum_encoder = TransformerModel(*args,**kwargs)
         self.loss_fn = MultipleNegativesRankingLoss()
 
-    def get_model_lr(self):
+    def get_model_lr(self,*args,**kwargs):
         return super(TransformerForESimcse, self).get_model_lr()
 
     def pooling_output(self,outputs):
         if self.pooling == 'cls':
             simcse_logits = outputs[0][:, 0]
         elif self.pooling == 'pooler':
             simcse_logits = outputs[1]
```

## deep_training/nlp/models/gec_model.py

```diff
@@ -75,15 +75,15 @@
         config = self.config
         self.dropout = nn.Dropout(config.hidden_dropout_prob)
         self.classifier1 = nn.Linear(config.hidden_size, 4)
         self.classifier2 = nn.Linear(config.hidden_size, config.num_labels,bias=False)
         self.loss_fn = nn.CrossEntropyLoss()
 
 
-    def get_model_lr(self):
+    def get_model_lr(self,*args,**kwargs):
         return super(TransformerForGec, self).get_model_lr() + [
             (self.classifier1, self.config.task_specific_params['learning_rate_for_task']),
             (self.classifier2, self.config.task_specific_params['learning_rate_for_task']),
         ]
 
     def compute_loss(self, *args,**batch) -> tuple:
         labels_action: torch.Tensor = batch.pop('labels_action',None)
```

## deep_training/nlp/models/gplinker.py

```diff
@@ -49,15 +49,15 @@
         PointerLayerObject = EfficientPointerLayer if with_efficient else PointerLayer
         self.entities_layer = PointerLayerObject(self.config.hidden_size, 2, 64)
         self.heads_layer = PointerLayerObject(self.config.hidden_size, self.config.num_labels, 64, RoPE=False,
                                               tril_mask=False)
         self.tails_layer = PointerLayerObject(self.config.hidden_size, self.config.num_labels, 64, RoPE=False,
                                               tril_mask=False)
 
-    def get_model_lr(self):
+    def get_model_lr(self,*args,**kwargs):
         return super(TransformerForGplinker, self).get_model_lr() + [
             (self.entities_layer, self.config.task_specific_params['learning_rate_for_task']),
             (self.heads_layer, self.config.task_specific_params['learning_rate_for_task']),
             (self.tails_layer, self.config.task_specific_params['learning_rate_for_task']),
         ]
 
     def compute_loss(self, *args,**batch) -> tuple:
@@ -225,15 +225,15 @@
         super(TransformerForGplinkerEvent, self).__init__(*args, **kwargs)
         self.dropout = nn.Dropout(self.config.hidden_dropout_prob)
         PointerLayerObject = EfficientPointerLayer if with_efficient else PointerLayer
         self.entities_layer = PointerLayerObject(self.config.hidden_size, self.config.num_labels, 64)
         self.heads_layer = PointerLayerObject(self.config.hidden_size, 1, 64, RoPE=False)
         self.tails_layer = PointerLayerObject(self.config.hidden_size, 1, 64, RoPE=False)
 
-    def get_model_lr(self):
+    def get_model_lr(self,*args,**kwargs):
         return super(TransformerForGplinkerEvent, self).get_model_lr() + [
             (self.entities_layer, self.config.task_specific_params['learning_rate_for_task']),
             (self.heads_layer, self.config.task_specific_params['learning_rate_for_task']),
             (self.tails_layer, self.config.task_specific_params['learning_rate_for_task']),
         ]
 
     def compute_loss(self, *args,**batch) -> tuple:
```

## deep_training/nlp/models/infonce.py

```diff
@@ -18,15 +18,15 @@
         vector_size = kwargs.pop('vector_size', 512)
         super(TransformerForInfoNce, self).__init__(*args, **kwargs)
         config = self.config
         self.pooling = pooling
         self.feat_head = nn.Linear(config.hidden_size, vector_size, bias=False)
         self.loss_fn = InfoNCE(temperature=temperature,negative_mode='paired', reduction='sum')
 
-    def get_model_lr(self):
+    def get_model_lr(self,*args,**kwargs):
         return super(TransformerForInfoNce, self).get_model_lr() + [
             (self.feat_head, self.config.task_specific_params['learning_rate_for_task'])
         ]
 
     def forward_for_hidden(self, *args, **batch):
         outputs = self.model(*args, **batch, output_hidden_states=True, )
         if self.pooling == 'cls':
```

## deep_training/nlp/models/mhs_ner.py

```diff
@@ -43,15 +43,15 @@
         config = self.config
 
         self.dropout = nn.Dropout(config.hidden_dropout_prob)
         self.mhslayer = MhsLayer(config.hidden_size,config.num_labels)
         self.sigmoid = nn.Sigmoid()
         self.loss_fn = MutiheadlinkerLossEx()
 
-    def get_model_lr(self):
+    def get_model_lr(self,*args,**kwargs):
         return super(TransformerForMhsNer, self).get_model_lr() + [
             (self.dropout, self.config.task_specific_params['learning_rate_for_task']),
             (self.mhslayer, self.config.task_specific_params['learning_rate_for_task']),
             (self.loss_fn, self.config.task_specific_params['learning_rate_for_task']),
         ]
 
     def compute_loss(self, *args,**batch) -> tuple:
```

## deep_training/nlp/models/mhslinker.py

```diff
@@ -102,15 +102,15 @@
         self.dropout = nn.Dropout(config.hidden_dropout_prob)
         self.classifier = nn.Linear(config.hidden_size, 3)
         self.crf = CRF(num_tags=3)
         self.mhslayer = MhsLayer(config.hidden_size,config.num_labels)
         self.sigmoid = nn.Sigmoid()
         self.loss_fn = MutiheadlinkerLossEx()
 
-    def get_model_lr(self):
+    def get_model_lr(self,*args,**kwargs):
         return super(TransformerForMhsLinker, self).get_model_lr() + [
             (self.dropout, self.config.task_specific_params['learning_rate_for_task']),
             (self.classifier, self.config.task_specific_params['learning_rate_for_task']),
             (self.crf, self.config.task_specific_params['learning_rate_for_task']),
             (self.mhslayer, self.config.task_specific_params['learning_rate_for_task']),
             (self.loss_fn, self.config.task_specific_params['learning_rate_for_task']),
         ]
```

## deep_training/nlp/models/onerel_model.py

```diff
@@ -47,15 +47,15 @@
         self.relation_matrix_layer = nn.Linear(self.config.hidden_size * 3, self.config.num_labels * self.tag_size)
 
         self.dropout_2 = nn.Dropout(entity_pair_dropout)
         # self.activation = nn.ReLU()
         self.loss_fn = nn.CrossEntropyLoss(reduction='none',ignore_index=-100)
 
 
-    def get_model_lr(self):
+    def get_model_lr(self,*args,**kwargs):
         return super(TransformerForOneRel, self).get_model_lr() + [
             (self.dropout, self.config.task_specific_params['learning_rate']),
             (self.dropout_2, self.config.task_specific_params['learning_rate']),
             (self.relation_matrix_layer, self.config.task_specific_params['learning_rate_for_task']),
             (self.projection_matrix_layer, self.config.task_specific_params['learning_rate_for_task']),
         ]
```

## deep_training/nlp/models/pointer.py

```diff
@@ -31,15 +31,15 @@
     def __init__(self,*args,**kwargs):
         with_efficient = kwargs.pop('with_efficient', True)
         super(TransformerForPointer, self).__init__(*args, **kwargs)
         self.dropout = nn.Dropout(self.config.hidden_dropout_prob)
         PointerLayerObject = EfficientPointerLayer if with_efficient else PointerLayer
         self.pointer_layer = PointerLayerObject(self.config.hidden_size,self.config.num_labels,64)
 
-    def get_model_lr(self):
+    def get_model_lr(self,*args,**kwargs):
         return super(TransformerForPointer, self).get_model_lr() + [
             (self.pointer_layer, self.config.task_specific_params['learning_rate_for_task']),
         ]
 
     def compute_loss(self,*args,**batch) -> tuple:
         labels: torch.Tensor = batch.pop('labels', None)
         outputs = self.model(*args,**batch)
```

## deep_training/nlp/models/prefixtuning.py

```diff
@@ -68,15 +68,15 @@
         total_param = all_param - the_model_param
         print('total param is {}'.format(total_param))  # 9860105
         #function
         self._get_prompt : typing.Callable = self.get_prompt_0 if prompt_args.prompt_type == 0 else self.get_prompt_1
         self._get_transformer_outputs : typing.Callable = self.get_transformer_outputs_0 if prompt_args.prompt_type == 0 else self.get_transformer_outputs_1
 
 
-    def get_model_lr(self):
+    def get_model_lr(self,*args,**kwargs):
         return super(PrefixTransformerForModel, self).get_model_lr() + [
             (self.prefix_encoder, self.config.task_specific_params['learning_rate_for_task']),
         ]
 
     def get_prompt_0(self, batch_size):
         prefix_tokens = self.prefix_tokens.unsqueeze(0).expand(batch_size, -1).to(self.model.device)
         prompts = self.prefix_encoder(prefix_tokens)
@@ -149,15 +149,15 @@
 
 
 class PrefixTransformerForSequenceClassification(PrefixTransformerForModel):
     def __init__(self,  *args: Any, **kwargs: Any):
         super().__init__(*args, **kwargs)
         self.classifier = torch.nn.Linear(self.config.hidden_size, self.config.num_labels)
 
-    def get_model_lr(self):
+    def get_model_lr(self,*args,**kwargs):
         return super(PrefixTransformerForSequenceClassification, self).get_model_lr() + [
             (self.classifier, self.config.task_specific_params['learning_rate_for_task']),
         ]
 
 
     def compute_loss(self, *args,**batch) -> tuple:
         labels = batch.pop('labels',None)
@@ -200,15 +200,15 @@
 
 class PrefixTransformerForTokenClassification(PrefixTransformerForModel):
     def __init__(self, *args: Any, **kwargs: Any):
         super().__init__(*args, **kwargs)
         self.num_labels = self.config.num_labels
         self.classifier = torch.nn.Linear(self.config.hidden_size,  self.config.num_labels)
 
-    def get_model_lr(self):
+    def get_model_lr(self,*args,**kwargs):
         return super(PrefixTransformerForTokenClassification, self).get_model_lr() + [
             (self.classifier, self.config.task_specific_params['learning_rate_for_task']),
         ]
 
 
     def compute_loss(self, *args,**batch) -> tuple:
         labels = batch.pop('labels',None)
@@ -243,15 +243,15 @@
 class PrefixTransformerPointer(PrefixTransformerForModel):
     def __init__(self, *args, **kwargs):
         with_efficient = kwargs.pop('with_efficient', True)
         super().__init__(*args, **kwargs)
         PointerLayerObject = EfficientPointerLayer if with_efficient else PointerLayer
         self.pointer_layer = PointerLayerObject(self.config.hidden_size, self.config.num_labels, 64)
 
-    def get_model_lr(self):
+    def get_model_lr(self,*args,**kwargs):
         return super(PrefixTransformerPointer, self).get_model_lr() + [
             (self.pointer_layer, self.config.task_specific_params['learning_rate_for_task']),
         ]
 
 
     def compute_loss(self, *args,**batch) -> tuple:
         labels: torch.Tensor = batch.pop('labels', None)
@@ -297,15 +297,15 @@
     def __init__(self,*args, **kwargs):
         super().__init__(*args, **kwargs)
         config = self.config
         self.dropout = nn.Dropout(config.hidden_dropout_prob)
         self.classifier = nn.Linear(config.hidden_size, config.num_labels)
         self.crf = CRF(num_tags=config.num_labels)
 
-    def get_model_lr(self):
+    def get_model_lr(self,*args,**kwargs):
         return super(PrefixTransformerForCRF, self).get_model_lr() + [
             (self.classifier, self.config.task_specific_params['learning_rate']),
             (self.crf, self.config.task_specific_params['learning_rate_for_task']),
         ]
 
     def compute_loss(self, *args,**batch) -> tuple:
         labels: torch.Tensor = batch.pop('labels', None)
```

## deep_training/nlp/models/prgc_model.py

```diff
@@ -225,15 +225,15 @@
         self.rel_judgement = MultiNonLinearClassifier(config.hidden_size,config.num_labels,prgcmodel_args.dropout)
         self.rel_embedding = nn.Embedding(config.num_labels,config.hidden_size)
 
         self.loss_fn1 = nn.CrossEntropyLoss(reduction='none',ignore_index=-100)
         self.loss_fn2 = nn.BCEWithLogitsLoss(reduction='none')
 
 
-    def get_model_lr(self):
+    def get_model_lr(self,*args,**kwargs):
         return super(TransformerForPRGC, self).get_model_lr() + [
             (self.dropout, self.config.task_specific_params['learning_rate_for_task']),
             (self.sequence_tagging_sub, self.config.task_specific_params['learning_rate_for_task']),
             (self.sequence_tagging_obj, self.config.task_specific_params['learning_rate_for_task']),
             (self.sequence_tagging_sum, self.config.task_specific_params['learning_rate_for_task']),
             (self.global_corres, self.config.task_specific_params['learning_rate_for_task']),
             (self.rel_judgement, self.config.task_specific_params['learning_rate_for_task']),
```

## deep_training/nlp/models/promptbert_cse.py

```diff
@@ -183,15 +183,15 @@
 
             if self.promptbertcse_args.mask_embedding_sentence_autoprompt_random_init:
                 self.p_mbv.data.normal_(mean=0.0, std=0.02)
         else:
             self.dict_mbv = None
             self.fl_mbv = None
 
-    def get_model_lr(self):
+    def get_model_lr(self,*args,**kwargs):
         current = [(self.mlp, self.config.task_specific_params['learning_rate_for_task']),
                    (getattr(self, 'p_mbv', None), self.config.task_specific_params['learning_rate_for_task']),
                    (getattr(self, 'dict_mbv', None), self.config.task_specific_params['learning_rate_for_task']),
                    (getattr(self, 'fl_mbv', None), self.config.task_specific_params['learning_rate_for_task']), ]
         return super(TransformerForPromptbertcse, self).get_model_lr() + [
             item for item in current if item[0] is not None
         ]
```

## deep_training/nlp/models/pure_model.py

```diff
@@ -74,15 +74,15 @@
                       out_features = self.puremodel_args.head_hidden_dim),
             nn.ReLU(),
             nn.Dropout(p=config.hidden_dropout_prob),
             nn.Linear(self.puremodel_args.head_hidden_dim, config.num_labels + 1)
         )
         self.loss_fn = CrossEntropyLoss(reduction='sum',ignore_index=-100)
 
-    def get_model_lr(self):
+    def get_model_lr(self,*args,**kwargs):
         return super(TransformerForPure, self).get_model_lr() + [
             (self.width_embedding, self.config.task_specific_params['learning_rate']),
             (self.classifier, self.config.task_specific_params['learning_rate']),
         ]
 
     def _get_span_embeddings(self, sequence_output, spans):
         """
```

## deep_training/nlp/models/simcse.py

```diff
@@ -22,15 +22,15 @@
         pooling = kwargs.pop('pooling')
         super(TransformerForSimcse, self).__init__(*args,**kwargs)
         self.pooling = pooling
         config = self.config
         self.sim_head = nn.Linear(config.hidden_size, 512, bias=False)
         self.loss_fn = MultipleNegativesRankingLoss()
 
-    def get_model_lr(self):
+    def get_model_lr(self,*args,**kwargs):
         return super(TransformerForSimcse, self).get_model_lr() + [
             (self.sim_head, self.config.task_specific_params['learning_rate_for_task'])
         ]
 
     def forward_for_hidden(self, *args, **batch):
         outputs = self.model(*args, **batch, output_hidden_states=True, )
         if self.pooling == 'cls':
```

## deep_training/nlp/models/span_ner.py

```diff
@@ -81,15 +81,15 @@
                 nn.Linear(config.hidden_size, (config.num_labels + 1) * 2),
             )
             self.loss_fn = nn.CrossEntropyLoss(reduction='none')
             self.compute_loss = self.compute_loss_for_singlelabel
 
 
 
-    def get_model_lr(self):
+    def get_model_lr(self,*args,**kwargs):
         return super(TransformerForSpanNer, self).get_model_lr() + [
             (self.dropout, self.config.task_specific_params['learning_rate_for_task']),
             (self.span_layer, self.config.task_specific_params['learning_rate_for_task']),
         ]
 
 
     def compute_loss_for_mutilabel(self,*args,**batch):
```

## deep_training/nlp/models/spn4re.py

```diff
@@ -293,15 +293,15 @@
         self.criterion = SetCriterion(self.config.num_labels,
                                       loss_weight=self.get_loss_weight(spn4re_args),
                                       na_coef=self.spn4re_args.na_rel_coef,
                                       losses=["entity", "relation"],
                                       matcher=self.spn4re_args.matcher)
 
 
-    def get_model_lr(self):
+    def get_model_lr(self,*args,**kwargs):
         return super(TransformerForSPN4RE, self).get_model_lr() + [
             (self.dropout, self.config.task_specific_params['learning_rate']),
             (self.decoder, self.config.task_specific_params['learning_rate']),
             (self.criterion, self.config.task_specific_params['learning_rate']),
         ]
 
     def compute_loss(self, *args,**batch) -> tuple:
```

## deep_training/nlp/models/tplinker.py

```diff
@@ -138,15 +138,15 @@
 
         self.ent_fc = nn.Linear(self.config.hidden_size, 2)
         self.heads_layer = nn.Linear(self.config.hidden_size, self.config.num_labels * 3)
         self.tails_layer = nn.Linear(self.config.hidden_size, self.config.num_labels * 3)
         self.loss_ent_fn = TplinkerLoss(reduction='sum')
         self.loss_rel_fn = TplinkerLoss(reduction='sum')
 
-    def get_model_lr(self):
+    def get_model_lr(self,*args,**kwargs):
         return super(TransformerForTplinker, self).get_model_lr() + [
             (self.dropout, self.config.task_specific_params['learning_rate_for_task']),
             (self.handshakingkernel, self.config.task_specific_params['learning_rate_for_task']),
             (self.ent_fc, self.config.task_specific_params['learning_rate_for_task']),
             (self.heads_layer, self.config.task_specific_params['learning_rate_for_task']),
             (self.tails_layer, self.config.task_specific_params['learning_rate_for_task']),
             (self.loss_ent_fn, self.config.task_specific_params['learning_rate_for_task']),
```

## deep_training/nlp/models/tplinkerplus.py

```diff
@@ -132,15 +132,15 @@
         super(TransformerForTplinkerPlus, self).__init__(*args, **kwargs)
         self.tok_pair_sample_rate = tok_pair_sample_rate
         self.dropout = nn.Dropout(self.config.hidden_dropout_prob)
         self.handshakingkernel = HandshakingKernel(self.config.hidden_size,shaking_type,inner_enc_type)
         self.fc = nn.Linear(self.config.hidden_size,self.config.num_labels)
         self.loss_fn = TplinkerPlusLoss()
 
-    def get_model_lr(self):
+    def get_model_lr(self,*args,**kwargs):
         return super(TransformerForTplinkerPlus, self).get_model_lr() + [
             (self.dropout, self.config.task_specific_params['learning_rate_for_task']),
             (self.handshakingkernel, self.config.task_specific_params['learning_rate_for_task']),
             (self.fc, self.config.task_specific_params['learning_rate_for_task']),
             (self.loss_fn, self.config.task_specific_params['learning_rate_for_task']),
         ]
```

## deep_training/nlp/models/transformer.py

```diff
@@ -44,15 +44,15 @@
 class TransformerModelForUnilm(TransformerModel):
     def __init__(self,*args: Any, **kwargs: Any):
         ignore_index = kwargs.pop('ignore_index',-100)
         super().__init__(*args, **kwargs)
         self.loss_fct = LM_loss(ignore_index=ignore_index)
         self.lm_head = nn.Linear(self.config.hidden_size, self.config.vocab_size, bias=False)
 
-    def get_model_lr(self):
+    def get_model_lr(self,*args,**kwargs):
         return super(TransformerModelForUnilm, self).get_model_lr() + \
                [(self.lm_head,self.config.task_specific_params['learning_rate_for_task']),]
 
     def compute_loss(self, *args,**batch) -> tuple:
         batch['attention_mask'] = unilm_mask(batch['token_type_ids'])
         if getattr(self.config, 'type_vocab_size', 0) != 2:
             batch.pop('token_type_ids')
```

## deep_training/nlp/models/transformer_base.py

```diff
@@ -221,16 +221,19 @@
                 if o == 'model':
                     o = 'model_'
                 setattr(self._premodel_data,k,o)
 
         assert self._premodel_data.base_model_prefix is not None, ValueError('base_model_prefix is not allow empty')
         setattr(self, self._premodel_data.base_model_prefix, model)
 
-    def get_model_lr(self):
-        return [(self.model if self._premodel_data.base_model_prefix is not None else self , self.config.task_specific_params['learning_rate']), ]
+    def get_model_lr(self,model=None,lr=None):
+        lr = lr if lr is not None else self.config.task_specific_params['learning_rate']
+        if model is not None:
+            return [(model,lr)]
+        return [(self.model if self._premodel_data.base_model_prefix is not None else self , lr), ]
 
 
 
 class TransformerLightningModule(MyLightningModule):
     def __init__(self, *args,**kwargs):
         config = get_value_from_args('config',PretrainedConfig,*args,**kwargs)
         model_args = get_value_from_args('model_args', ModelArguments, *args, **kwargs)
@@ -347,36 +350,40 @@
         ]
         for e in event_:
             a = getattr(self.__backbone, e, None)
             if a is not None:
                 setattr(self,e,a)
 
 
-    def get_model_lr(self):
-        return self.model.get_model_lr()
+    def get_model_lr(self,model=None,lr=None):
+        lr = lr if lr is not None else self.config.task_specific_params['learning_rate']
+        if model is not None:
+            return [(model, lr)]
+        return self.model.get_model_lr(model=None,lr=None) if model is None else [(model,self.config.task_specific_params['learning_rate'])]
 
 
     def compute_loss(self,*args, **kwargs):
         kwargs.update(dict(args))
         return self.model.compute_loss(**kwargs)
 
 
     def forward(self,*args, **kwargs):
         kwargs.update(dict(args))
         return self.compute_loss(**kwargs)
 
 
     def setup(self, stage: str) -> None:
-        setattr(self.backbone, 'trainer', self.trainer)
-        setattr(self.backbone, 'estimated_stepping_batches', self.trainer.estimated_stepping_batches)
+        if self.backbone is not None:
+            setattr(self.backbone, 'trainer', self.trainer)
+            setattr(self.backbone, 'estimated_stepping_batches', self.trainer.estimated_stepping_batches)
 
 
-    def get_named_parameters(self):
+    def get_named_parameters(self,*args,**kwargs):
         training_args = self.training_args
-        model_attrs = self.get_model_lr()
+        model_attrs = self.get_model_lr(*args,**kwargs)
         no_decay = ["bias", "LayerNorm.weight"]
         def __get_named_parameters(a : nn.Module):
             return [
                 {
                     "params": [p for n, p in a.named_parameters() if not any(nd in n for nd in no_decay)],
                     "weight_decay": training_args.weight_decay, "lr": lr,
                 },
```

## deep_training/nlp/models/tsdae_model.py

```diff
@@ -116,15 +116,15 @@
             self.predictions = nn.Linear(decoder_config.hidden_size, decoder_config.vocab_size)
             self.loss_fn = nn.CrossEntropyLoss(ignore_index=self.decoder_tokenizer.pad_token_id)
         else:
             self.predictions, self.classifier2,self.decoder,self.loss_fn = None,None,None,None
 
 
 
-    def get_model_lr(self):
+    def get_model_lr(self,*args,**kwargs):
         return super(TransformerForTSDAE, self).get_model_lr() + [
             (self.classifier, self.config.task_specific_params['learning_rate_for_task']),
             (self.classifier2, self.config.task_specific_params['learning_rate_for_task']),
             (self.decoder, self.config.task_specific_params['learning_rate_for_task']),
             (self.predictions, self.config.task_specific_params['learning_rate_for_task']),
         ]
```

## deep_training/nlp/models/w2ner.py

```diff
@@ -165,15 +165,15 @@
                                      w2nerArguments.ffnn_hid_size,
                                      w2nerArguments.out_dropout)
 
         self.cln = LayerNorm(w2nerArguments.lstm_hid_size, w2nerArguments.lstm_hid_size)
         self.criterion = nn.CrossEntropyLoss(reduction='mean')
 
 
-    def get_model_lr(self):
+    def get_model_lr(self,*args,**kwargs):
         return super(TransformerForW2ner, self).get_model_lr() + [
             (self.dropout, self.config.task_specific_params['learning_rate_for_task']),
             (self.dis_embs, self.config.task_specific_params['learning_rate_for_task']),
             (self.reg_embs, self.config.task_specific_params['learning_rate_for_task']),
             (self.encoder, self.config.task_specific_params['learning_rate_for_task']),
             (self.convLayer, self.config.task_specific_params['learning_rate_for_task']),
             (self.predictor, self.config.task_specific_params['learning_rate_for_task']),
```

## deep_training/nlp/models/moss/modeling_moss.py

```diff
@@ -722,7 +722,11 @@
         [`~PretrainedModel.beam_sample`] is called. This is required to match `past_key_values` with the correct
         beam_idx at every generation step.
         """
         return tuple(
             tuple(past_state.index_select(0, beam_idx.to(past_state.device)) for past_state in layer_past)
             for layer_past in past_key_values
         )
+
+    def quantize(self, wbits, groupsize):
+        from .quantization import quantize_with_gptq
+        return quantize_with_gptq(self, wbits, groupsize)
```

## deep_training/nlp/models/moss/tokenization_moss.py

```diff
@@ -27,35 +27,46 @@
 }
 
 PRETRAINED_VOCAB_FILES_MAP = {
     "vocab_file": {
         "fnlp/moss-moon-003-base": "https://huggingface.co/fnlp/moss-moon-003-base/resolve/main/vocab.json",
         "fnlp/moss-moon-003-sft": "https://huggingface.co/fnlp/moss-moon-003-sft/resolve/main/vocab.json",
         "fnlp/moss-moon-003-sft-plugin": "https://huggingface.co/fnlp/moss-moon-003-sft-plugin/resolve/main/vocab.json",
+        "fnlp/moss-moon-003-sft-int8": "https://huggingface.co/fnlp/moss-moon-003-sft-int8/resolve/main/vocab.json",
+        "fnlp/moss-moon-003-sft-plugin-int8": "https://huggingface.co/fnlp/moss-moon-003-sft-plugin-int8/resolve/main/vocab.json",
+        "fnlp/moss-moon-003-sft-int4": "https://huggingface.co/fnlp/moss-moon-003-sft-int4/resolve/main/vocab.json",
+        "fnlp/moss-moon-003-sft-plugin-int4": "https://huggingface.co/fnlp/moss-moon-003-sft-plugin-int4/resolve/main/vocab.json",
     },
     "merges_file": {
         "fnlp/moss-moon-003-base": "https://huggingface.co/fnlp/moss-moon-003-base/resolve/main/merges.txt",
         "fnlp/moss-moon-003-sft": "https://huggingface.co/fnlp/moss-moon-003-sft/resolve/main/merges.txt",
         "fnlp/moss-moon-003-sft-plugin": "https://huggingface.co/fnlp/moss-moon-003-sft-plugin/resolve/main/merges.txt",
+        "fnlp/moss-moon-003-sft-int8": "https://huggingface.co/fnlp/moss-moon-003-sft-int8/resolve/main/merges.txt",
+        "fnlp/moss-moon-003-sft-plugin-int8": "https://huggingface.co/fnlp/moss-moon-003-sft-plugin-int8/resolve/main/merges.txt",
+        "fnlp/moss-moon-003-sft-int4": "https://huggingface.co/fnlp/moss-moon-003-sft-int4/resolve/main/merges.txt",
+        "fnlp/moss-moon-003-sft-plugin-int4": "https://huggingface.co/fnlp/moss-moon-003-sft-plugin-int4/resolve/main/merges.txt",
     },
 }
 
 PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {
     "fnlp/moss-moon-003-base": 2048,
     "fnlp/moss-moon-003-sft": 2048,
     "fnlp/moss-moon-003-sft-plugin": 2048,
+    "fnlp/moss-moon-003-sft-int8": 2048,
+    "fnlp/moss-moon-003-sft-plugin-int8": 2048,
+    "fnlp/moss-moon-003-sft-int4": 2048,
+    "fnlp/moss-moon-003-sft-plugin-int4": 2048,
 }
 
 
 @lru_cache()
 def bytes_to_unicode():
     """
     Returns list of utf-8 byte and a mapping to unicode strings. We specifically avoids mapping to whitespace/control
     characters the bpe code barfs on.
-
     The reversible bpe codes work on unicode strings. This means you need a large # of unicode characters in your vocab
     if you want to avoid UNKs. When you're at something like a 10B token dataset you end up needing around 5K for
     decent coverage. This is a significant percentage of your normal, say, 32K bpe vocab. To avoid that, we want lookup
     tables between utf-8 bytes and unicode strings.
     """
     bs = (
         list(range(ord("!"), ord("~") + 1)) + list(range(ord("¡"), ord("¬") + 1)) + list(range(ord("®"), ord("ÿ") + 1))
@@ -70,44 +81,36 @@
     cs = [chr(n) for n in cs]
     return dict(zip(bs, cs))
 
 
 def get_pairs(word):
     """
     Return set of symbol pairs in a word.
-
     Word is represented as tuple of symbols (symbols being variable-length strings).
     """
     pairs = set()
     prev_char = word[0]
     for char in word[1:]:
         pairs.add((prev_char, char))
         prev_char = char
     return pairs
 
 
 class MossTokenizer(PreTrainedTokenizer):
     """
     Construct a Moss tokenizer. Based on byte-level Byte-Pair-Encoding.
-
     This tokenizer has been trained to treat spaces like parts of the tokens (a bit like sentencepiece) so a word will
     be encoded differently whether it is at the beginning of the sentence (without space) or not:
-
     You can get around that behavior by passing `add_prefix_space=True` when instantiating this tokenizer or when you
     call it on some text, but since the model was not pretrained this way, it might yield a decrease in performance.
-
     <Tip>
-
     When used with `is_split_into_words=True`, this tokenizer will add a space before each word (even the first one).
-
     </Tip>
-
     This tokenizer inherits from [`PreTrainedTokenizer`] which contains most of the main methods. Users should refer to
     this superclass for more information regarding those methods.
-
     Args:
         vocab_file (`str`):
             Path to the vocabulary file.
         merges_file (`str`):
             Path to the merges file.
         errors (`str`, *optional*, defaults to `"replace"`):
             Paradigm to follow when decoding bytes to UTF-8. See
@@ -302,32 +305,29 @@
         clean_up_tokenization_spaces: bool = None,
         truncate_before_pattern: Optional[List[str]] = None,
         **kwargs,
     ) -> str:
         """
         Converts a sequence of ids in a string, using the tokenizer and vocabulary with options to remove special
         tokens and clean up tokenization spaces.
-
         Similar to doing `self.convert_tokens_to_string(self.convert_ids_to_tokens(token_ids))`.
-
         Args:
             token_ids (`Union[int, List[int], np.ndarray, torch.Tensor, tf.Tensor]`):
                 List of tokenized input ids. Can be obtained using the `__call__` method.
             skip_special_tokens (`bool`, *optional*, defaults to `False`):
                 Whether or not to remove special tokens in the decoding.
             clean_up_tokenization_spaces (`bool`, *optional*):
                 Whether or not to clean up the tokenization spaces. If `None`, will default to
                 `self.clean_up_tokenization_spaces` (available in the `tokenizer_config`).
             truncate_before_pattern (`List[str]`, *optional*, defaults to `None`):
                 A list of regular expression strings that will be used to truncate the returned string. This can be
                 used to remove extra pieces of code (e.g. truncate if observing a comment symbol "#" at the beginning
                 of a new line). An example pattern could be `["^#", re.escape("<|endoftext|>"), "^'''", "\n\n\n"]`.
             kwargs (additional keyword arguments, *optional*):
                 Will be passed to the underlying model specific decode method.
-
         Returns:
             `str`: The decoded sentence.
         """
         decoded_text = super()._decode(
             token_ids=token_ids,
             skip_special_tokens=skip_special_tokens,
             clean_up_tokenization_spaces=clean_up_tokenization_spaces,
@@ -361,8 +361,8 @@
         terminals_pos = [
             pos for pos in [find_re(completion, terminal, start_pos) for terminal in terminals] if pos != -1
         ]
 
         if len(terminals_pos) > 0:
             return completion[: min(terminals_pos)]
         else:
-            return completion
+            return completion
```

## deep_training/nlp/models/rlhf/ppo/configuration.py

```diff
@@ -1,9 +1,87 @@
 # -*- coding: utf-8 -*-
 # @Time    : 2023/4/20 11:03
 import warnings
 from dataclasses import field, dataclass
-from typing import Optional
+from typing import Optional, Dict, Any
 
 import numpy as np
 from transformers.utils import flatten_dict
 
+@dataclass
+class MethodConfig:
+    """
+    Config for a certain RL method.
+
+    :param name: Name of the method
+    :type name: str
+    """
+
+    name: str
+
+    @classmethod
+    def from_dict(cls, config: Dict[str, Any]):
+        return cls(**config)
+
+
+
+@dataclass
+class PPOConfig(MethodConfig):
+    """
+    Config for PPO method
+
+    :param ppo_epochs: Number of updates per batch
+    :type ppo_epochs: int
+
+    :param num_rollouts: Number  of experiences to observe before learning
+    :type num_rollouts: int
+
+    :param init_kl_coef: Initial value for KL coefficient
+    :type init_kl_coef: float
+
+    :param target: Target value for KL coefficient
+    :type target: float
+
+    :param horizon: Number of steps for KL coefficient to reach target
+    :type horizon: int
+
+    :param gamma: Discount factor
+    :type gamma: float
+
+    :param lam: GAE lambda
+    :type lam: float
+
+    :param cliprange: Clipping range for PPO policy loss (1 - cliprange, 1 + cliprange)
+    :type cliprange: float
+
+    :param cliprange_value: Clipping range for predicted values
+                            (observed values - cliprange_value, observed values + cliprange_value)
+    :type cliprange_value: float
+
+    :param vf_coef: Value loss scale w.r.t policy loss
+    :type vf_coef: float
+
+    :param gen_kwargs: Additioanl kwargs for the generation
+    :type gen_kwargs: Dict[str, Any]
+
+    :param gen_experience_kwargs: if this is not None, then the experience is generated using this
+    :type gen_experience_kwargs: Dict[str, Any]
+    """
+
+    ppo_epochs: int
+    num_rollouts: int
+    chunk_size: int
+    init_kl_coef: float
+    target: float
+    horizon: int
+    gamma: float
+    lam: float
+    cliprange: float
+    cliprange_value: float
+    vf_coef: float
+    scale_reward: Optional[str]
+    ref_mean: Optional[float]
+    ref_std: Optional[float]
+    cliprange_reward: float
+    gen_kwargs: dict
+    gen_experience_kwargs: Optional[dict] = None
+
```

## deep_training/nlp/models/rlhf/ppo/ppo.py

```diff
@@ -1,2 +1,200 @@
 # -*- coding: utf-8 -*-
 # @Time    : 2023/4/20 11:05
+import logging
+import os
+from time import time
+from typing import List, Callable, Tuple, Optional
+
+import torch
+from torch import nn
+from tqdm import tqdm
+from torch.nn import functional as F
+import torch.distributed as dist
+from .....nlp.layers.ppo import AdaptiveKLController, FixedKLController
+from .data_type import PPORLElement, PPORLBatch
+from .utils import logprobs_of_labels, Clock, gather_dict, RunningMoments, pad_across_processes, _gpu_gather, \
+    get_tensor_stats, flatten_dict, whiten
+
+logger = logging.get_logger(__name__)
+
+
+
+class PPOLoss(nn.Module):
+    def __init__(self,model_arch_type):
+        super(PPOLoss, self).__init__()
+        self.model_arch_type = model_arch_type
+
+    def foward(self,batch: PPORLBatch,device):
+        """Forward pass & loss
+
+              Args:
+                  batch: Previous batch of episodes
+              """
+        # Move `batch` data to `accelerator` device
+        query_tensors = batch.query_tensors.to(device)
+        response_tensors = batch.response_tensors.to(device)
+        old_logprobs = batch.logprobs.to(device)
+        old_values = batch.values.to(device)
+        old_rewards = batch.rewards.to(device)
+        response_length = old_rewards.shape[1]
+
+        advantages, returns = self.get_advantages_and_returns(old_values, old_rewards, response_length)
+
+        if self.model_arch_type == "seq2seq":
+            input_ids = query_tensors
+            decoder_input_ids = response_tensors
+            attention_mask = input_ids.ne(self.tokenizer.pad_token_id).long().to(device)
+            decoder_attention_mask = (
+                decoder_input_ids.ne(self.tokenizer.pad_token_id).long().to(device)
+            )
+            decoder_attention_mask[:, 0] = 1
+
+            # Forward pass
+            outputs = self.model(
+                input_ids=input_ids,
+                attention_mask=attention_mask,
+                decoder_input_ids=decoder_input_ids,
+                decoder_attention_mask=decoder_attention_mask,
+            )
+
+            logits = outputs.logits
+            values_pred = outputs.value
+            logprobs = logprobs_of_labels(logits[:, :-1, :], decoder_input_ids[:, 1:])
+            mask = decoder_input_ids.ne(self.tokenizer.pad_token_id).long().to(device)
+            start = 0
+            end = start + response_length
+            logprobs, values_pred, mask = (
+                logprobs[:, start:end],
+                values_pred[:, start:end],
+                mask[:, start:end],
+            )
+        else:
+            tokens = torch.cat((query_tensors, response_tensors), dim=1)
+            attention_mask = tokens.not_equal(self.tokenizer.pad_token_id).long().to(tokens.device)
+            outputs = self.model(tokens, attention_mask, return_dict=True)
+            logits = outputs.logits
+            values_pred = outputs.value
+            values_pred = values_pred[:, :-1]
+            logprobs = logprobs_of_labels(logits[:, :-1, :], tokens[:, 1:])
+
+            start = query_tensors.shape[1] - 1
+            end = start + response_length
+            logprobs, values_pred, mask = (
+                logprobs[:, start:end],
+                values_pred[:, start:end],
+                attention_mask[:, start:end],
+            )
+
+        loss, stats = self.loss_fn(
+            logprobs=logprobs,
+            values=values_pred,
+            old_logprobs=old_logprobs,
+            old_values=old_values,
+            advantages=advantages,
+            returns=returns,
+            mask=mask,
+        )
+        return loss, stats
+
+    def get_advantages_and_returns(
+            self,
+            values, # : TensorType["batch_size", "response_size"]
+            rewards, #: TensorType["batch_size", "response_size"]
+            response_length: int,
+            use_whitening: Optional[bool] = True,
+    ) -> Tuple[torch.Tensor, torch.Tensor]:
+        """Function that computes advantages and returns from rewards and values.
+        Calculated as in the original PPO paper: https://arxiv.org/abs/1707.06347
+        Note that rewards may include a KL divergence loss term.
+
+        Advantages looks like this:
+        Adv1 =  R1 + γ * λ * R2     + γ^2 * λ^2 * R3       + ...
+              - V1 + γ * (1 - λ) V2 + γ^2 * λ * (1 - λ) V3 + ...
+
+        Returns looks like this:
+        Ret1 =  R1 + γ * λ * R2     + γ^2 * λ^2 * R3       + ...
+                   + γ * (1 - λ) V2 + γ^2 * λ * (1 - λ) V3 + ...
+
+        Args:
+            values: Tensor of shape (batch_size, response_size)
+            rewards: Tensor of shape (batch_size, response_size)
+            response_length: Length of the response sequence
+            use_whitening: Whether to use whitening (ie. normalize advantages) or not
+        """
+        lastgaelam = 0
+        advantages_reversed = []
+        for t in reversed(range(response_length)):
+            nextvalues = values[:, t + 1] if t < response_length - 1 else 0.0
+            delta = rewards[:, t] + self.gamma * nextvalues - values[:, t]
+            lastgaelam = delta + self.gamma * self.lam * lastgaelam
+            advantages_reversed.append(lastgaelam)
+        advantages = torch.stack(advantages_reversed[::-1], dim=1)
+        returns = advantages + values
+        if use_whitening:
+            advantages = whiten(advantages)
+        return advantages.detach(), returns
+
+    def loss_fn(
+            self,
+            logprobs, # : TensorType["batch_size", "response_size"]
+            values, # : TensorType["batch_size", "response_size"]
+            old_logprobs, # : TensorType["batch_size", "response_size"]
+            old_values, # : TensorType["batch_size", "response_size"]
+            advantages, # : TensorType["batch_size", "response_size"]
+            returns, # : TensorType["batch_size", "response_size"]
+            mask # : TensorType["batch_size", "response_size"],
+    ):
+        """PPO objective function.
+        References:
+        - https://stable-baselines.readthedocs.io/en/master/modules/ppo2.html
+        """
+        values_clipped = torch.clamp(
+            values,
+            old_values - self.cliprange_value,
+            old_values + self.cliprange_value,
+        )
+        n = mask.sum()
+
+        vf_loss1 = (values - returns) ** 2
+        vf_loss2 = (values_clipped - returns) ** 2
+        vf_loss = 0.5 * torch.sum(torch.max(vf_loss1, vf_loss2) * mask) / n
+        vf_clipfrac = torch.sum((vf_loss2 > vf_loss1).float() * mask) / n
+
+        log_ratio = (logprobs - old_logprobs) * mask
+        ratio = torch.exp(log_ratio)
+        # Unbiased KL-div estimates (`k3`). Ref: http://joschu.net/blog/kl-approx.html
+        with torch.no_grad():
+            approx_kl = torch.mean((ratio - 1) - log_ratio)
+
+        pg_loss1 = -advantages * ratio
+        pg_loss2 = -advantages * torch.clamp(
+            ratio,
+            1.0 - self.cliprange,
+            1.0 + self.cliprange,
+        )
+        pg_loss = torch.sum(torch.max(pg_loss1, pg_loss2) * mask) / n
+        pg_clipfrac = torch.sum((pg_loss2 > pg_loss1).float() * mask) / n
+
+        loss = pg_loss + self.vf_coef * vf_loss
+
+        stats = dict(
+            losses=dict(
+                total_loss=loss.item(),
+                policy_loss=pg_loss.item(),
+                value_loss=vf_loss.item(),
+            ),
+            values=dict(
+                get_tensor_stats(values, mask, n),
+                values_error=torch.sum(((values - returns) * mask) ** 2) / n,
+                clipfrac=vf_clipfrac,
+            ),
+            old_values=get_tensor_stats(old_values, mask, n),
+            returns=get_tensor_stats(returns, mask, n),
+            policy=dict(approx_kl=approx_kl.item(), clipfrac=pg_clipfrac.item()),
+            ratio=(ratio * mask).sum() / n,
+            padding_percentage=n / mask.numel(),
+        )
+
+        return loss, flatten_dict(stats)
+
+
```

### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

## deep_training/nlp/models/splinker/splinker.py

```diff
@@ -49,15 +49,15 @@
         super(TransformerForSplinker, self).__init__(*args, **kwargs)
         config = self.config
         self.dropout = nn.Dropout(config.hidden_dropout_prob)
         self.classifier = nn.Linear(config.hidden_size, config.num_labels * 2 +2)
         self.loss_fn = BCELossForSplinker()
         self.sigmoid = nn.Sigmoid()
 
-    def get_model_lr(self):
+    def get_model_lr(self,*args,**kwargs):
         return super(TransformerForSplinker, self).get_model_lr() + [
             (self.classifier, self.config.task_specific_params['learning_rate_for_task']),
         ]
     
 
     def compute_loss(self,*args,**batch) -> tuple:
         labels: torch.Tensor = batch.pop('labels',None)
```

## deep_training/nlp/utils/__init__.py

```diff
@@ -12,14 +12,20 @@
 from ..optimizer.lion import Lion
 from ..optimizer.lamb import Lamb
 
 
 def configure_optimizers(named_parameter: typing.Union[typing.List,typing.Tuple],
                          training_args: TrainingArguments,
                          estimated_stepping_batches: int):
+
+    if estimated_stepping_batches is None:
+        if training_args.max_steps is not None and training_args.max_steps > 0:
+            estimated_stepping_batches = int(training_args.max_steps / training_args.gradient_accumulation_steps)
+    assert estimated_stepping_batches is not None
+
     optimizer_name = training_args.optimizer.lower()
     if optimizer_name == 'adamw':
         optimizer = AdamW(named_parameter, lr=training_args.learning_rate,
                           eps=training_args.adam_epsilon,
                           betas=training_args.optimizer_betas,
                           weight_decay=training_args.weight_decay
                           )
```

## Comparing `deep_training-0.1.3rc0.dist-info/METADATA` & `deep_training-0.1.3rc2.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: deep-training
-Version: 0.1.3rc0
+Version: 0.1.3rc2
 Summary: an easy training architecture
 Home-page: https://github.com/ssbuild/deep_training
 Author: ssbuild
 Author-email: 9727464@qq.com
 License: Apache License 2.0
 Platform: UNKNOWN
 Requires-Dist: pytorch-lightning (>=2)
```

## Comparing `deep_training-0.1.3rc0.dist-info/RECORD` & `deep_training-0.1.3rc2.dist-info/RECORD`

 * *Files 10% similar despite different names*

```diff
@@ -1,23 +1,24 @@
 deep_training/__init__.py,sha256=bhATnUT4VEzwvA8_8IwxspnDRKf32ZgEeHYCN2E5Dd4,47
-deep_training/setup.py,sha256=46TsaKTiTi81hV6hEosREfIgocgVQ3BI2m-oNRY5yaQ,900
+deep_training/setup.py,sha256=i93fj925-OkoFgbJMULSDAUtyaGsf31IjsFRcqFhQQY,900
 deep_training/cv/__init__.py,sha256=J-zlKxMsAfAgoO0vSAzgYJXSuMSJcJ7NKAPKeaeC3TM,55
 deep_training/data_helper/__init__.py,sha256=P8rAMalR6xNepAf-9ldGoOSsEiUtur8Px6gUpTXQhd8,195
 deep_training/data_helper/data_helper.py,sha256=wamHVXHpCIcG-COkVLRmwIjmcQ0MQy99xjago0ulkkY,29088
 deep_training/data_helper/data_module.py,sha256=cRqwzcKMpFaE2HhdbAEwrIC9KxOE0rLkeQ25VCJh2W8,4926
 deep_training/data_helper/data_writer.py,sha256=BnxUmMuR60Wawd1SH9TTEBsQuDLozxWJdmLozuO-Wv4,1383
 deep_training/data_helper/training_args.py,sha256=xAjTMEaNvXXzgdV9oNvSCaR1lKX4wdeIJoqus1VTN7w,12557
 deep_training/nlp/__init__.py,sha256=L4_ltrwpG8mrgN1hZRKimefLHgjhRYyXVtLMFzr1grw,70
 deep_training/nlp/layers/__init__.py,sha256=zbd9GfR02_YVgsTJSXjfyIcQwj8PmG4PscMdA0p6ONI,56
 deep_training/nlp/layers/activate.py,sha256=0q7htFl9Az2fdUjrjv-QMUCE5oenYPVTLZ3lRemIKzA,241
 deep_training/nlp/layers/crf.py,sha256=JTihPuJuBBp83I9UZzVg0wogwwpdJrs0VKtuLPBSCDM,13271
 deep_training/nlp/layers/handshakingkernel.py,sha256=BRJZbEjKM347q8zEMEtJXxXjmqhegmQgqebhqMy4UkI,4653
 deep_training/nlp/layers/mask.py,sha256=8SB_Hl9X48-yuJMCPjLDabDXvgWvH4VPqUOSVDmePFs,435
 deep_training/nlp/layers/mhslayer.py,sha256=Ky6xW3hNe0x4WWPPoWa8pZkCp_-MR5VE0yKHYPzzpd0,1319
 deep_training/nlp/layers/norm.py,sha256=r_yHSnDAv8RY1nb1VS1lMWttbJVyCO376OIuu0So8c8,5911
+deep_training/nlp/layers/ppo.py,sha256=CCaGA5Jx47UnAUy7kBYcf4emPRt0498U9tdLaoAEO-A,1390
 deep_training/nlp/layers/prefix_encoder.py,sha256=y_Y4wWLnEyZJf33pQJFjWfl-AX1VS8Aejj3JXOdiRXQ,1220
 deep_training/nlp/layers/seq_pointer.py,sha256=KmwZclK9gqdluy2o-h7nd3zL3EZjjjw1L6dz0isCFI8,7259
 deep_training/nlp/layers/w2ner.py,sha256=fP7hlMHp1NTH6elNMJA-wBOER76VTouSSsKCinLsCyM,3550
 deep_training/nlp/layers/lora_v1/__init__.py,sha256=gmwJqLmiKqPfh5_VGWWr38y8lLgdPWw6JrjNVrvsLEY,72
 deep_training/nlp/layers/lora_v1/layers.py,sha256=JWz9RtqA-hLsTxyhZPBlz82aN_VaPjNoDYRhssKV1H0,15095
 deep_training/nlp/layers/lora_v1/utils.py,sha256=1ouFUmTF9IXzum97eIlrTeT6J4OAnEwIaWkZdgXMjSc,1819
 deep_training/nlp/layers/lora_v2/__init__.py,sha256=dGpWUx0v7UoVgwZY5srCDCBvt_hlI77zA6mQO3CxMaE,72
@@ -61,39 +62,39 @@
 deep_training/nlp/losses/loss_splinker.py,sha256=aNeywPDi4eXlZE8w-PEH_O5py-U8rK2XX6VWvQeJpgk,562
 deep_training/nlp/losses/loss_spn4re.py,sha256=bTeDLS1Sc-HEvmRTO1uKOWaqqOYSEpY4fypbLwK7Ld4,10822
 deep_training/nlp/losses/loss_tplinker.py,sha256=KvFlyIxcj381lJRlds1uHfVvtwPZyf6VpnudYS8lBc8,5644
 deep_training/nlp/losses/utils.py,sha256=9G5lNmk5UmJoeaftPQcB2IWJAuDeWZ3yvEBQnrrIUSE,2466
 deep_training/nlp/metrics/__init__.py,sha256=sz0EVQSYGtPoRuRm7TCTh8ZClcUyozdVIIxAP8bEPSI,71
 deep_training/nlp/metrics/pointer.py,sha256=FDE99f8ZygvABLCKYV32ooAT6u53k-nmreOAptsnkWc,655
 deep_training/nlp/models/__init__.py,sha256=B8musCB5yh_lKApyDVt2sei9jkaa8Xq_MZiPwtbn3y0,58
-deep_training/nlp/models/casrel.py,sha256=FNcs3n7wyf8w9nLSoxn0GH17SBr8dMbuleCOMWUpZYY,6811
-deep_training/nlp/models/crf_cascad.py,sha256=9-EF87Q4_3KGwW6Q3y9y8Yl21LisnNF1dxfQAsuPSwU,5078
-deep_training/nlp/models/crf_model.py,sha256=edMjxx_XhcFcXLlUDWZmlxaVfth_55wUMcKpI8xyUDI,1573
-deep_training/nlp/models/diffcse.py,sha256=KXRdUa5BiN06u6Z0RtxHoAPOrHA5z_JmjsKcSeHbWvI,12970
-deep_training/nlp/models/esimcse.py,sha256=mY2xBZd916BoDWa4ugetFqG8lRSc2ux6Iqlk8ymPII0,5388
-deep_training/nlp/models/gec_model.py,sha256=ZhEtJ035C5YkeFiwSk05AbXEyw0UazkmYbv7D6JrD_g,4194
-deep_training/nlp/models/gplinker.py,sha256=cTiExAJjLewkX8jRWpuDdYC0HATlsYCF2Su_msHiezA,10824
-deep_training/nlp/models/infonce.py,sha256=axjo-3XHz8qyhxJX5E-lNB3HiTX3sEB-bFs_rCLAUG0,3799
-deep_training/nlp/models/mhs_ner.py,sha256=uo7tCKzXei_U4_da_vKMFbrK3uPL8S2zRejstjLiJqg,2444
-deep_training/nlp/models/mhslinker.py,sha256=BcVgMAfdhAW_80qcLVaZVoW_7ZRgfYSDwhobtFXoiAM,5976
-deep_training/nlp/models/onerel_model.py,sha256=AiiNSYEpp3NWbl7XY3bD5sxgrzJqRsg8FmDttUWnNN0,4646
-deep_training/nlp/models/pointer.py,sha256=Ey2N2CpLJS_rmVCNPW13YGWtyyKXW8wJlo3r24ZksMc,2735
-deep_training/nlp/models/prefixtuning.py,sha256=r7-UZ-d8782YUWnOz9c4ro0fe0TlIxnkKpskMlMxgM8,13317
-deep_training/nlp/models/prgc_model.py,sha256=4A54kryXN0R749Mwxko5ndyushHbbKr7bHwT3tjPaCc,15900
-deep_training/nlp/models/promptbert_cse.py,sha256=ZuG-BYq_pDPL1J2WdadUFtpieTTfCWWt9jEUEQ51HvM,16100
-deep_training/nlp/models/pure_model.py,sha256=J_rrgtl3CAg47301I1ntoI_kEwcXYgUioBa1pyczgR8,5134
-deep_training/nlp/models/simcse.py,sha256=_rOgAaunki07rsf6sH3jDQ41O9kXW8yF1ZuVqL7IbDo,3934
-deep_training/nlp/models/span_ner.py,sha256=UeLTYDCjjkcmIoEtNp60xqoHc02eXEhNLwf3EqeQznk,6007
-deep_training/nlp/models/spn4re.py,sha256=pSITHdWKnBzJ8KiQzScczfyxHl96NxRaUGE8B34FTrc,14439
-deep_training/nlp/models/tplinker.py,sha256=H2xNhLUnJs5FOoNZOylKGkHbhufcOXPr9xZG0BfDoJQ,11368
-deep_training/nlp/models/tplinkerplus.py,sha256=ywaqBqgDsmU1v__3VUaxDzNw8LaKVAL6Lnx49obvDUY,8142
-deep_training/nlp/models/transformer.py,sha256=oHoytULozKoZhK4RukhnMOYgXzrHxujYbY0VoqhumGM,6609
-deep_training/nlp/models/transformer_base.py,sha256=ZAgpFCUKCK3PqFv2_EY7L2D4YuFpreZUBOEljwB5xdk,25490
-deep_training/nlp/models/tsdae_model.py,sha256=ArjLqYu8XL_WkAqwiHYJXFIdro-HJHIxwBXirxBETVU,7953
-deep_training/nlp/models/w2ner.py,sha256=-KtfdpYY68s142CMcWHJbfiEHFW-qbSEENqtRgxHjBw,9025
+deep_training/nlp/models/casrel.py,sha256=OHJldk1TMxeiP8lhdzECWrpHF1cB__ZkpryZeqyvgmo,6826
+deep_training/nlp/models/crf_cascad.py,sha256=1U12EMFuGwYNKFMfn_wFDYsyp1jjzDB-ujOc6eknfPw,5093
+deep_training/nlp/models/crf_model.py,sha256=LYFh4S-fqF23zhxDPrwGI8R1wEep_jtAx-B8nUXJMtY,1588
+deep_training/nlp/models/diffcse.py,sha256=rgp_gCTdq64NkMkwAZEwacTtzz3h9thmj81xAuktRws,12985
+deep_training/nlp/models/esimcse.py,sha256=nT9k2MK5spCjrfjr3ZXhH-AGyeLTKlWXQGmu9PP16IU,5403
+deep_training/nlp/models/gec_model.py,sha256=YLJMX0e4UMe2TRakOmUjNGsKBmHv_WRCteWWYxqPBVw,4209
+deep_training/nlp/models/gplinker.py,sha256=3RjkwbcCw8RSBK5nYz0XdUz-f4dMj0M8vtCRt5D71MM,10854
+deep_training/nlp/models/infonce.py,sha256=8ytOu5iUuEj0j4wa8zRX9t6uB-dCRuhTp6C8nh1d5eQ,3814
+deep_training/nlp/models/mhs_ner.py,sha256=czbhCnnAZFZBuGRO6mLPGhQPjSU1EXOqekNeU0vB6_I,2459
+deep_training/nlp/models/mhslinker.py,sha256=jI1sppDEqqXqmvX3kiWyivCwu1tsGfTF4HuWykFfzik,5991
+deep_training/nlp/models/onerel_model.py,sha256=uy7DObzLO33bf8C_M8f0jvCofk5qCWtr_e-yWoIfum8,4661
+deep_training/nlp/models/pointer.py,sha256=VY6zkd314vIhKp5xqMU0Kh402T157jBrxJjItzkkry0,2750
+deep_training/nlp/models/prefixtuning.py,sha256=NiwMtdnFRazsKNhACB94kBDNYV0MK5Y7_aPDYthIcvQ,13392
+deep_training/nlp/models/prgc_model.py,sha256=KHiwjM5ay2xPUPjFYV0-lVH4diSxVuLv1gLJCIHM3Qk,15915
+deep_training/nlp/models/promptbert_cse.py,sha256=VsoutrF8VFNwmrhJnA4b6FcEejq-MP1L_5BI1q3l0ok,16115
+deep_training/nlp/models/pure_model.py,sha256=LD8cYvvRirnP8iMFCyRhsNXRHpZt93Kh2WGoUZoEnFw,5149
+deep_training/nlp/models/simcse.py,sha256=ubVGkeMatDeIUqySV8Tc2TJHvaRKb4p3JOvUTOOhaRo,3949
+deep_training/nlp/models/span_ner.py,sha256=rD0TY2K-zesfRFGfDguqkSAfxHGgbQHG3K5QZ6gc7Zg,6022
+deep_training/nlp/models/spn4re.py,sha256=g_pk3bNqpH41EnzJ77oWPsKvbUwzJfaBYMux5FiEc60,14454
+deep_training/nlp/models/tplinker.py,sha256=PJ9smipeIiA1CDi8xz1gIg2DBWzO5C1B2wITItEsd1A,11383
+deep_training/nlp/models/tplinkerplus.py,sha256=hP4KD3rf2hktfQzHnI7RA2j_2cjk_0G5v6CkbLt1gvQ,8157
+deep_training/nlp/models/transformer.py,sha256=ZuywgLt3HZhsR4sJ4SyZvrYgaVJW8lCn5JH1j_IceXE,6624
+deep_training/nlp/models/transformer_base.py,sha256=yI4WrmI_4imoedr3IYZ9-ZsRN2UMjtW7TOtUYOuWV8E,25966
+deep_training/nlp/models/tsdae_model.py,sha256=lb04RIGkhHhilD-vdkfb8YK9hnTck1nN79WX1Pngbbk,7968
+deep_training/nlp/models/w2ner.py,sha256=z0BortOquZSzmma355wNLz1ofLku_hMb2CjL4KDf-PM,9040
 deep_training/nlp/models/LLaMA/__init__.py,sha256=n_M2atEv-G2i3oy_YkLCVu5QiLLyfxEj2xr91h1dWEw,16500
 deep_training/nlp/models/LLaMA/configuration.py,sha256=HNzzhIIdR9HBN9Y4Oavv6cGgIf0ExcphwsbVkltJ2ZM,5087
 deep_training/nlp/models/LLaMA_parallel/__init__.py,sha256=5lsrh09pBTzRRKwc1bJtJs37Qn5qKqif_5S0pOoD1zc,19183
 deep_training/nlp/models/LLaMA_parallel/configuration.py,sha256=HNzzhIIdR9HBN9Y4Oavv6cGgIf0ExcphwsbVkltJ2ZM,5087
 deep_training/nlp/models/PaLM/__init__.py,sha256=P1qwWPUycRmZ6I48tov6janJUNpp4L-iMoVN54ykcQw,31627
 deep_training/nlp/models/PaLM/configuration.py,sha256=kIb3nj-2pQB2wyNrYHSZqr_ta1F0Cg-VbGEbnM5icPc,5890
 deep_training/nlp/models/chatglm/__init__.py,sha256=t9u927aSHY0mVpxtGrY7_jMEx25g9rsHKcE0HR3GWGc,60508
@@ -111,32 +112,35 @@
 deep_training/nlp/models/lora/v2/configuration.py,sha256=RXTsOjRKUHGFKpSrrFywjV41kT2liEPj1C6Li-ogJpI,11281
 deep_training/nlp/models/lora/v2/lora_model.py,sha256=5k09kzj8bSvU-CQm5GJWtg5isXUEUYPmvKuxdLPc_V4,11745
 deep_training/nlp/models/lora/v2/lora_wrapper.py,sha256=tzDCWUiGYC81cbfNiu4ZKo3VZsftM_SF8NwH8r56BO0,10265
 deep_training/nlp/models/lora/v2/save_and_load.py,sha256=U7_ZaPm8gpg8gQhZei6UG5KvsJXDtSNZfZk1gWo6nWc,4889
 deep_training/nlp/models/moss/__init__.py,sha256=_dQslDggRX8ZsR6RPTUuBzAHotQt8MPAqZ1-nGULPns,467
 deep_training/nlp/models/moss/configuration_moss.py,sha256=Qqp7anpWGnsotkqd5UOfc9e5zhxgx7j5xetSQUOmhaQ,5097
 deep_training/nlp/models/moss/custom_autotune.py,sha256=O-C9w-hZkcrUgDfK4B1iPtKjHQAZwELNefYhlLABHyc,6735
-deep_training/nlp/models/moss/modeling_moss.py,sha256=smkAESJv2rw-npBasohtoz1ztxtrCo479RGbkw_nUIk,30926
+deep_training/nlp/models/moss/modeling_moss.py,sha256=Trm6zkUFQo9SkgInIuusSFekRvyLa6x2W6WyRE9CswI,31079
 deep_training/nlp/models/moss/quantization.py,sha256=z43YME9DW_yER96uUoyWdE0GwyZaZX4psA40LRHLhP0,18866
-deep_training/nlp/models/moss/tokenization_moss.py,sha256=nqDlylb3w1FOpOTwHySh9WMxmPo9IXdZrYkkHgjdCbw,14782
+deep_training/nlp/models/moss/tokenization_moss.py,sha256=Ft7hwLBfYoAqn33anM0sbkvU7GuXJQW8NJ1Ddko_1hk,15939
 deep_training/nlp/models/rlhf/__init__.py,sha256=c1W6T8PhNnCVnEIKtr7qu-jHY2IliW9HcMOv5TZ92b0,55
 deep_training/nlp/models/rlhf/ppo/__init__.py,sha256=IqNQicmSmtZVbJIdNZdaQxpx0EbqvTJSUb2Bx1pRdys,55
-deep_training/nlp/models/rlhf/ppo/configuration.py,sha256=XDkcqvL5IVHYQe5Yew7hoxeWK3BQW7pTreg4VCF5G_s,212
-deep_training/nlp/models/rlhf/ppo/ppo.py,sha256=kMqYK4UyKiqavDLCExOYUiKNSBsc2axgtshOHczVSn4,55
+deep_training/nlp/models/rlhf/ppo/configuration.py,sha256=RjPR9mOa-sxtgD65dCfI5os_L7XADs591fJrxNBdodY,2238
+deep_training/nlp/models/rlhf/ppo/data_type.py,sha256=YSz3BPegvAC6Pl3x-dnFRbBV-qSxiJjwVwpUvbmMV7U,2691
+deep_training/nlp/models/rlhf/ppo/ppo.py,sha256=awBy3E1Yftz8kBUa46ojwIxy1t1L1FlVaegLF9zKJ5I,8064
+deep_training/nlp/models/rlhf/ppo/ppo_dataset.py,sha256=ETmwxeaWEOaReDozOrRax4RH2bA-PaPZdyQQ5W-DTnI,16349
+deep_training/nlp/models/rlhf/ppo/utils.py,sha256=9oDHyKiXKXJDpLuVfUyUaA6FhyobLmaU7seY_hupPYU,10496
 deep_training/nlp/models/splinker/__init__.py,sha256=QtgnpJa78vAq9bzfjN67NmHU3dXU6WH84jeyZoD1sBs,102
-deep_training/nlp/models/splinker/splinker.py,sha256=cAXQoPucM3ULYUhBw9z-OxPK_b9hHKEZPgMb4vFfQwc,2851
+deep_training/nlp/models/splinker/splinker.py,sha256=AhIWyfUtNOLqwZn520J-mv8LJwIoDZpo8yNoc4V5Gss,2866
 deep_training/nlp/models/t5decoder/__init__.py,sha256=R9Op4Ysli9isootQQ2FcjhpbG13fNESlmUROu6cfGH0,14478
 deep_training/nlp/models/t5encoder/__init__.py,sha256=692ChfLf2sZWgzhBM37g1PdpmEmsU1R9RRl_uTHRET0,6646
 deep_training/nlp/optimizer/__init__.py,sha256=c4cmx9ebIdqwXBu3N9QbcNNHb32t2MV6fTK9aC2VBGQ,56
 deep_training/nlp/optimizer/lamb.py,sha256=htvZQHPWHG5GCDgo9xCaZikWwRyaD2PjDioIQvX7qXw,5225
 deep_training/nlp/optimizer/lion/__init__.py,sha256=AvYkLp7sOpRIC3a5ejuniUUKyQmmBA1TPJdt2RA7Nqg,99
 deep_training/nlp/optimizer/lion/lion.py,sha256=kDN4_dz1N6G0q8PhQBpdQRNhtm5MXNSx-kde2JP2FlU,2295
 deep_training/nlp/optimizer/lion/triton.py,sha256=QLdWMW7cgqQU6Zb8uqmESONr7S7Nf1Tk4TR7OwACDQo,2198
 deep_training/nlp/scheduler/__init__.py,sha256=-zaiinwJzOBWypkNodSZO12kqbswVsPy5JCsYpvLbbY,2868
-deep_training/nlp/utils/__init__.py,sha256=RjmFkASRpijHVp-0w7PAXB_M21zs15I1g02YnJ5NihM,6982
+deep_training/nlp/utils/__init__.py,sha256=56nsV4nOnpzHX1VGbHQWWJyWkdC_fnkd-N-TWt3T_J4,7277
 deep_training/nlp/utils/adversarial.py,sha256=FNZlg8mV23YXRu7aDcu1JZBUGBV01hi_bwRzfFyzEzM,6323
 deep_training/nlp/utils/nlputils.py,sha256=KEmFliU1IqJHy3INNDvOriEMlBkP8GNwe8Y8_c_imZQ,15256
 deep_training/nlp/utils/spearman.py,sha256=tOpaah5bt_65ferL_uI6FMfKvNexi7CQztSYLj-k3yo,795
 deep_training/tfnlp/__init__.py,sha256=TRm9uMMO340jiD1ZGdDhtoxQ5BxI-au-RnOwAV13mbM,53
 deep_training/tfnlp/layers/__init__.py,sha256=TRm9uMMO340jiD1ZGdDhtoxQ5BxI-au-RnOwAV13mbM,53
 deep_training/tfnlp/losses/__init__.py,sha256=TRm9uMMO340jiD1ZGdDhtoxQ5BxI-au-RnOwAV13mbM,53
 deep_training/tfnlp/metrics/__init__.py,sha256=69flKnae4cQQyWUDwuYE0w0iaPonvH0P_WjBd_t-IqU,53
@@ -145,11 +149,11 @@
 deep_training/tfnlp/scheduler/__init__.py,sha256=69flKnae4cQQyWUDwuYE0w0iaPonvH0P_WjBd_t-IqU,53
 deep_training/tfnlp/utils/__init__.py,sha256=kAmlOWNSpQCHbtT-mAsKGQzQFoWKp2jQf3neCJ0cCRY,53
 deep_training/utils/__init__.py,sha256=JFm7m_LPsS9Oavyxn9rbWqllCmV_zBho19rISlHNX4c,55
 deep_training/utils/distributed.py,sha256=-dhvJ6YHpRxvtZ1_on50IE33fUFW3zKXBKqqK-L1HGM,1941
 deep_training/utils/func.py,sha256=1p8hiQDCyk_gQGKrF7y6Dt66k3jLXSAt2IQeJuHQEl8,1724
 deep_training/utils/maskedlm.py,sha256=o8EB2BbDdh7wdgqz9Oi6SsVr1uBWxV15qfTk2VPjWsU,5117
 deep_training/utils/trainer.py,sha256=Rit5xEC2r9MvQdDR4A5A6E4_gzNCVNmW9m55kC83O50,7469
-deep_training-0.1.3rc0.dist-info/METADATA,sha256=Jl4kZax1kYebJvVKjPOty8QymGDMpFNXgdwSbwY0VAw,626
-deep_training-0.1.3rc0.dist-info/WHEEL,sha256=OqRkF0eY5GHssMorFjlbTIq072vpHpF60fIQA6lS9xA,92
-deep_training-0.1.3rc0.dist-info/top_level.txt,sha256=P4qengiW56PZRm1VvlGcseSUCmAaBCsalCviUABZtO0,14
-deep_training-0.1.3rc0.dist-info/RECORD,,
+deep_training-0.1.3rc2.dist-info/METADATA,sha256=7woWpmmF8wmFfxKUVZ7Yy5Wbkrh6fsg0tTTU_QaWFek,626
+deep_training-0.1.3rc2.dist-info/WHEEL,sha256=OqRkF0eY5GHssMorFjlbTIq072vpHpF60fIQA6lS9xA,92
+deep_training-0.1.3rc2.dist-info/top_level.txt,sha256=P4qengiW56PZRm1VvlGcseSUCmAaBCsalCviUABZtO0,14
+deep_training-0.1.3rc2.dist-info/RECORD,,
```


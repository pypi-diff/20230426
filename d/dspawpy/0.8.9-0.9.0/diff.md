# Comparing `tmp/dspawpy-0.8.9-py3-none-any.whl.zip` & `tmp/dspawpy-0.9.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,22 +1,22 @@
-Zip file size: 69440 bytes, number of entries: 20
+Zip file size: 70357 bytes, number of entries: 20
 -rw-rw-rw-  2.0 fat        0 b- defN 23-Apr-04 06:32 dspawpy/__init__.py
--rw-rw-rw-  2.0 fat    29176 b- defN 23-Apr-20 08:41 dspawpy/plot.py
+-rw-rw-rw-  2.0 fat    29208 b- defN 23-Apr-25 05:34 dspawpy/plot.py
 -rw-rw-rw-  2.0 fat        0 b- defN 23-Apr-04 06:32 dspawpy/analysis/__init__.py
--rw-rw-rw-  2.0 fat    47547 b- defN 23-Apr-13 06:12 dspawpy/analysis/aimdtools.py
+-rw-rw-rw-  2.0 fat    23956 b- defN 23-Apr-25 05:50 dspawpy/analysis/aimdtools.py
 -rw-rw-rw-  2.0 fat    20152 b- defN 23-Apr-04 06:32 dspawpy/analysis/vacf.py
 -rw-rw-rw-  2.0 fat        0 b- defN 23-Apr-04 06:32 dspawpy/diffusion/__init__.py
--rw-rw-rw-  2.0 fat     9607 b- defN 23-Apr-13 05:59 dspawpy/diffusion/neb.py
--rw-rw-rw-  2.0 fat    52973 b- defN 23-Apr-21 04:37 dspawpy/diffusion/nebtools.py
--rw-rw-rw-  2.0 fat    10993 b- defN 23-Apr-13 05:52 dspawpy/diffusion/pathfinder.py
+-rw-rw-rw-  2.0 fat     9639 b- defN 23-Apr-25 05:34 dspawpy/diffusion/neb.py
+-rw-rw-rw-  2.0 fat    53458 b- defN 23-Apr-25 06:36 dspawpy/diffusion/nebtools.py
+-rw-rw-rw-  2.0 fat    11045 b- defN 23-Apr-25 05:34 dspawpy/diffusion/pathfinder.py
 -rw-rw-rw-  2.0 fat        0 b- defN 23-Apr-04 08:25 dspawpy/io/__init__.py
--rw-rw-rw-  2.0 fat    21646 b- defN 23-Apr-19 06:23 dspawpy/io/read.py
--rw-rw-rw-  2.0 fat     7910 b- defN 23-Apr-04 06:32 dspawpy/io/read_json.py
--rw-rw-rw-  2.0 fat    10331 b- defN 23-Apr-04 06:32 dspawpy/io/structure.py
--rw-rw-rw-  2.0 fat    29454 b- defN 23-Apr-21 08:01 dspawpy/io/utils.py
--rw-rw-rw-  2.0 fat    11045 b- defN 23-Apr-17 08:05 dspawpy/io/write.py
--rw-rw-rw-  2.0 fat     1794 b- defN 23-Apr-04 06:32 dspawpy/io/write_json.py
--rw-rw-rw-  2.0 fat     1523 b- defN 23-Apr-21 09:21 dspawpy-0.8.9.dist-info/METADATA
--rw-rw-rw-  2.0 fat       92 b- defN 23-Apr-21 09:21 dspawpy-0.8.9.dist-info/WHEEL
--rw-rw-rw-  2.0 fat        8 b- defN 23-Apr-21 09:21 dspawpy-0.8.9.dist-info/top_level.txt
-?rw-rw-r--  2.0 fat     1582 b- defN 23-Apr-21 09:21 dspawpy-0.8.9.dist-info/RECORD
-20 files, 255833 bytes uncompressed, 66890 bytes compressed:  73.9%
+-rw-rw-rw-  2.0 fat    41491 b- defN 23-Apr-25 06:36 dspawpy/io/read.py
+-rw-rw-rw-  2.0 fat     7721 b- defN 23-Apr-25 05:46 dspawpy/io/read_json.py
+-rw-rw-rw-  2.0 fat    13268 b- defN 23-Apr-25 06:36 dspawpy/io/structure.py
+-rw-rw-rw-  2.0 fat    25265 b- defN 23-Apr-25 05:34 dspawpy/io/utils.py
+-rw-rw-rw-  2.0 fat    17401 b- defN 23-Apr-25 06:36 dspawpy/io/write.py
+-rw-rw-rw-  2.0 fat     1761 b- defN 23-Apr-25 05:51 dspawpy/io/write_json.py
+-rw-rw-rw-  2.0 fat     1766 b- defN 23-Apr-26 02:17 dspawpy-0.9.0.dist-info/METADATA
+-rw-rw-rw-  2.0 fat       92 b- defN 23-Apr-26 02:17 dspawpy-0.9.0.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat        8 b- defN 23-Apr-26 02:17 dspawpy-0.9.0.dist-info/top_level.txt
+?rw-rw-r--  2.0 fat     1582 b- defN 23-Apr-26 02:17 dspawpy-0.9.0.dist-info/RECORD
+20 files, 257813 bytes uncompressed, 67807 bytes compressed:  73.7%
```

## zipnote {}

```diff
@@ -42,20 +42,20 @@
 
 Filename: dspawpy/io/write.py
 Comment: 
 
 Filename: dspawpy/io/write_json.py
 Comment: 
 
-Filename: dspawpy-0.8.9.dist-info/METADATA
+Filename: dspawpy-0.9.0.dist-info/METADATA
 Comment: 
 
-Filename: dspawpy-0.8.9.dist-info/WHEEL
+Filename: dspawpy-0.9.0.dist-info/WHEEL
 Comment: 
 
-Filename: dspawpy-0.8.9.dist-info/top_level.txt
+Filename: dspawpy-0.9.0.dist-info/top_level.txt
 Comment: 
 
-Filename: dspawpy-0.8.9.dist-info/RECORD
+Filename: dspawpy-0.9.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## dspawpy/plot.py

```diff
@@ -1,20 +1,22 @@
+import json
 import os
+
 import h5py
-import json
+import matplotlib.pyplot as plt
 import numpy as np
 import pandas as pd
 import statsmodels.api as sm
-import matplotlib.pyplot as plt
 from scipy.interpolate import interp1d
+
 from dspawpy.io.read import load_h5
 
 
 def average_along_axis(
-    datafile = "potential.h5",
+    datafile="potential.h5",
     task: str = "potential",
     axis=2,
     smooth=False,
     smooth_frac=0.8,
     raw=False,
     **kwargs,
 ):
@@ -67,15 +69,15 @@
             datafile = os.path.join(directory, f"{task}.h5")
             print("Readingf {task}.h5...")
         elif os.path.exists(os.path.join(directory, f"{task}.json")):
             datafile = os.path.join(directory, f"{task}.json")
             print("Readingf {task}.json...")
         else:
             raise FileNotFoundError(f"未找到{task}.h5/{task}.json文件！")
-        
+
     # parse the real datafile
     elif datafile.endswith(".h5"):
         hfile = datafile
         hdict = load_h5(hfile)
         grid = hdict["/AtomInfo/Grid"]
         # pot = np.asarray(potential["/Potential/TotalElectrostaticPotential"]).reshape(grid, order="F")
         # DS-PAW 数据写入h5 列优先
@@ -744,29 +746,29 @@
         for i, df in enumerate(datafile):
             # concentrate returned np.ndarray
             x, y = _read_aimd_converge_data(df, index)
             xs.extend(x)
             ys.extend(y)
         xs = np.linspace(1, len(xs), len(xs))
         return xs, ys
-        
+
     # search datafile in the given directory
     elif isinstance(datafile, str):
-        if os.path.isdir(datafile): # 如果是文件夹
+        if os.path.isdir(datafile):  # 如果是文件夹
             directory = datafile  # specified datafile is actually a directory
             print(f"您指定了一个文件夹，正在{directory}中自动查找aimd.h5...")
             if os.path.exists(os.path.join(directory, "aimd.h5")):
                 datafile = os.path.join(directory, "aimd.h5")
                 print("Reading aimd.h5...")
             else:
                 raise FileNotFoundError("未找到aimd.h5文件！")
-            
-        elif datafile.endswith(".h5"): # 如果是h5文件
+
+        elif datafile.endswith(".h5"):  # 如果是h5文件
             hf = h5py.File(datafile)  # 加载h5文件
-            print(f' reading {os.path.abspath(datafile)}...')
+            print(f" reading {os.path.abspath(datafile)}...")
             Nstep = len(np.array(hf.get("/Structures"))) - 2  # 步数（可能存在未完成的）
             ys = np.empty(Nstep)  # 准备一个空数组
             # 开始读取
             if index == "5":
                 for i in range(1, Nstep + 1):
                     ys[i - 1] = np.linalg.det(hf.get("/Structures/Step-%d/Lattice" % i))
             else:
@@ -775,15 +777,17 @@
                     "2": "TotalEnergy0",
                     "3": "PressureKinetic",
                     "4": "Temperature",
                 }
                 for i in range(1, Nstep + 1):
                     # 如果计算中断，则没有PressureKinetic这个键
                     try:
-                        ys[i - 1] = np.array(hf.get("/AimdInfo/Step-%d/%s" % (i, map[index])))
+                        ys[i - 1] = np.array(
+                            hf.get("/AimdInfo/Step-%d/%s" % (i, map[index]))
+                        )
                     except:
                         ys[i - 1] = 0
                         ys = np.delete(ys, -1)
                         print(f"-> 计算中断于第 {Nstep} 步，未读取到第 {i} 步的 {map[index]} 数据！")
                         break
 
             Nstep = len(ys)  # 步数更新为实际完成的步数
```

## dspawpy/analysis/aimdtools.py

```diff
@@ -1,14 +1,17 @@
 # -*- coding: utf-8 -*-
 import os
+from typing import List, Union
+
+import matplotlib.pyplot as plt
 import numpy as np
-from typing import List, Tuple, Union
-from scipy.ndimage import gaussian_filter1d
 from pymatgen.core import Structure
-import matplotlib.pyplot as plt
+from scipy.ndimage import gaussian_filter1d
+
+from dspawpy.io.structure import build_Structures_from_datafile
 
 
 class MSD:
     # 用于实际计算均方差的类，摘自pymatgen开源项目
     def __init__(
         self,
         structures: List[Structure],
@@ -57,15 +60,15 @@
                 "invalid msd_type: {} specified, please specify one of xyz, "
                 "xy, xz, yz, x, y, z".format(self.msd_type)
             )
 
         self.dim_fac = len(self._dim)
 
     def run(self):
-        print('Calculating MSD...')
+        print("Calculating MSD...")
         result = np.zeros((self.n_frames, self.n_particles))
 
         rd = np.zeros((self.n_frames, self.n_particles, self.dim_fac))
         for i in range(1, self.n_frames):
             disp = self._position_array[i, :, :] - self._position_array[i - 1, :, :]
             # mic by periodic boundary condition
             disp[np.abs(disp) > 0.5] = disp[np.abs(disp) > 0.5] - np.sign(
@@ -129,17 +132,15 @@
         # each neighbor list is a tuple of
         # center_indices, neighbor_indices, image_vectors, distances
         (
             self.center_indices,
             self.neighbor_indices,
             self.image_vectors,
             self.distances,  # 完整的距离列表（遍历体系所有原子）
-        ) = list(
-            zip(*self.neighbor_lists)
-        )
+        ) = list(zip(*self.neighbor_lists))
 
         elements = np.array([str(i.specie) for i in structures[0]])  # type: ignore
         self.center_elements = [elements[i] for i in self.center_indices]
         self.neighbor_elements = [elements[i] for i in self.neighbor_indices]
         self.density = [{}] * len(self.structures)
 
         self.natoms = [
@@ -204,19 +205,19 @@
             whether to take the average over all structures
 
         Returns
         -------
         (x, rdf)
             x is the radial points, and rdf is the rdf value.
         """
-        print('Calculating RDF...')
+        print("Calculating RDF...")
         all_rdfs = [
-                self.get_one_rdf(ref_species, species, i)[1]
-                for i in range(self.n_structures)
-            ]
+            self.get_one_rdf(ref_species, species, i)[1]
+            for i in range(self.n_structures)
+        ]
         if is_average:
             all_rdfs = np.mean(all_rdfs, axis=0)
         return self.r, all_rdfs
 
     def get_one_rdf(
         self,
         ref_species: Union[str, List[str]],
@@ -277,15 +278,15 @@
             the species that we are interested in. The rdfs are calculated on these species.
         is_average (bool): whether to take structural average
 
         Returns
         --------
         numpy array
         """
-        print('Calculating coordination number...')
+        print("Calculating coordination number...")
         # Note: The average density from all input structures is used here.
         all_rdf = self.get_rdf(ref_species, species, is_average=False)[1]
         if isinstance(species, str):
             species = [species]
         density = [sum(i[j] for j in species) for i in self.density]
         cn = [
             np.cumsum(rdf * density[i] * 4.0 * np.pi * self.r**2 * self.dr)
@@ -307,15 +308,15 @@
 
         self._position_array = np.zeros((self.n_frames, self.n_particles, 3))
 
         for i, s in enumerate(self.structures):
             self._position_array[i, :, :] = s.frac_coords
 
     def run(self, base_index=0):
-        print('Calculating RMSD...')
+        print("Calculating RMSD...")
         result = np.zeros(self.n_frames)
         rd = np.zeros((self.n_frames, self.n_particles, 3))
         for i in range(1, self.n_frames):
             disp = self._position_array[i, :, :] - self._position_array[i - 1, :, :]
             # mic by periodic boundary condition
             disp[np.abs(disp) > 0.5] = disp[np.abs(disp) > 0.5] - np.sign(
                 disp[np.abs(disp) > 0.5]
@@ -327,65 +328,14 @@
         for i in range(self.n_frames):
             sqdist = np.square(rd[i] - rd[base_index]).sum(axis=-1)
             result[i] = sqdist.mean()
 
         return np.sqrt(result)
 
 
-def build_Structures_from_datafile(datafile: Union[str, List[str]]) -> List[Structure]:
-    """读取一/多个h5/json文件，返回pymatgen的Structures列表
-
-    Parameters
-    ----------
-    datafile : 字符串或字符串列表
-        aimd.h5/aimd.json文件或包含任意这些文件文件夹；若给定字符串列表，将依次读取数据并合并成一个Structures列表
-
-    Returns
-    -------
-    List[Structure] : pymatgen structures 列表
-
-    Examples
-    --------
-    >>> from dspawpy.analysis.aimdtools import build_Structures_from_datafile
-    # 读取单个文件
-    >>> pymatgen_Structures = build_Structures_from_datafile(datafile='aimd1.h5')
-    # 给定包含aimd.h5或aimd.json文件的文件夹位置
-    >>> pymatgen_Structures = build_Structures_from_datafile(datafile='my_aimd_task')
-    # 当datafile为列表时，将依次读取多个文件，合并成一个Structures列表
-    >>> pymatgen_Structures = build_Structures_from_datafile(datafile=['aimd1.h5','aimd2.h5'])
-    """
-    dfs = []
-    if isinstance(datafile, list):  # 续算模式，给的是多个文件
-        dfs = datafile
-    else:  # 单次计算模式，处理单个文件
-        if os.path.isdir(datafile):
-            print(f"正在查找读取文件夹 {datafile} 中的aimd.h5或aimd.json文件...")
-            if os.path.exists(os.path.join(datafile, "aimd.h5")):
-                df = os.path.join(datafile, "aimd.h5")
-            elif os.path.exists(os.path.join(datafile, "aimd.json")):
-                df = os.path.join(datafile, "aimd.json")
-            else:
-                raise FileNotFoundError("不存在相应的aimd.h5或aimd.json文件！")
-
-        if datafile.endswith(".h5") or datafile.endswith(".json"):
-            df = datafile
-        else:
-            raise FileNotFoundError("未找到aimd.h5或aimd.json文件！")
-        dfs.append(df)
-
-    # 读取结构数据
-    pymatgen_Structures = []
-    for df in dfs:
-        # TODO 支持选取特定帧
-        structure_list = _get_structure_list(df)
-        pymatgen_Structures.extend(structure_list)
-
-    return pymatgen_Structures
-
-
 def get_lagtime_msd(
     datafile: Union[str, List[str]],
     select: Union[str, List[int]] = "all",
     msd_type: str = "xyz",
     timestep: float = 1.0,
 ):
     """计算不同时间步长下的均方差
@@ -533,17 +483,15 @@
            0.97097276])]
     """
     strs = build_Structures_from_datafile(datafile)
     # print(strs[0]) # check pbc
     # raise ValueError
 
     # 计算rdf并绘制主要曲线
-    obj = RDF(
-        structures=strs, rmin=rmin, rmax=rmax, ngrid=ngrid, sigma=sigma
-    )
+    obj = RDF(structures=strs, rmin=rmin, rmax=rmax, ngrid=ngrid, sigma=sigma)
 
     rs, rdfs = obj.get_rdf(ele1, ele2)
     return rs, rdfs
 
 
 def plot_msd(
     lagtime: np.ndarray,
@@ -760,594 +708,7 @@
 
     if figname:
         plt.savefig(figname)
     if show and ishow:  # 画子图的话，不应每个子图都show
         plt.show()  # show会自动清空图片
 
     return ax
-
-
-def read_h5(
-    hpath: str,
-    index = None,
-    ele = None,
-    ai = None,
-    return_scaled: bool = False,
-):
-    """从hpath指定的路径读取h5文件中的数据
-
-    Parameters
-    ----------
-    hpath: str
-        h5文件路径
-    index: int or list or str
-        运动轨迹中的第几步，从1开始计数
-        如果要切片，用字符串写法： '1, 10:20, 23'
-    ele: str or list or np.array
-        元素，例如 'C'，'H'，'O'，'N'
-    ai: int or list or np.array
-        原子序号（体系中的第几个原子，不是质子数）
-        如果要切片，用字符串写法： '1, 10:20, 23'
-    return_scaled: bool
-        是否返回原子分数坐标，默认为False
-
-    Return
-    -------
-    Nstep: int
-        离子步总数
-    elements: list
-        元素列表, Natom x 1
-    positions: np.ndarray
-        原子位置,  Nstep x Natom x 3
-    lattices: np.ndarray
-        晶胞, Nstep x 3 x 3
-
-    Examples
-    --------
-    >>> from dspawpy.analysis.aimdtools import read_h5
-    >>> Nstep, elements, positions, lattices = read_h5(hpath='aimd.h5', ele='H', index='1:2')
-    >>> Nstep
-    2
-    >>> elements
-    ['H', 'H']
-    >>> positions
-    array([[[0.56037855, 5.60910012, 0.06341764],
-            [0.57622933, 0.78033174, 6.28639689]],
-           [[0.55354018, 5.60627362, 0.12845834],
-            [0.57012995, 0.80246543, 6.22272366]]])
-    >>> lattices
-    array([[[6.35016, 0.     , 0.     ],
-            [0.     , 6.35016, 0.     ],
-            [0.     , 0.     , 6.35016]],
-           [[6.35016, 0.     , 0.     ],
-            [0.     , 6.35016, 0.     ],
-            [0.     , 0.     , 6.35016]]])
-    """
-    import h5py
-
-    print(f"Reading {os.path.abspath(hpath)} ...")
-    hf = h5py.File(hpath)  # 加载h5文件
-    Total_step = len(np.array(hf.get("/Structures"))) - 2  # 总步数
-
-    if ele and ai:
-        raise ValueError("暂不支持同时指定元素和原子序号")
-    # 步数
-    if index:
-        if isinstance(index, int):  # 1
-            indices = [index]
-
-        elif isinstance(index, list) or isinstance(ai, np.ndarray):  # [1,2,3]
-            indices = index
-
-        elif isinstance(index, str):  # ':', '-3:'
-            indices = _parse_indices(index, Total_step)
-
-        else:
-            raise ValueError("请输入正确格式的index")
-
-        Nstep = len(indices)
-    else:
-        Nstep = Total_step
-        indices = list(range(1, Nstep + 1))
-
-    # 读取元素列表，这个列表不会随步数改变，也不会“合并同类项”
-    from dspawpy.io.utils import get_ele_from_h5
-
-    Elements = np.array(get_ele_from_h5(hpath), dtype="str")
-
-    # 开始读取晶胞和原子位置
-    lattices = np.empty((Nstep, 3, 3))  # Nstep x 3 x 3
-    location = []
-    if ele:  # 如果用户指定元素
-        if isinstance(ele, str):  # 单个元素符号，例如 'Fe'
-            ele_list = np.array(ele, dtype="str")
-            location = np.where(Elements == ele_list)[0]
-        # 多个元素符号组成的列表，例如 ['Fe', 'O']
-        elif isinstance(ele, list) or isinstance(ele, np.ndarray):
-            for e in ele:
-                loc = np.where(Elements == e)[0]
-                location.append(loc)
-            location = np.concatenate(location)
-        else:
-            raise TypeError("请输入正确的元素或元素列表")
-        elements = Elements[location]
-
-    elif ai:  # 如果用户指定原子序号
-        if isinstance(ai, int):  # 1
-            ais = [ai]
-        elif isinstance(ai, list) or isinstance(ai, np.ndarray):  # [1,2,3]
-            ais = ai
-        elif isinstance(ai, str):  # ':', '-3:'
-            ais = _parse_indices(ai, Total_step)
-        else:
-            raise ValueError("请输入正确格式的ai")
-        ais = [i - 1 for i in ais]  # python从0开始计数，但是用户从1开始计数
-        elements = Elements[ais]
-        location = ais
-
-    else:  # 如果都没指定
-        elements = Elements
-        location = list(range(len(Elements)))
-
-    elements = elements.tolist()  # for pretty output
-
-    if return_scaled:
-        scaled_positions = np.empty(shape=(len(indices), len(elements), 3))
-        for i, index in enumerate(indices):  # 步数
-            lats = np.array(hf.get("/Structures/Step-" + str(index) + "/Lattice"))
-            lattices[i] = lats
-            # [x1,y1,z1,x2,y2,z2,x3,y3,z3], ...
-            # 结构优化时输出的都是分数坐标，不管CoordinateType写的是啥！
-            spos = np.array(hf.get("/Structures/Step-" + str(index) + "/Position"))
-            wrapped_spos = spos - np.floor(spos)  # wrap into [0,1)
-            wrapped_spos = wrapped_spos.flatten().reshape(-1, 3).T  # reshape
-            for j, sli in enumerate(location):
-                scaled_positions[i, j, :] = np.dot(wrapped_spos[:, sli], np.eye(3, 3))
-        return Nstep, elements, scaled_positions, lattices
-
-    else:
-        # Nstep x Natom x 3
-        positions = np.empty(shape=(len(indices), len(elements), 3))
-        for i, index in enumerate(indices):  # 步数
-            lats = np.array(hf.get("/Structures/Step-" + str(index) + "/Lattice"))
-            lattices[i] = lats
-            # [x1,y1,z1,x2,y2,z2,x3,y3,z3], ...
-            # 结构优化时输出的都是分数坐标，不管CoordinateType写的是啥！
-            spos = np.array(hf.get("/Structures/Step-" + str(index) + "/Position"))
-            wrapped_spos = spos - np.floor(spos)  # wrap into [0,1)
-            wrapped_spos = wrapped_spos.flatten().reshape(-1, 3).T  # reshape
-            for j, sli in enumerate(location):
-                positions[i, j, :] = np.dot(wrapped_spos[:, sli], lats)
-
-        return Nstep, elements, positions, lattices
-
-
-# 2. 写轨迹文件
-def write_xyz_traj(
-    datafile="aimd.h5",
-    ai=None,
-    ele=None,
-    index=None,
-    xyzfile="aimdTraj.xyz",
-):
-    """保存xyz格式的轨迹文件
-
-    Parameters
-    ----------
-    datafile : str or list
-        DSPAW计算完成后保存的h5/json文件或包含它们的文件夹路径
-    ai : int
-        原子编号列表（体系中的第几号原子，不是质子数）
-    ele : str
-        元素，例如 'C'，'H'，'O'，'N'
-    index : int
-        优化过程中的第几步
-
-    Returns
-    -------
-    xyzfile: str
-        写入xyz格式的轨迹文件，默认为aimdTraj.xyz
-
-    Example
-    -------
-    >>> from dspawpy.analysis.aimdtools import write_xyz_traj
-    >>> write_xyz_traj(datafile='aimd.h5', ai=[1,2,3], index=1, xyzfile='aimdTraj.xyz')
-    """
-    if isinstance(datafile, list):
-        for i, df in enumerate(datafile):
-            write_xyz_traj(df, ai, ele, index, str(i+1)+xyzfile)
-        return f"{xyzfile} 文件已保存！"
-    # search datafile in the given directory
-    elif os.path.isdir(datafile):
-        directory = datafile  # specified datafile is actually a directory
-        print("您指定了一个文件夹，正在查找相关h5或json文件...")
-        if os.path.exists(os.path.join(directory, "aimd.h5")):
-            datafile = os.path.join(directory, "aimd.h5")
-            print("Reading aimd.h5...")
-        elif os.path.exists(os.path.join(directory, "aimd.json")):
-            datafile = os.path.join(directory, "aimd.json")
-            print("Reading aimd.json...")
-        else:
-            raise FileNotFoundError("未找到aimd.h5/aimd.json文件！")
-    if datafile.endswith(".h5"):
-        Nstep, eles, poses, lats = read_h5(datafile, index, ele, ai)
-    elif datafile.endswith(".json"):
-        Nstep, eles, poses, lats = _read_json(datafile, index, ele, ai)
-    else:
-        raise TypeError("仅支持读取h5或json文件！")
-    
-    # 写入文件
-    with open(xyzfile, "w") as f:
-        # Nstep
-        for n in range(Nstep):
-            # 原子数不会变，就是不合并的元素总数
-            f.write("%d\n" % len(eles))
-            # lattice
-            f.write(
-                'Lattice="%f %f %f %f %f %f %f %f %f" Properties=species:S:1:pos:R:3 pbc="T T T"\n'
-                % (
-                    lats[n, 0, 0],
-                    lats[n, 0, 1],
-                    lats[n, 0, 2],
-                    lats[n, 1, 0],
-                    lats[n, 1, 1],
-                    lats[n, 1, 2],
-                    lats[n, 2, 0],
-                    lats[n, 2, 1],
-                    lats[n, 2, 2],
-                )
-            )
-            # position and element
-            for i in range(len(eles)):
-                f.write(
-                    "%s %f %f %f\n"
-                    % (eles[i], poses[n, i, 0], poses[n, i, 1], poses[n, i, 2])
-                )
-    print(f"{xyzfile} 文件已保存！")
-
-
-def write_dump_traj(
-    datafile="aimd.h5",
-    ai=None,
-    ele=None,
-    index=None,
-    dumpfile="aimdTraj.dump",
-):
-    """保存为lammps的dump格式的轨迹文件，暂时只支持正交晶胞
-
-    Parameters
-    ----------
-    datafile : str or list
-        DSPAW计算完成后保存的h5/json文件或包含它们的文件夹路径
-    ai : int
-        原子编号列表（体系中的第几号原子，不是质子数）
-    ele : str
-        元素，例如 'C'，'H'，'O'，'N'
-    index : int
-        优化过程中的第几步
-
-    Returns
-    -------
-    dumpfile: str
-        写入dump格式的轨迹文件，默认为aimdTraj.dump
-
-    Example
-    -------
-    >>> from dspawpy.analysis.aimdtools import write_dump_traj
-    >>> write_dump_traj(datafile='aimd.h5', ai=[1,2,3], index=1, dumpfile='aimdTraj.dump')
-    """
-    if isinstance(datafile, list):
-        for i, df in enumerate(datafile):
-            write_dump_traj(df, ai, ele, index, str(i+1)+dumpfile)
-        return f"{dumpfile} 文件已保存！"
-    # search datafile in the given directory
-    elif os.path.isdir(datafile):
-        directory = datafile  # specified datafile is actually a directory
-        print("您指定了一个文件夹，正在查找相关h5或json文件...")
-        if os.path.exists(os.path.join(directory, "aimd.h5")):
-            datafile = os.path.join(directory, "aimd.h5")
-            print("Reading aimd.h5...")
-        elif os.path.exists(os.path.join(directory, "aimd.json")):
-            datafile = os.path.join(directory, "aimd.json")
-            print("Reading aimd.json...")
-        else:
-            raise FileNotFoundError("未找到aimd.h5/aimd.json文件！")
-    if datafile.endswith(".h5"):
-        Nstep, eles, poses, lats = read_h5(datafile, index, ele, ai)
-    elif datafile.endswith(".json"):
-        Nstep, eles, poses, lats = _read_json(datafile, index, ele, ai)
-    else:
-        raise TypeError("仅支持读取h5或json文件！")
-
-    # 写入文件
-    with open(dumpfile, "w") as f:
-        for n in range(Nstep):
-            box_bounds = _get_lammps_non_orthogonal_box(lats[n])
-            f.write("ITEM: TIMESTEP\n%d\n" % n)
-            f.write("ITEM: NUMBER OF ATOMS\n%d\n" % (len(eles)))
-            f.write("ITEM: BOX BOUNDS xy xz yz xx yy zz\n")
-            f.write(
-                "%f %f %f\n%f %f %f\n %f %f %f\n"
-                % (
-                    box_bounds[0][0],
-                    box_bounds[0][1],
-                    box_bounds[0][2],
-                    box_bounds[1][0],
-                    box_bounds[1][1],
-                    box_bounds[1][2],
-                    box_bounds[2][0],
-                    box_bounds[2][1],
-                    box_bounds[2][2],
-                )
-            )
-            f.write("ITEM: ATOMS type x y z id\n")
-            for i in range(len(eles)):
-                f.write(
-                    "%s %f %f %f %d\n"
-                    % (eles[i], poses[n, i, 0], poses[n, i, 1], poses[n, i, 2], i + 1)
-                )
-    print(f"{dumpfile} 文件已保存！")
-
-def _get_structure_list(df: str = "aimd.h5") -> List[Structure]:
-    """get pymatgen structures from single datafile
-
-    Parameters
-    ----------
-    df : str, optional
-        datafile, by default "aimd.h5"
-
-    Returns
-    -------
-    List[Structure] : list of pymatgen structures
-
-    Examples
-    --------
-    >>> from dspawpy.analysis.aimdtools import get_structure_list
-    >>> structure_list = get_structure_list(df='aimd.h5')
-    """
-    if df.endswith(".h5"):
-        # create Structure structure_list from aimd.h5
-        Nstep, elements, positions, lattices = read_h5(df)
-        strs = []
-        for i in range(Nstep):
-            strs.append(
-                Structure(
-                    lattices[i], elements, positions[i], coords_are_cartesian=False
-                )
-            )
-    elif df.endswith(".json"):
-        from dspawpy.io.read import json2structures
-
-        strs = json2structures(df)
-    else:
-        raise ValueError(f"{df} file format not supported")
-
-    return strs
-
-
-def _get_neighbor_list(structure, r) -> Tuple:
-    """Thin wrapper to enable parallel calculations
-
-    Parameter
-    ---------
-    structure (pymatgen Structure): pymatgen structure
-    r (float): cutoff radius
-
-    Returns
-    --------
-    tuple of neighbor list
-    """
-    return structure.get_neighbor_list(r)
-
-
-def _parse_indices(index: str, total_step) -> list:
-    """解析用户输入的原子序号字符串
-
-    输入：
-        - index: 用户输入的原子序号/元素字符串，例如 '1:3,5,7:10'
-    输出：
-        - indices: 解析后的原子序号列表，例如 [1,2,3,4,5,6,7,8,9,10]
-    """
-    assert ":" in index, "如果不想切片索引，请输入整数或者列表"
-    blcs = index.split(",")
-    indices = []
-    for blc in blcs:
-        if ":" in blc:  # 切片
-            low = blc.split(":")[0]
-            if not low:
-                low = 1  # 从1开始
-            else:
-                low = int(low)
-                assert low > 0, "索引从1开始！"
-            high = blc.split(":")[1]
-            if not high:
-                high = total_step
-            else:
-                high = int(high)
-                assert high <= total_step, "索引超出范围！"
-
-            for i in range(low, high + 1):
-                indices.append(i)
-        else:  # 单个数字
-            indices.append(int(blc))
-    return indices
-
-
-def _read_json(
-    jpath: str,
-    index= None,
-    ele = None,
-    ai= None,
-):
-    """从json指定的路径读取数据
-
-    输入:
-    - jpath: json文件路径
-    - ai: 原子序号（体系中的第几个原子，不是质子数）
-    - ele: 元素，例如 'C'，'H'，'O'，'N'
-    - index: 运动轨迹中的第几步，从1开始
-
-    输出：
-    - Nstep: 总共要保存多少步的信息, int
-    - elements: 元素列表, list, Natom x 1
-    - positions: 原子位置, list, Nstep x Natom x 3
-    - lattices: 晶胞, list, Nstep x 3 x 3
-    """
-    import json
-
-    with open(jpath, "r") as f:
-        data = json.load(f)  # 加载json文件
-
-    Total_step = len(data["Structures"])  # 总步数
-
-    if ele and ai:
-        raise ValueError("暂不支持同时指定元素和原子序号")
-    # 步数
-    if index:
-        if isinstance(index, int):  # 1
-            indices = [index]
-
-        elif isinstance(index, list) or isinstance(ai, np.ndarray):  # [1,2,3]
-            indices = index
-
-        elif isinstance(index, str):  # ':', '-3:'
-            indices = _parse_indices(index, Total_step)
-
-        else:
-            raise ValueError("请输入正确格式的index")
-
-        Nstep = len(indices)
-    else:
-        Nstep = Total_step
-        indices = list(range(1, Nstep + 1))  # [1,Nstep+1)
-
-    # 预先读取全部元素的总列表，这个列表不会随步数改变，也不会“合并同类项”
-    # 这样可以避免在循环内部频繁判断元素是否符合用户需要
-
-    Nele = len(data["Structures"][0]["Atoms"])  # 总元素数量
-    total_elements = np.empty(shape=(Nele), dtype="str")  # 未合并的元素列表
-    for i in range(Nele):
-        element = data["Structures"][0]["Atoms"][i]["Element"]
-        total_elements[i] = element
-
-    # 开始读取晶胞和原子位置
-    # 在data['Structures']['%d' % index]['Atoms']中根据元素所在序号选择结构
-    if ele:  # 用户指定要某些元素
-        location = []
-        if isinstance(ele, str):  # 单个元素符号，例如 'Fe'
-            ele_list = list(ele)
-        # 多个元素符号组成的列表，例如 ['Fe', 'O']
-        elif isinstance(ele, list) or isinstance(ele, np.ndarray):
-            ele_list = ele
-        else:
-            raise TypeError("请输入正确的元素或元素列表")
-        for e in ele_list:
-            location.append(np.where(total_elements == e)[0])
-        location = np.concatenate(location)
-
-    elif ai:  # 如果用户指定原子序号，也要据此筛选元素列表
-        if isinstance(ai, int):  # 1
-            ais = [ai]
-        elif isinstance(ai, list) or isinstance(ai, np.ndarray):  # [1,2,3]
-            ais = ai
-        elif isinstance(ai, str):  # ':', '-3:'
-            ais = _parse_indices(ai, Total_step)
-        else:
-            raise ValueError("请输入正确格式的ai")
-        ais = [i - 1 for i in ais]  # python从0开始计数，但是用户从1开始计数
-        location = ais
-        # read lattices and poses
-
-    else:  # 如果都没指定
-        location = list(range(Total_step))
-
-    # 满足用户需要的elements列表
-    elements = np.empty(shape=len(location), dtype="str")
-    for i in range(len(location)):
-        elements[i] = total_elements[location[i]]
-
-    # Nstep x Natom x 3
-    positions = np.empty(shape=(len(indices), len(elements), 3))
-    lattices = np.empty(shape=(Nstep, 3, 3))  # Nstep x 3 x 3
-    for i, index in enumerate(indices):  # 步数
-        lat = data["Structures"][index - 1]["Lattice"]
-        lattices[i] = np.array(lat).reshape(3, 3)
-        for j, sli in enumerate(location):
-            positions[i, j, :] = data["Structures"][index - 1]["Atoms"][sli][
-                "Position"
-            ][:]
-
-    return Nstep, elements, positions, lattices
-
-
-def _get_lammps_non_orthogonal_box(lat: np.ndarray):
-    """计算用于输入lammps的盒子边界参数
-
-    Parameters
-    ----------
-    lat : np.ndarray
-        常见的非三角3x3矩阵
-
-    Returns
-    -------
-    box_bounds:
-        用于输入lammps的盒子边界
-    """
-    # https://docs.lammps.org/Howto_triclinic.html
-    A = lat[0]
-    B = lat[1]
-    C = lat[2]
-    assert np.cross(A, B).dot(C) > 0, "Lat is not right handed"
-
-    # 将常规3x3矩阵转成标准的上三角矩阵
-    alpha = np.arccos(np.dot(B, C) / (np.linalg.norm(B) * np.linalg.norm(C)))
-    beta = np.arccos(np.dot(A, C) / (np.linalg.norm(A) * np.linalg.norm(C)))
-    gamma = np.arccos(np.dot(A, B) / (np.linalg.norm(A) * np.linalg.norm(B)))
-
-    ax = np.linalg.norm(A)
-    a = np.array([ax, 0, 0])
-
-    bx = np.linalg.norm(B) * np.cos(gamma)
-    by = np.linalg.norm(B) * np.sin(gamma)
-    b = np.array([bx, by, 0])
-
-    cx = np.linalg.norm(C) * np.cos(beta)
-    cy = (np.linalg.norm(B) * np.linalg.norm(C) - bx * cx) / by
-    cz = np.sqrt(abs(np.linalg.norm(C) ** 2 - cx**2 - cy**2))
-    c = np.array([cx, cy, cz])
-
-    # triangluar matrix in lammmps cell format
-    # note that in OVITO, it will be down-triangular one
-    # lammps_lattice = np.array([a,b,c]).T
-
-    # write lammps box parameters
-    # https://docs.lammps.org/Howto_triclinic.html#:~:text=The%20inverse%20relationship%20can%20be%20written%20as%20follows
-    lx = np.linalg.norm(a)
-    xy = np.linalg.norm(b) * np.cos(gamma)
-    xz = np.linalg.norm(c) * np.cos(beta)
-    ly = np.sqrt(np.linalg.norm(b) ** 2 - xy**2)
-    yz = (np.linalg.norm(b) * np.linalg.norm(c) * np.cos(alpha) - xy * xz) / ly
-    lz = np.sqrt(np.linalg.norm(c) ** 2 - xz**2 - yz**2)
-
-    # "The parallelepiped has its “origin” at (xlo,ylo,zlo) and is defined by 3 edge vectors starting from the origin given by a = (xhi-xlo,0,0); b = (xy,yhi-ylo,0); c = (xz,yz,zhi-zlo)."
-    # 令原点在(0,0,0)，则 xlo = ylo = zlo = 0
-    xlo = ylo = zlo = 0
-    # https://docs.lammps.org/Howto_triclinic.html#:~:text=the%20LAMMPS%20box%20sizes%20(lx%2Cly%2Clz)%20%3D%20(xhi%2Dxlo%2Cyhi%2Dylo%2Czhi%2Dzlo)
-    xhi = lx + xlo
-    yhi = ly + ylo
-    zhi = lz + zlo
-    # https://docs.lammps.org/Howto_triclinic.html#:~:text=This%20bounding%20box%20is%20convenient%20for%20many%20visualization%20programs%20and%20is%20calculated%20from%20the%209%20triclinic%20box%20parameters%20(xlo%2Cxhi%2Cylo%2Cyhi%2Czlo%2Czhi%2Cxy%2Cxz%2Cyz)%20as%20follows%3A
-    xlo_bound = xlo + np.min([0, xy, xz, xy + xz])
-    xhi_bound = xhi + np.max([0, xy, xz, xy + xz])
-    ylo_bound = ylo + np.min([0, yz])
-    yhi_bound = yhi + np.max([0, yz])
-    zlo_bound = zlo
-    zhi_bound = zhi
-    box_bounds = np.array(
-        [
-            [xlo_bound, xhi_bound, xy],
-            [ylo_bound, yhi_bound, xz],
-            [zlo_bound, zhi_bound, yz],
-        ]
-    )
-
-    return box_bounds
```

## dspawpy/diffusion/neb.py

```diff
@@ -1,18 +1,20 @@
 # -*- coding: utf-8 -*-
 import json
 import os
 from typing import List
-import numpy as np
+
 import matplotlib.pyplot as plt
-from scipy.interpolate import interp1d
+import numpy as np
 from pymatgen.core import Structure
+from scipy.interpolate import interp1d
+
+from dspawpy.diffusion.pathfinder import IDPPSolver
 from dspawpy.io.read import load_h5
 from dspawpy.io.structure import to_file
-from dspawpy.diffusion.pathfinder import IDPPSolver
 
 
 class NEB:
     """
 
     Parameters
     ----------
@@ -41,15 +43,17 @@
             initial_structure:
             final_structure:
             nimages: number of images,contain initial and final structure
         """
 
         self.nimages = nimages
         self.iddp = IDPPSolver.from_endpoints(
-            endpoints=[initial_structure, final_structure], nimages=self.nimages - 2, sort_tol=0 # 锁定原子编号
+            endpoints=[initial_structure, final_structure],
+            nimages=self.nimages - 2,
+            sort_tol=0,  # 锁定原子编号
         )
 
     def linear_interpolate(self):
         return self.iddp.structures
 
     def idpp_interpolate(
         self,
```

## dspawpy/diffusion/nebtools.py

```diff
@@ -1,17 +1,20 @@
+import json
 import os
+
 import h5py
-import json
-import pandas as pd
 import numpy as np
+import pandas as pd
 
 np.set_printoptions(suppress=True)  # 不使用科学计数法
-from dspawpy.io.utils import get_pos_ele_lat, get_ele_from_h5, get_spo_ele_lat
 import matplotlib.pyplot as plt
 
+from dspawpy.io.read import pel_from_as
+from dspawpy.io.utils import get_ele_from_h5
+
 
 def get_distance(
     spo1: np.ndarray, spo2: np.ndarray, lat1: np.ndarray, lat2: np.ndarray
 ):
     """根据两个结构的分数坐标和晶胞计算距离
 
     Parameters
@@ -236,15 +239,15 @@
     ynew = inter_f(xnew)
 
     if raw:
         pd.DataFrame({"x_raw": rcs, "y_raw": dEs}).to_csv("raw_xy.csv", index=False)
         pd.DataFrame({"x_interpolated": xnew, "y_interpolated": ynew}).to_csv(
             "raw_interpolated_xy.csv", index=False
         )
-        
+
     # plot
     if kwargs:
         plt.plot(xnew, ynew, label=method + str(kwargs))
     else:
         plt.plot(xnew, ynew, label=method)
     plt.scatter(rcs, dEs, c="r")
     plt.xlabel("Reaction Coordinate (Å)")
@@ -542,15 +545,15 @@
     """
     # 1. 绘制能垒图
     print("--> 1. 打印NEB计算时各构型的能量和受力...")
     printef(directory)
 
     # 2. 打印各构型受力、反应坐标、能量、与初始构型的能量差
     print("\n--> 2. 绘制能垒图...")
-    plt.clf() # 清空画布再画图
+    plt.clf()  # 清空画布再画图
     plot_barrier(directory=directory, raw=raw, **kwargs)
 
     # 3. 绘制并保存结构优化过程的能量和受力收敛过程图到各构型文件夹中
     print("\n--> 3. 绘制收敛过程图到各构型文件夹中...")
     subfolders = get_neb_subfolders(directory)
     for subfolder in subfolders[1 : len(subfolders) - 1]:
         print(f"----> {subfolder}/converge.png...")
@@ -612,25 +615,27 @@
                 print("未找到初始插值结构，将从计算结果h5或json文件中读取！")
             except Exception as e:
                 print("初始插值结构读取失败！", e)
         else:
             try:  # read from h5 file
                 raw = _from_h5(directory, step)
             except FileNotFoundError:
-                try:  # read from json file
-                    raw = _from_json(directory, step)
-                except json.decoder.JSONDecodeError:
-                    print("json文件格式错误！")
-                except Exception as e:
-                    print(e)
+                raw = _from_json(directory, step)
+                # try:  # read from json file
+                #     raw = _from_json(directory, step)
+                # except json.decoder.JSONDecodeError:
+                #     print("json文件格式错误！")
+                # except Exception as e:
+                #     print(e)
             except Exception as e:
                 print("h5文件内容读取失败！", e)
     _dump_neb_movie_json(raw)
 
-def write_xyz(preview:bool=False, directory:str='.', step:int=-1):
+
+def write_xyz(preview: bool = False, directory: str = ".", step: int = -1):
     """
     将NEB结构链条写成xyz轨迹文件用于可视化
 
     Parameters
     ----------
     preview : bool
         是否预览模式，默认否
@@ -675,40 +680,41 @@
                     print("json文件格式错误！")
                 except Exception as e:
                     print(e)
             except Exception as e:
                 print("h5文件内容读取失败！", e)
     _dump_neb_xyz(raw)
 
+
 def _dump_neb_xyz(raw):
     """根据之前收集到的各数据列表，dump json文件到output"""
     (
         output,
         subfolders,
         step,
         MaxForces,
         TotalEnergies,
-        Poses, # Nimage x Natom x 3 , read
-        Latvs, # Nimage x 9
-        Elems, # Nimage x Natom
-        Fixs, # Natom x 3
+        Poses,  # Nimage x Natom x 3 , read
+        Latvs,  # Nimage x 9
+        Elems,  # Nimage x Natom
+        Fixs,  # Natom x 3
         reactionCoordinates,
         totalEnergies,
         maxForces,
         tangents,
-        iDirects
+        iDirects,
     ) = raw
 
     # 写入文件
-    xyzfile = output[:-5] + '.xyz'
-    Nstep = len(subfolders) # 选定离子步，展示构型链
+    xyzfile = output[:-5] + ".xyz"
+    Nstep = len(subfolders)  # 选定离子步，展示构型链
     with open(xyzfile, "w") as f:
         # Nstep
         for n in range(Nstep):
-            eles = Elems[n] # 针对每个构型
+            eles = Elems[n]  # 针对每个构型
             # 原子数不会变，就是不合并的元素总数
             f.write("%d\n" % len(eles))
             # lattice
             f.write(
                 'Lattice="%f %f %f %f %f %f %f %f %f" Properties=species:S:1:pos:R:3 pbc="T T T"\n'
                 % (
                     Latvs[n, 0],
@@ -726,14 +732,15 @@
             for i in range(len(eles)):
                 f.write(
                     "%s %f %f %f\n"
                     % (eles[i], Poses[n, i, 0], Poses[n, i, 1], Poses[n, i, 2])
                 )
     print(f"--> {os.path.abspath(xyzfile)} 写入成功！\n")
 
+
 def _from_structures(directory: str):
     """从structure00.as，structure01.as，...，中读取结构信息，
     写入neb_movie_init，以便用DeviceStudio打开观察
 
     Parameters
     ----------
     directory : str
@@ -756,20 +763,20 @@
     MaxForces = np.zeros(shape=(nimage - 2, step + 1))  # optional
     TotalEnergies = np.zeros(shape=(nimage - 2, step + 1))  # optional
 
     Poses = []  # nimage x Natom x 3 , read
     Elems = []  # nimage x Natom, read
     Latvs = []  # nimage x 9, read
 
-    iDirects = [] # read coordinate type
+    iDirects = []  # read coordinate type
     for i, folder in enumerate(subfolders):
         structure_path = os.path.join(directory, folder, f"structure{folder}.as")
         if not os.path.exists(structure_path):
             raise FileNotFoundError(f"请检查{structure_path}是否存在！")
-        pos, ele, lat = get_pos_ele_lat(structure_path)
+        pos, ele, lat = pel_from_as(structure_path)
         Poses.append(pos)
         Elems.append(ele)
         Latvs.append(lat)
         with open(structure_path, "r") as f:
             lines = f.readlines()
             coordinateType = lines[6].split()[0]
             if coordinateType == "Direct":
@@ -797,20 +804,20 @@
         Latvs,
         Elems,
         Fixs,
         reactionCoordinates,
         totalEnergies,
         maxForces,
         tangents,
-        iDirects
+        iDirects,
     )
 
 
 def _from_h5(directory: str, step: int):
-    """从NEB路径下的h5文件读取指定step数的结构和能量信息，
+    """从NEB路径下的h5文件读取 从第一步开始到指定step数 的结构和能量信息，
     写入json文件，以便用DeviceStudio打开观察。
 
     支持热读取结构信息（其他信息忽略）
 
     Parameters
     ----------
     directory : str
@@ -819,15 +826,15 @@
         step数，默认-1，读取最后一个构型
 
     Returns
     -------
     用于json文件的各个数组
     """
     # ^ 前期设置
-    neb_h5 = os.path.join(directory, '01', 'neb01.h5')
+    neb_h5 = os.path.join(directory, "01", "neb01.h5")
     ele = get_ele_from_h5(hpath=neb_h5)
     Natom = len(ele)
     data = h5py.File(neb_h5)
     try:
         total_steps = np.array(data.get("/NebSize"))[0]
     except:
         print("NEB计算未正常结束，正在尝试实时读取结构信息...")
@@ -868,61 +875,71 @@
         """如果是首尾两个构型，最多只有scf.h5文件，没有neb.h5文件
         用户如果算NEB的时候，不计算首尾构型的自洽，
          或者在别处算完了但是没有复制到首尾文件夹中并命名为scf.h5，
           便不能使用第一个功能
         """
         if folder == subfolders[0] or folder == subfolders[-1]:
             h5_path = os.path.join(directory, folder, "scf.h5")
-            spath = os.path.join(directory, folder, f'structure{folder}.as')
-            assert os.path.exists(h5_path) or os.path.exists(spath), f"请确认{h5_path}或{spath}至少存在一个！"
+            spath = os.path.join(directory, folder, f"structure{folder}.as")
+            assert os.path.exists(h5_path) or os.path.exists(
+                spath
+            ), f"请确认{h5_path}或{spath}至少存在一个！"
         else:
             h5_path = os.path.join(directory, folder, f"neb{folder}.h5")
             assert os.path.exists(h5_path), f"请确认{h5_path}是否存在！"
 
     # ^ 开始分功能读取数据
     for i, folder in enumerate(subfolders):
         if folder == subfolders[0] or folder == subfolders[-1]:
             h5_path = os.path.join(directory, folder, "scf.h5")
             if os.path.exists(h5_path):
                 data = h5py.File(h5_path)
                 # 不影响可视化，直接定为0
                 if folder == subfolders[0]:
                     reactionCoordinates[i] = 0
-                pos = np.array(data.get("/Structures/Step-1/Position")).reshape(-1,3)  # scaled
+                pos = np.array(data.get("/Structures/Step-1/Position")).reshape(
+                    -1, 3
+                )  # scaled
                 lat = np.array(data.get("/Structures/Step-1/Lattice"))
                 ele = get_ele_from_h5(hpath=h5_path)
                 totalEnergies[i] = np.array(data.get("/Energy/TotalEnergy0"))
             else:
-                pos, ele, lat = get_spo_ele_lat(spath)
+                pos, ele, lat = pel_from_as(spath, scaled=True)
         else:
             h5_path = os.path.join(directory, folder, f"neb{folder}.h5")
             data = h5py.File(h5_path)
             # reading...
             try:
-                reactionCoordinates[i - 1] = np.array(data.get("/Distance/Previous"))[-1]
+                reactionCoordinates[i - 1] = np.array(data.get("/Distance/Previous"))[
+                    -1
+                ]
                 maxForces[i - 1] = np.array(data.get("/MaxForce"))[-1]
                 tangents[i - 1] = np.array(data.get("/Tangent"))[-1]
                 if folder == subfolders[-2]:
-                    reactionCoordinates[i + 1] = np.array(data.get("/Distance/Next"))[-1]
+                    reactionCoordinates[i + 1] = np.array(data.get("/Distance/Next"))[
+                        -1
+                    ]
                 # read MaxForces and TotalEnergies
                 nionStep = np.array(data.get("/MaxForce")).shape[0]
                 assert step <= nionStep, f"总共只完成了{nionStep}个离子步!"
                 for j in range(step):
                     MaxForces[i - 1, j] = np.array(data.get("/MaxForce"))[j]
                     TotalEnergies[i - 1, j] = np.array(data.get("/TotalEnergy"))[j]
                 totalEnergies[i] = np.array(data.get("/Energy/TotalEnergy0"))
             except:
-                pass # 还没完成NEB计算，不影响读取结构信息用于可视化
+                pass  # 还没完成NEB计算，不影响读取结构信息用于可视化
             # read the latest structure for visualization
-            pos = np.array(data.get(f"/Structures/Step-{step}/Position")).reshape(Natom,3)  # scaled
+            pos = np.array(data.get(f"/Structures/Step-{step}/Position")).reshape(
+                Natom, 3
+            )  # scaled
             lat = np.array(data.get(f"/Structures/Step-{step}/Lattice"))
             ele = get_ele_from_h5(hpath=h5_path)
 
         Elems.append(ele)
-        Sposes[i,:,:] = pos
+        Sposes[i, :, :] = pos
         Latvs.append(lat)
 
     if os.path.exists(os.path.join(directory, "neb.h5")):
         tdata = h5py.File(os.path.join(directory, "neb.h5"))
         # atom fix, not lattice
         # ignore this trivial message because it is not necessary for the visualization
         if "/UnrelaxStructure/Image00/Fix" in tdata:
@@ -939,15 +956,15 @@
             Fixs = np.full(shape=(Natom, 3), fill_value=False)
     else:
         Fixs = np.full(shape=(Natom, 3), fill_value=False)
 
     Elems = np.array(Elems).reshape((nimage, Natom))
     Latvs = np.array(Latvs).reshape((nimage, 9))
     Fixs = np.array(Fixs).reshape((Natom, 3))
-    iDirects = [True for i in range(Natom)] # only output direct coordinates
+    iDirects = [True for i in range(Natom)]  # only output direct coordinates
 
     return (
         output,
         subfolders,
         step,
         MaxForces,
         TotalEnergies,  #
@@ -955,20 +972,20 @@
         Latvs,
         Elems,
         Fixs,
         reactionCoordinates,
         totalEnergies,
         maxForces,
         tangents,
-        iDirects
+        iDirects,
     )
 
 
 def _from_json(directory: str, step: int):
-    """从NEB路径下的json文件读取指定step数的结构和能量信息，
+    """从NEB路径下的json文件读取 从第一步开始到指定step数 的结构和能量信息，
     写入json文件，以便用DeviceStudio打开观察
 
     Parameters
     ----------
     directory : str
         NEB路径，默认当前路径
     step : int
@@ -1059,37 +1076,38 @@
             # 读取晶胞矢量、原子坐标
             relax_json = os.path.join(directory, folder, "relax.json")
             assert os.path.exists(relax_json), f"{relax_json}不存在！"
 
             with open(relax_json, "r") as f:
                 rdata = json.load(f)
 
-            lat = rdata[step]["Lattice"]  # 第step步优化后的晶胞
+            lat = rdata[step - 1]["Lattice"]  # 第step步优化后的晶胞
             Latvs.append(lat)
 
             Natom = len(rdata[0]["Atoms"])
             for j in range(Natom):  # for each atom
-                pos = rdata[step]["Atoms"][j]["Position"]  # 第step步优化后的原子坐标
+                pos = rdata[step - 1]["Atoms"][j]["Position"]  # 第step步优化后的原子坐标
                 Sposes.append(pos)  # ! 输出的都是分数坐标
 
             # 读取能量和反应坐标
             nj = os.path.join(directory, folder, f"neb{folder}.json")
             with open(nj, "r") as f:
+                print(f"Reading {os.path.abspath(nj)}...")
                 ndata = json.load(f)
 
-            totalEnergies[i] = ndata[step]["TotalEnergy"]  # 读取第step步优化后的能量
+            totalEnergies[i] = ndata[step - 1]["TotalEnergy"]  # 读取第step步优化后的能量
 
             # 读取与前一个构型相比的反应坐标
-            reactionCoordinates[i - 1] = ndata[step]["ReactionCoordinate"][-2]
-            tangents[i - 1] = ndata[step]["Tangent"]
+            reactionCoordinates[i - 1] = ndata[step - 1]["ReactionCoordinate"][-2]
+            tangents[i - 1] = ndata[step - 1]["Tangent"]
             if folder == subfolders[-2]:  # 末态前一个构型的计算结果中读取反应坐标
-                reactionCoordinates[i + 1] = ndata[step]["ReactionCoordinate"][-1]
-            for j in range(step + 1):
+                reactionCoordinates[i + 1] = ndata[step - 1]["ReactionCoordinate"][-1]
+            for j in range(step):
                 MaxForces[i - 1, j] = ndata[j]["MaxForce"]
-                # TODO neb01.json中不存在TotalEnergy0，暂时读取TotalEnergy
+                # neb01.json中不存在TotalEnergy0，暂时读取TotalEnergy
                 TotalEnergies[i - 1, j] = ndata[j]["TotalEnergy"]
 
         else:  # 末态构型
             js_path = os.path.join(directory, folder, "system.json")
             neb_js_path = os.path.join(directory, folder, f"system{folder}.json")
             if os.path.exists(neb_js_path):  # 优先读取neb计算得到的json文件
                 with open(neb_js_path, "r") as f:
@@ -1147,15 +1165,15 @@
         reactionCoordinates[i] += reactionCoordinates[i - 1]
 
     # reshape data
     Sposes = np.array(Sposes).reshape((nimage, Natom, 3))
     Elems = np.array(Elems).reshape((nimage, Natom))
     Latvs = np.array(Latvs).reshape((nimage, 9))
     Fixs = np.array(Fixs).reshape((Natom, 3))
-    iDirects = [True for i in range(Natom)] # only output direct coordinates
+    iDirects = [True for i in range(Natom)]  # only output direct coordinates
 
     return (
         output,
         subfolders,
         step,
         MaxForces,
         TotalEnergies,
@@ -1183,15 +1201,15 @@
         Latvs,
         Elems,
         Fixs,
         reactionCoordinates,
         totalEnergies,
         maxForces,
         tangents,
-        iDirects
+        iDirects,
     ) = raw
 
     IterDict = {}
     for s, sf in enumerate(subfolders):
         if sf == subfolders[0] or sf == subfolders[-1]:
             continue
         else:
@@ -1224,15 +1242,19 @@
                 "Position": pos[i].tolist(),
                 "Pot": "",
             }  # empty
             atoms.append(atom)
         if iDirects[s]:
             rs = {"Atoms": atoms, "CoordinateType": "Direct", "Lattice": lat.tolist()}
         else:
-            rs = {"Atoms": atoms, "CoordinateType": "Cartesian", "Lattice": lat.tolist()}
+            rs = {
+                "Atoms": atoms,
+                "CoordinateType": "Cartesian",
+                "Lattice": lat.tolist(),
+            }
         RSList.append(rs)
 
     URSList = []  # DS似乎并不读取这部分信息，空置即可
 
     data = {
         "Distance": {"ReactionCoordinate": reactionCoordinates.tolist()},
         "Energy": {"TotalEnergy": totalEnergies.tolist()},
```

## dspawpy/diffusion/pathfinder.py

```diff
@@ -1,14 +1,14 @@
 # -*- coding: utf-8 -*-
-import warnings
 import itertools
+import warnings
 
 import numpy as np
+from pymatgen.core import PeriodicSite, Structure
 from pymatgen.core.periodic_table import get_el_sp
-from pymatgen.core import Structure, PeriodicSite
 
 
 # copy from pymatgen-analysis-diffusion https://github.com/materialsvirtuallab/pymatgen-analysis-diffusion
 class IDPPSolver:
     """
     A solver using image dependent pair potential (IDPP) algo to get an improved
     initial NEB path. For more details about this algo, please refer to
@@ -192,15 +192,18 @@
             nimages (int): Number of images between the two end-points.
             sort_tol (float): Distance tolerance (in Angstrom) used to match the
                 atomic indices between start and end structures. Need
                 to increase the value in some cases.
         """
         try:
             images = endpoints[0].interpolate(
-                endpoints[1], nimages=nimages + 1, interpolate_lattices=True, autosort_tol=sort_tol
+                endpoints[1],
+                nimages=nimages + 1,
+                interpolate_lattices=True,
+                autosort_tol=sort_tol,
             )
         except Exception as e:
             if "Unable to reliably match structures " in str(e):
                 warnings.warn(
                     "Auto sorting is turned off because it is unable"
                     " to match the end-point structures!",
                     UserWarning,
```

## dspawpy/io/read.py

```diff
@@ -1,60 +1,599 @@
-# -*- coding: utf-8 -*-
+"""
+Functions to read properties from structure or output files
+"""
 
 import json
-import h5py
-from typing import List, Dict
+import os
+import re
 
+import h5py
 import numpy as np
-from pymatgen.core.structure import Structure
 from pymatgen.core.lattice import Lattice
-from pymatgen.electronic_structure.dos import Dos, CompleteDos
-from pymatgen.electronic_structure.core import Spin
-from pymatgen.electronic_structure.core import Orbital
+from pymatgen.core.structure import Structure
 from pymatgen.electronic_structure.bandstructure import BandStructureSymmLine
+from pymatgen.electronic_structure.core import Orbital, Spin
+from pymatgen.electronic_structure.dos import CompleteDos, Dos
 from pymatgen.phonon.bandstructure import PhononBandStructureSymmLine
 from pymatgen.phonon.dos import PhononDos
 
 
-def json2structures(jsonfile):
-    """relax.json/aimd.json -> [pymatgen.Structure]
+def get_lines_without_comment(filename: str, comment: str = "#"):
+    lines = []
+    """Filter out comment lines"""
+    with open(filename) as file:
+        while True:
+            line = file.readline()
+            if line:
+                line = re.sub(comment + r".*$", "", line)  # remove comment
+                line = line.strip()
+                if line:
+                    lines.append(line)
+            else:
+                break
+
+    return lines
+
+
+def get_ele_from_h5(hpath: str = "aimd.h5"):
+    """从h5文件中读取元素列表；
+    多离子步并不会在每个离子步的Structure中保存元素信息，只能读取初始结构的元素信息
 
     Parameters
     ----------
-    jsonfile : str
-        包含多个离子步的 json 文件路径，例如 "relax.json" 或 "aimd.json"
+    hpath : str
+        h5文件路径
 
     Returns
     -------
-    pymatgen_structures : list
-        pymatgen.Structure 列表
+    ele : list
+        元素列表, Natom x 1
 
     Examples
     --------
-    >>> from dspawpy.io.read import json2structures
-    >>> structures = json2structures("relax.json")
+    >>> from dspawpy.io.utils import get_ele_from_h5
+    >>> ele = get_ele_from_h5(hpath='aimd.h5')
+    ['H', 'H', 'O']
     """
-    with open(jsonfile, "r") as file:
-        j = json.load(file)
+    data = h5py.File(hpath)
+    Elements_bytes = np.array(data.get("/AtomInfo/Elements"))
+    tempdata = np.array([i.decode() for i in Elements_bytes])
+    ele = "".join(tempdata).split(";")
+
+    return ele
+
+
+def get_sinfo(datafile: str, scaled=False, index=None, ele=None, ai=None):
+    """Wrapper to get structure information from h5/json/as file
+
+    从datafile中读取结构信息
+
+    Parameters
+    ----------
+    datafile : str
+        h5文件或json结果文件路径
+    scaled : bool, optional
+        是否返回分数坐标，默认False
+    index : int or list or str, optional
+        运动轨迹中的第几步，从1开始计数
+        如果要切片，用字符串写法： '1, 10'
+        默认为None，返回所有步
+    ele : list, optional
+        元素列表, Natom x 1
+        默认为None，从h5文件中读取
+    ai : int or list or str, optional
+        多离子步中的第几个离子步，从1开始计数
+        如果要切片，用字符串写法： '1, 10'
+        默认为None，返回所有离子步
+
+    Returns
+    -------
+    Nstep : int
+        总离子步数（几个构型）
+    pos : np.ndarray
+        坐标分量数组，Natom x 3
+    ele : list
+        元素列表, Natom x 1
+    latv : np.ndarray
+        晶胞矢量数组，3 x 3
+    D_mag_fix : dict
+        磁矩、自由度相关信息
+
+    Examples
+    --------
+    >>> from dspawpy.io.read import get_sinfo
+    """
+    if datafile.endswith(".h5"):
+        assert os.path.exists(datafile), f"{os.path.abspath(datafile)} does not exist!"
+        Nstep, eles, pos, latv, D_mag_fix = _sinfo_from_h5(
+            hpath=datafile, index=index, ele=ele, ai=ai, return_scaled=scaled
+        )
+    elif datafile.endswith(".json"):
+        assert os.path.exists(datafile), f"{os.path.abspath(datafile)} does not exist!"
+        Nstep, eles, pos, latv, D_mag_fix = _sinfo_from_json(
+            jpath=datafile, return_scaled=scaled
+        )
+    else:
+        raise ValueError("datafile must be .h5 / .json file!")
+
+    return Nstep, eles, pos, latv, D_mag_fix
+
+
+def pel_from_as(spath: str, scaled=False):
+    """Extract structure information from .as file
+
+    从DSPAW的as结构文件中读取坐标、元素列表，和晶胞信息
 
-    pymatgen_structures = []
-    for step in range(len(j)):
-        atominfo = j[step]["Atoms"]
-        elements = []
-        positions = []
-        for atomindex in range(len(atominfo)):
-            elements.append(atominfo[atomindex]["Element"])
-            positions.append(atominfo[atomindex]["Position"])
-        coords = np.asarray(positions).reshape(-1, 3)
-        lattice = np.asarray(j[step]["Lattice"]).reshape(3, 3)
-        pymatgen_structures.append(
-            Structure(lattice, elements, coords, coords_are_cartesian=True)
+    Parameters
+    ----------
+
+    spath : str
+        结构文件路径
+
+    Returns
+    -------
+
+    pos : np.ndarray
+        坐标分量数组，Natom x 3
+    ele : list
+        元素列表, Natom x 1
+    latv : np.ndarray
+        晶胞矢量数组，3 x 3
+
+    Examples
+    --------
+
+    >>> from dspawpy.io.read import pel_from_as
+    >>> pos, ele, latv = pel_from_as(spath='structure.as', scaled=False)
+    >>> pos
+    array([[ 0.        ,  0.        ,  9.06355632],
+           [ 1.59203323,  0.91916082, 10.62711265],
+           [ 1.59203323,  0.91916082,  7.5       ]])
+    >>> ele
+    ['Mo', 'S', 'S']
+    >>> latv
+    array([[ 3.18406646,  0.        ,  0.        ],
+           [-1.59203323,  2.75748245,  0.        ],
+           [ 0.        ,  0.        , 30.        ]])
+
+    if scaled=True, return scaled coordinates
+    >>> spos, ele, latv = pel_from_as(spath='structure.as', scaled=True)
+    >>> spos
+    array([[0.        , 0.        , 0.30211854],
+           [0.66666667, 0.33333333, 0.35423709],
+           [0.66666667, 0.33333333, 0.25      ]])
+    >>> ele
+    ['Mo', 'S', 'S']
+    >>> latv
+    array([[ 3.18406646,  0.        ,  0.        ],
+           [-1.59203323,  2.75748245,  0.        ],
+           [ 0.        ,  0.        , 30.        ]])
+    """
+    with open(spath, "r") as f:
+        lines = f.readlines()
+        Natom = int(lines[1])  # 原子总数
+        ele = [line.split()[0] for line in lines[7 : 7 + Natom]]  # 元素列表
+
+        # 晶格矢量
+        latv = np.array([line.split()[0:3] for line in lines[3:6]], dtype=float)
+        # xyz坐标分量
+        coord = np.array(
+            [line.split()[1:4] for line in lines[7 : 7 + Natom]], dtype=float
         )
+        # coordinates type
+        if lines[6].startswith("C"):  # 笛卡尔 --> 分数坐标
+            spos = np.linalg.solve(latv.T, np.transpose(coord)).T
+        elif lines[6].startswith("D"):
+            spos = coord
+        else:
+            raise ValueError(f"{spath}中的坐标类型未知！")
+
+        if scaled:
+            pos = spos
+        else:
+            pos = np.dot(spos, latv)
+
+    return pos, ele, latv
+
+
+def _sinfo_from_h5(
+    hpath: str,
+    index=None,
+    ele=None,
+    ai=None,
+    return_scaled: bool = False,
+):
+    print(f"Reading {os.path.abspath(hpath)} ...")
+    hf = h5py.File(hpath)  # 加载h5文件
+    Total_step = len(np.array(hf.get("/Structures"))) - 2  # 总步数
+
+    if ele is not None and ai is not None:
+        raise ValueError("暂不支持同时指定元素和原子序号")
+    # 步数
+    if index is not None:
+        if isinstance(index, int):  # 1
+            indices = [index]
 
-    return pymatgen_structures
+        elif isinstance(index, list) or isinstance(ai, np.ndarray):  # [1,2,3]
+            indices = index
+
+        elif isinstance(index, str):  # ':', '-3:'
+            indices = __parse_indices(index, Total_step)
+
+        else:
+            raise ValueError("请输入正确格式的index")
+
+        Nstep = len(indices)
+    else:
+        Nstep = Total_step
+        indices = list(range(1, Nstep + 1))
+
+    # 读取元素列表，这个列表不会随步数改变，也不会“合并同类项”
+    Elements = np.array(get_ele_from_h5(hpath), dtype=object)
+
+    # 开始读取晶胞和原子位置
+    lattices = np.empty((Nstep, 3, 3))  # Nstep x 3 x 3
+    location = []
+    if ele is not None:  # 如果用户指定元素
+        if isinstance(ele, str):  # 单个元素符号，例如 'Fe'
+            ele_list = np.array(ele, dtype=object)
+            location = np.where(Elements == ele_list)[0]
+        # 多个元素符号组成的列表，例如 ['Fe', 'O']
+        elif isinstance(ele, list) or isinstance(ele, np.ndarray):
+            for e in ele:
+                loc = np.where(Elements == e)[0]
+                location.append(loc)
+            location = np.concatenate(location)
+        else:
+            raise TypeError("请输入正确的元素或元素列表")
+        elements = Elements[location]
+
+    elif ai is not None:  # 如果用户指定原子序号
+        if isinstance(ai, int):  # 1
+            ais = [ai]
+        elif isinstance(ai, list) or isinstance(ai, np.ndarray):  # [1,2,3]
+            ais = ai
+        elif isinstance(ai, str):  # ':', '-3:'
+            ais = __parse_indices(ai, Total_step)
+        else:
+            raise ValueError("请输入正确格式的ai")
+        ais = [i - 1 for i in ais]  # python从0开始计数，但是用户从1开始计数
+        elements = Elements[ais]
+        location = ais
+
+    else:  # 如果都没指定
+        elements = Elements
+        location = list(range(len(Elements)))
+
+    elements = elements.tolist()  # for pretty output
+
+    mags = []  # must be Nstep x Natom x ?
+
+    poses = np.empty(shape=(len(indices), len(elements), 3))
+    for i, ind in enumerate(indices):  # 步数
+        lats = np.array(hf.get("/Structures/Step-" + str(ind) + "/Lattice"))
+        lattices[i] = lats
+        # [x1,y1,z1,x2,y2,z2,x3,y3,z3], ...
+        # 结构优化时输出的都是分数坐标，不管CoordinateType写的是啥！
+        pos = np.array(hf.get("/Structures/Step-" + str(ind) + "/Position"))
+        wrapped_pos = pos - np.floor(pos)  # wrap into [0,1)
+        wrapped_pos = wrapped_pos.flatten().reshape(-1, 3).T  # reshape
+
+        try:  # 自旋计算
+            mag = np.array(hf.get("/Structures/Step-" + str(ind) + "/Mag"))
+            if mag == None:
+                mag = np.zeros(shape=(len(elements), 1))
+        except Exception as e:
+            print(e)
+            mag = np.zeros(shape=(len(elements), 1))
+        mags.append(mag)
+
+    try:  # fix atom
+        atomfixs = np.array(hf.get("/AtomInfo/Fix")).astype(bool).flatten()
+        assert atomfixs.shape == (12,)  # np.ndarray (Natom x 3, )
+        atomfixs = atomfixs.reshape(-1, 3)  # (Natom, 3)
+    except Exception as e:
+        print(e)
+        atomfixs = np.full(shape=(len(elements), 3), fill_value=False)
+
+    mags = np.array(mags).reshape(Nstep, len(elements), -1)
+    # repeat atomfixs to Nstep x Natom x 3
+    atomfixs = np.repeat(atomfixs[np.newaxis, :, :], Nstep, axis=0).tolist()
+
+    D_mag_fix = {"Mags": mags, "AtomFixs": atomfixs}
+    print(
+        f"This function does not handle lattice fix info, \n you must manually set it before starting new calculations.."
+    )
+
+    if return_scaled:  # Fractional coordinates
+        for i, ind in enumerate(indices):  # 步数
+            for j, sli in enumerate(location):
+                poses[i, j, :] = np.dot(wrapped_pos[:, sli], np.eye(3, 3))
+    else:  # Cartesian coordinates
+        for i, ind in enumerate(indices):  # 步数
+            for j, sli in enumerate(location):
+                poses[i, j, :] = np.dot(wrapped_pos[:, sli], lats)
+
+    return Nstep, elements, poses, lattices, D_mag_fix
+
+
+def _sinfo_from_json(
+    jpath: str,
+    index=None,
+    ele=None,
+    ai=None,
+    return_scaled=False,
+):
+    """从json指定的路径读取结构相关数据
+
+    输入:
+    - jpath: json文件路径
+    - ai: 原子序号（体系中的第几个原子，不是质子数）
+    - ele: 元素，例如 'C'，'H'，'O'，'N'
+    - index: 运动轨迹中的第几步，从1开始
+
+    输出：
+    - Nstep: 总共要保存多少步的信息, int
+    - elements: 元素列表, list, Natom x 1
+    - positions: 原子位置, list, Nstep x Natom x 3
+    - lattices: 晶胞, list, Nstep x 3 x 3
+    """
+    print(f"Reading {os.path.abspath(jpath)}...")
+    with open(jpath, "r") as f:
+        data = json.load(f)  # 加载json文件
+
+    if "Structures" in data:
+        Total_step = len(data["Structures"])  # aimd.json
+    else:
+        Total_step = len(data)  # relax.json, neb01.json
+
+    if ele is not None and ai is not None:
+        raise ValueError("暂不支持同时指定元素和原子序号")
+    # 步数
+    if index is not None:
+        if isinstance(index, int):  # 1
+            indices = [index]
+
+        elif isinstance(index, list) or isinstance(ai, np.ndarray):  # [1,2,3]
+            indices = index
+
+        elif isinstance(index, str):  # ':', '-3:'
+            indices = __parse_indices(index, Total_step)
+
+        else:
+            raise ValueError("请输入正确格式的index")
+
+        Nstep = len(indices)
+    else:
+        Nstep = Total_step
+        indices = list(range(1, Nstep + 1))  # [1,Nstep+1)
+
+    # 预先读取全部元素的总列表，这个列表不会随步数改变，也不会“合并同类项”
+    # 这样可以避免在循环内部频繁判断元素是否符合用户需要
+
+    if "Structures" in data:
+        Nele = len(data["Structures"][0]["Atoms"])  # relax.json
+        total_elements = np.empty(shape=(Nele), dtype=object)  # 未合并的元素列表
+        for i in range(Nele):
+            element = data["Structures"][0]["Atoms"][i]["Element"]
+            total_elements[i] = element
+    else:
+        Nele = len(data[0]["Atoms"])
+        total_elements = np.empty(shape=(Nele), dtype=object)  # 未合并的元素列表
+        for i in range(Nele):
+            element = data[0]["Atoms"][i]["Element"]
+            total_elements[i] = element
+
+    Natom = len(total_elements)
+
+    # 开始读取晶胞和原子位置
+    # 在data['Structures']['%d' % index]['Atoms']中根据元素所在序号选择结构
+    if ele is not None:  # 用户指定要某些元素
+        location = []
+        if isinstance(ele, str):  # 单个元素符号，例如 'Fe'
+            ele_list = list(ele)
+        # 多个元素符号组成的列表，例如 ['Fe', 'O']
+        elif isinstance(ele, list) or isinstance(ele, np.ndarray):
+            ele_list = ele
+        else:
+            raise TypeError("请输入正确的元素或元素列表")
+        for e in ele_list:
+            location.append(np.where(total_elements == e)[0])
+        location = np.concatenate(location)
+
+    elif ai is not None:  # 如果用户指定原子序号，也要据此筛选元素列表
+        if isinstance(ai, int):  # 1
+            ais = [ai]
+        elif isinstance(ai, list) or isinstance(ai, np.ndarray):  # [1,2,3]
+            ais = ai
+        elif isinstance(ai, str):  # ':', '-3:'
+            ais = __parse_indices(ai, Total_step)
+        else:
+            raise ValueError("请输入正确格式的ai")
+        ais = [i - 1 for i in ais]  # python从0开始计数，但是用户从1开始计数
+        location = ais
+        # read lattices and poses
+
+    else:  # 如果都没指定
+        location = list(range(Natom))
+
+    # 满足用户需要的elements列表
+    elements = np.empty(shape=(Natom,), dtype=object)
+    for i in range(len(location)):
+        elements[i] = total_elements[location[i]]
+
+    # Nstep x Natom x 3, positions are all fractional
+    positions = np.empty(shape=(len(indices), len(elements), 3))
+    lattices = np.empty(shape=(Nstep, 3, 3))  # Nstep x 3 x 3
+    mags = []  # Nstep x Natom x ?
+    Atomfixs = []  # Nstep x Natom x 3
+
+    if "Structures" in data:  # relax.json
+        for i, ind in enumerate(indices):  # for every ionic step
+            lat = data["Structures"][ind - 1]["Lattice"]
+            lattices[i] = np.array(lat).reshape(3, 3)
+            mag_for_each_step = []
+            fix_for_each_step = []
+            for j, sli in enumerate(location):
+                ati = data["Structures"][ind - 1]["Atoms"][sli]
+                positions[i, j, :] = ati["Position"][:]
+
+                mag_for_each_atom = ati["Mag"][:]
+                mag_for_each_step.append(mag_for_each_atom)
+
+                fix_for_each_atom = ati["Fix"][:]
+                if fix_for_each_atom == []:
+                    fix_for_each_atom = [0, 0, 0]
+                fix_for_each_atom = [bool(i) for i in fix_for_each_atom]
+                fix_for_each_step.append(fix_for_each_atom)
+
+            mags.append(mag_for_each_step)
+            Atomfixs.append(fix_for_each_step)
+            if not return_scaled:
+                positions = np.dot(positions, lattices[i])
+    else:
+        for i, ind in enumerate(indices):  # for every ionic step
+            lat = data[ind - 1]["Lattice"]
+            lattices[i] = np.array(lat).reshape(3, 3)
+            mag_for_each_step = []
+            fix_for_each_step = []
+            for j, sli in enumerate(location):
+                ati = data[ind - 1]["Atoms"][sli]
+                positions[i, j, :] = ati["Position"][:]
+
+                mag_for_each_atom = ati["Mag"][:]
+                mag_for_each_step.append(mag_for_each_atom)
+
+                fix_for_each_atom = ati["Fix"][:]
+                if fix_for_each_atom == []:
+                    fix_for_each_atom = [0, 0, 0]
+                fix_for_each_atom = [bool(i) for i in fix_for_each_atom]
+                fix_for_each_step.append(fix_for_each_atom)
+
+            mags.append(mag_for_each_step)
+            Atomfixs.append(fix_for_each_step)
+            if not return_scaled:
+                positions = np.dot(positions, lattices[i])
+
+    elements = elements.tolist()
+    Mags = np.array(mags)  # (Nstep, Natom, ?) or (Nstep, 0,)
+
+    D_mag_fix = {"Mags": Mags, "AtomFixs": Atomfixs}
+    print(
+        f"This function does not handle lattice fix info, \n you must manually set it before starting new calculations.."
+    )
+
+    return Nstep, elements, positions, lattices, D_mag_fix
+
+
+def __parse_indices(index: str, total_step) -> list:
+    """解析用户输入的原子序号字符串
+
+    输入：
+        - index: 用户输入的原子序号/元素字符串，例如 '1:3,5,7:10'
+    输出：
+        - indices: 解析后的原子序号列表，例如 [1,2,3,4,5,6,7,8,9,10]
+    """
+    assert ":" in index, "如果不想切片索引，请输入整数或者列表"
+    blcs = index.split(",")
+    indices = []
+    for blc in blcs:
+        if ":" in blc:  # 切片
+            low = blc.split(":")[0]
+            if not low:
+                low = 1  # 从1开始
+            else:
+                low = int(low)
+                assert low > 0, "索引从1开始！"
+            high = blc.split(":")[1]
+            if not high:
+                high = total_step
+            else:
+                high = int(high)
+                assert high <= total_step, "索引超出范围！"
+
+            for i in range(low, high + 1):
+                indices.append(i)
+        else:  # 单个数字
+            indices.append(int(blc))
+    return indices
+
+
+def _get_lammps_non_orthogonal_box(lat: np.ndarray):
+    """计算用于输入lammps的盒子边界参数，用于生成dump结构文件
+
+    Parameters
+    ----------
+    lat : np.ndarray
+        常见的非三角3x3矩阵
+
+    Returns
+    -------
+    box_bounds:
+        用于输入lammps的盒子边界
+    """
+    # https://docs.lammps.org/Howto_triclinic.html
+    A = lat[0]
+    B = lat[1]
+    C = lat[2]
+    assert np.cross(A, B).dot(C) > 0, "Lat is not right handed"
+
+    # 将常规3x3矩阵转成标准的上三角矩阵
+    alpha = np.arccos(np.dot(B, C) / (np.linalg.norm(B) * np.linalg.norm(C)))
+    beta = np.arccos(np.dot(A, C) / (np.linalg.norm(A) * np.linalg.norm(C)))
+    gamma = np.arccos(np.dot(A, B) / (np.linalg.norm(A) * np.linalg.norm(B)))
+
+    ax = np.linalg.norm(A)
+    a = np.array([ax, 0, 0])
+
+    bx = np.linalg.norm(B) * np.cos(gamma)
+    by = np.linalg.norm(B) * np.sin(gamma)
+    b = np.array([bx, by, 0])
+
+    cx = np.linalg.norm(C) * np.cos(beta)
+    cy = (np.linalg.norm(B) * np.linalg.norm(C) - bx * cx) / by
+    cz = np.sqrt(abs(np.linalg.norm(C) ** 2 - cx**2 - cy**2))
+    c = np.array([cx, cy, cz])
+
+    # triangluar matrix in lammmps cell format
+    # note that in OVITO, it will be down-triangular one
+    # lammps_lattice = np.array([a,b,c]).T
+
+    # write lammps box parameters
+    # https://docs.lammps.org/Howto_triclinic.html#:~:text=The%20inverse%20relationship%20can%20be%20written%20as%20follows
+    lx = np.linalg.norm(a)
+    xy = np.linalg.norm(b) * np.cos(gamma)
+    xz = np.linalg.norm(c) * np.cos(beta)
+    ly = np.sqrt(np.linalg.norm(b) ** 2 - xy**2)
+    yz = (np.linalg.norm(b) * np.linalg.norm(c) * np.cos(alpha) - xy * xz) / ly
+    lz = np.sqrt(np.linalg.norm(c) ** 2 - xz**2 - yz**2)
+
+    # "The parallelepiped has its “origin” at (xlo,ylo,zlo) and is defined by 3 edge vectors starting from the origin given by a = (xhi-xlo,0,0); b = (xy,yhi-ylo,0); c = (xz,yz,zhi-zlo)."
+    # 令原点在(0,0,0)，则 xlo = ylo = zlo = 0
+    xlo = ylo = zlo = 0
+    # https://docs.lammps.org/Howto_triclinic.html#:~:text=the%20LAMMPS%20box%20sizes%20(lx%2Cly%2Clz)%20%3D%20(xhi%2Dxlo%2Cyhi%2Dylo%2Czhi%2Dzlo)
+    xhi = lx + xlo
+    yhi = ly + ylo
+    zhi = lz + zlo
+    # https://docs.lammps.org/Howto_triclinic.html#:~:text=This%20bounding%20box%20is%20convenient%20for%20many%20visualization%20programs%20and%20is%20calculated%20from%20the%209%20triclinic%20box%20parameters%20(xlo%2Cxhi%2Cylo%2Cyhi%2Czlo%2Czhi%2Cxy%2Cxz%2Cyz)%20as%20follows%3A
+    xlo_bound = xlo + np.min([0, xy, xz, xy + xz])
+    xhi_bound = xhi + np.max([0, xy, xz, xy + xz])
+    ylo_bound = ylo + np.min([0, yz])
+    yhi_bound = yhi + np.max([0, yz])
+    zlo_bound = zlo
+    zhi_bound = zhi
+    box_bounds = np.array(
+        [
+            [xlo_bound, xhi_bound, xy],
+            [ylo_bound, yhi_bound, xz],
+            [zlo_bound, zhi_bound, yz],
+        ]
+    )
+
+    return box_bounds
 
 
 def load_h5(dir_h5: str) -> dict:
     """遍历读取h5文件中的数据，保存为字典格式
 
     慎用此函数，因为会读取很多不需要的数据，耗时很长。
 
@@ -100,21 +639,21 @@
         datas = {}
         fin.visititems(get_names)
         fin.visititems(get_datas)
 
         return datas
 
 
-def load_h5_todict(dir_h5: str) -> Dict:
+def load_h5_todict(dir_h5: str) -> dict:
     """与上一个函数区别在于合并了部分同类数据，例如
 
     /Structures/Step-1/* 和 /Structures/Step-2/* 并入 /Structures/ 组内
     """
 
-    def create_dict(L: List, D: Dict):
+    def create_dict(L: list, D: dict):
         if len(L) == 2:
             D[L[0]] = L[1]
             return
         else:
             if not (L[0] in D.keys()):
                 D[L[0]] = {}
             create_dict(L[1:], D[L[0]])
@@ -153,15 +692,15 @@
             return get_total_dos_json(dos)
 
     else:
         print("file - " + dos_dir + " :  Unsupported format!")
         return
 
 
-def get_total_dos(dos: Dict) -> Dos:
+def get_total_dos(dos: dict) -> Dos:
     # h5 -> Dos Obj
     energies = np.asarray(dos["/DosInfo/DosEnergy"])
     if dos["/DosInfo/SpinType"][0] == "none":
         densities = {Spin.up: np.asarray(dos["/DosInfo/Spin1/Dos"])}
     else:
         densities = {
             Spin.up: np.asarray(dos["/DosInfo/Spin1/Dos"]),
@@ -169,15 +708,15 @@
         }
 
     efermi = dos["/DosInfo/EFermi"][0]
 
     return Dos(efermi, energies, densities)
 
 
-def get_complete_dos(dos: Dict) -> CompleteDos:
+def get_complete_dos(dos: dict) -> CompleteDos:
     # h5 -> CompleteDos Obj
     total_dos = get_total_dos(dos)
     structure = get_structure(dos, "/AtomInfo")
     N = len(structure)
     pdos = [{} for i in range(N)]
     number_of_spin = 1 if dos["/DosInfo/SpinType"][0] == "none" else 2
 
@@ -203,29 +742,29 @@
                     pdos[atom_index][orbit_name] = {spin: Contribution}
 
     pdoss = {structure[i]: pd for i, pd in enumerate(pdos)}
 
     return CompleteDos(structure, total_dos, pdoss)
 
 
-def get_total_dos_json(dos: Dict) -> Dos:
+def get_total_dos_json(dos: dict) -> Dos:
     # json -> Dos Obj
     energies = np.asarray(dos["DosInfo"]["DosEnergy"])
     if dos["DosInfo"]["SpinType"] == "none":
         densities = {Spin.up: np.asarray(dos["DosInfo"]["Spin1"]["Dos"])}
     else:
         densities = {
             Spin.up: np.asarray(dos["DosInfo"]["Spin1"]["Dos"]),
             Spin.down: np.asarray(dos["DosInfo"]["Spin2"]["Dos"]),
         }
     efermi = dos["DosInfo"]["EFermi"]
     return Dos(efermi, energies, densities)
 
 
-def get_complete_dos_json(dos: Dict) -> CompleteDos:
+def get_complete_dos_json(dos: dict) -> CompleteDos:
     # json -> CompleteDos Obj
     total_dos = get_total_dos_json(dos)
     structure = get_structure_json(dos["AtomInfo"])
     N = len(structure)
     pdos = [{} for i in range(N)]
     number_of_spin = 1 if dos["DosInfo"]["SpinType"] == "none" else 2
 
@@ -242,15 +781,15 @@
             else:
                 pdos[atom_index][orbit_name] = {spin: p["Contribution"]}
     pdoss = {structure[i]: pd for i, pd in enumerate(pdos)}
 
     return CompleteDos(structure, total_dos, pdoss)
 
 
-def get_structure(hdf5: Dict, key: str) -> Structure:
+def get_structure(hdf5: dict, key: str) -> Structure:
     # load_h5 -> Structure Obj
     lattice = np.asarray(hdf5[key + "/Lattice"]).reshape(3, 3)
     elements = hdf5[key + "/Elements"]
     positions = hdf5[key + "/Position"]
     coords = np.asarray(positions).reshape(-1, 3)
     is_direct = hdf5[key + "/CoordinateType"][0] == "Direct"
     return Structure(lattice, elements, coords, coords_are_cartesian=(not is_direct))
@@ -276,15 +815,15 @@
     elements = j["AtomInfo"]["Elements"]
     positions = j["AtomInfo"]["Position"]
     coords = np.asarray(positions).reshape(-1, 3)
     is_direct = j["AtomInfo"]["CoordinateType"][0] == "Direct"
     return Structure(lattice, elements, coords, coords_are_cartesian=(not is_direct))
 
 
-def get_band_data_h5(band: Dict, iwan=False):
+def get_band_data_h5(band: dict, iwan=False):
     if iwan:
         bd = "WannBandInfo"
     else:
         bd = "BandInfo"
     number_of_band = band[f"/{bd}/NumberOfBand"][0]
     number_of_kpoints = band[f"/{bd}/NumberOfKpoints"][0]
     if (
@@ -355,34 +894,34 @@
                             .T
                         )
                 projections[spin] = projection
 
     return structure, kpoints, eigenvals, efermi, labels_dict, projections
 
 
-def get_band_data_json(band: Dict, iwan=False):
+def get_band_data_json(band: dict, iwan=False):
     if iwan:
         bd = "WannBandInfo"
     else:
         bd = "BandInfo"
 
     number_of_band = band[f"{bd}"]["NumberOfBand"]
     number_of_kpoints = band[f"{bd}"]["NumberOfKpoints"]
-    if 'Spin2' in band[f"{bd}"]:
+    if "Spin2" in band[f"{bd}"]:
         number_of_spin = 2
     else:
         number_of_spin = 1
 
     symmetry_kPoints_index = band[f"{bd}"]["SymmetryKPointsIndex"]
 
     if "EFermi" in band[f"{bd}"]:
         efermi = band[f"{bd}"]["EFermi"]
     else:
-        efermi = 0 # for wannier
-        
+        efermi = 0  # for wannier
+
     eigenvals = {}
     for i in range(number_of_spin):
         spin_key = "Spin" + str(i + 1)
         spin = Spin.up if i == 0 else Spin.down
 
         if "BandEnergies" in band[f"{bd}"][spin_key]:
             data = band[f"{bd}"][spin_key]["BandEnergies"]
@@ -442,74 +981,74 @@
         band = load_h5(band_dir)
         raw = h5py.File(band_dir, "r").keys()
         if "/WannBandInfo/NumberOfBand" in raw:
             (
                 structure,
                 kpoints,
                 eigenvals,
-                efermi,
+                rEf,
                 labels_dict,
                 projections,
             ) = get_band_data_h5(band, iwan=True)
         elif "/BandInfo/NumberOfBand" in raw:
             (
                 structure,
                 kpoints,
                 eigenvals,
-                efermi,
+                rEf,
                 labels_dict,
                 projections,
             ) = get_band_data_h5(band, iwan=False)
         else:
             print("BandInfo or WannBandInfo key not found in h5file!")
             return
     elif band_dir.endswith(".json"):
         with open(band_dir, "r") as fin:
             band = json.load(fin)
         if "WannBandInfo" in band.keys():
             (
                 structure,
                 kpoints,
                 eigenvals,
-                efermi,
+                rEf,
                 labels_dict,
                 projections,
             ) = get_band_data_json(band, iwan=True)
         elif "BandInfo" in band.keys():
             (
                 structure,
                 kpoints,
                 eigenvals,
-                efermi,
+                rEf,
                 labels_dict,
                 projections,
             ) = get_band_data_json(band, iwan=False)
         else:
             print("BandInfo or WannBandInfo key not found in json file!")
             return
     else:
         print("file - " + band_dir + " :  Unsupported format!")
         return
 
     if efermi:  # 从h5直接读取的费米能级可能是错的，此时需要用户自行指定
-        efermi = efermi  # 这只是个临时解决方案
+        rEf = efermi  # 这只是个临时解决方案
 
     lattice_new = Lattice(structure.lattice.reciprocal_lattice.matrix)
     return BandStructureSymmLine(
         kpoints=kpoints,
         eigenvals=eigenvals,
         lattice=lattice_new,
-        efermi=efermi,
+        efermi=rEf,
         labels_dict=labels_dict,
         structure=structure,
         projections=projections,
     )
 
 
-def get_phonon_band_data_h5(band: Dict):
+def get_phonon_band_data_h5(band: dict):
     number_of_band = band["/BandInfo/NumberOfBand"][0]
     number_of_kpoints = band["/BandInfo/NumberOfQPoints"][0]
     number_of_spin = 1
     symmmetry_kpoints = band["/BandInfo/SymmetryQPoints"]
     symmetry_kPoints_index = band["/BandInfo/SymmetryQPointsIndex"]
     eigenvals = {}
     for i in range(number_of_spin):
@@ -530,15 +1069,15 @@
     if "/SupercellAtomInfo/CoordinateType" in band.keys():
         structure = get_structure(band, "/SupercellAtomInfo")
     else:
         structure = get_structure(band, "/AtomInfo")
     return symmmetry_kpoints, symmetry_kPoints_index, kpoints, structure, frequencies
 
 
-def get_phonon_band_data_json(band: Dict):
+def get_phonon_band_data_json(band: dict):
     number_of_band = band["BandInfo"]["NumberOfBand"]
     number_of_kpoints = band["BandInfo"]["NumberOfQPoints"]
     number_of_spin = 1
     symmmetry_kpoints = band["BandInfo"]["SymmetryQPoints"]
     symmetry_kPoints_index = band["BandInfo"]["SymmetryQPointsIndex"]
 
     eigenvals = {}
```

## dspawpy/io/read_json.py

```diff
@@ -1,53 +1,50 @@
 # -*- coding: utf-8 -*-
 
 import json
-from typing import Dict
 
 import numpy as np
-from pymatgen.core.structure import Structure
 from pymatgen.core.lattice import Lattice
-from pymatgen.electronic_structure.dos import Dos, CompleteDos
-from pymatgen.electronic_structure.core import Spin
-from pymatgen.electronic_structure.core import Orbital
+from pymatgen.core.structure import Structure
 from pymatgen.electronic_structure.bandstructure import BandStructureSymmLine
+from pymatgen.electronic_structure.core import Orbital, Spin
+from pymatgen.electronic_structure.dos import CompleteDos, Dos
 from pymatgen.phonon.bandstructure import PhononBandStructureSymmLine
-from pymatgen.phonon.dos import PhononDos, CompletePhononDos
+from pymatgen.phonon.dos import PhononDos
 
 
 def get_dos_data(dos_json: str):
     with open(dos_json, "r") as file:
         dos = json.load(file)
 
     if dos["DosInfo"]["Project"]:
         return get_complete_dos(dos)
     else:
         return get_total_dos(dos)
 
 
-def get_total_dos(dos: Dict) -> Dos:
+def get_total_dos(dos: dict) -> Dos:
     energies = np.asarray(dos["DosInfo"]["DosEnergy"])
     if dos["DosInfo"]["SpinType"] == "none":
         densities = {Spin.up: np.asarray(dos["DosInfo"]["Spin1"]["Dos"])}
     else:
         densities = {
             Spin.up: np.asarray(dos["DosInfo"]["Spin1"]["Dos"]),
             Spin.down: np.asarray(dos["DosInfo"]["Spin2"]["Dos"]),
         }
 
     efermi = dos["DosInfo"]["EFermi"]
 
     return Dos(efermi, energies, densities)
 
 
-def get_complete_dos(dos: Dict) -> CompleteDos:
+def get_complete_dos(dos: dict) -> CompleteDos:
     total_dos = get_total_dos(dos)
 
     structure = get_structure(dos["AtomInfo"])
-    orbit = dos["DosInfo"]["Orbit"]
     N = len(structure)
 
     pdos = [{} for i in range(N)]
     number_of_spin = 1 if dos["DosInfo"]["SpinType"] == "none" else 2
 
     for i in range(number_of_spin):
         spin_key = "Spin" + str(i + 1)
@@ -112,15 +109,14 @@
         band["BandInfo"]["SpinType"] == "none"
         or band["BandInfo"]["SpinType"] == "non-collinear"
     ):
         number_of_spin = 1
     else:
         number_of_spin = 2
 
-    symmmetry_kpoints = band["BandInfo"]["SymmetryKPoints"]
     symmetry_kPoints_index = band["BandInfo"]["SymmetryKPointsIndex"]
 
     efermi = band["BandInfo"]["EFermi"]
     eigenvals = {}
     for i in range(number_of_spin):
         spin_key = "Spin" + str(i + 1)
         spin = Spin.up if i == 0 else Spin.down
```

## dspawpy/io/structure.py

```diff
@@ -1,17 +1,100 @@
-# -*- coding: utf-8 -*-
+"""
+Functions to build structures,
+"""
 
 import json
-from typing import Dict, List
+from typing import Dict, List, Union
+
 import h5py
 import numpy as np
-
 from pymatgen.core import Structure
-from dspawpy.io.utils import get_lines_without_comment
-from dspawpy.analysis.aimdtools import read_h5
+
+from dspawpy.io.read import (_sinfo_from_h5, get_lines_without_comment,
+                             get_sinfo)
+
+
+def build_Structures_from_datafile(datafile: Union[str, List[str]]) -> List[Structure]:
+    """读取一/多个h5/json文件，返回pymatgen的Structures列表
+
+    Parameters
+    ----------
+    datafile : 字符串或字符串列表
+        aimd.h5/aimd.json文件或包含任意这些文件文件夹；若给定字符串列表，将依次读取数据并合并成一个Structures列表
+
+    Returns
+    -------
+    List[Structure] : pymatgen structures 列表
+
+    Examples
+    --------
+    >>> from dspawpy.analysis.aimdtools import build_Structures_from_datafile
+    # 读取单个文件
+    >>> pymatgen_Structures = build_Structures_from_datafile(datafile='aimd1.h5')
+    # 给定包含aimd.h5或aimd.json文件的文件夹位置
+    >>> pymatgen_Structures = build_Structures_from_datafile(datafile='my_aimd_task')
+    # 当datafile为列表时，将依次读取多个文件，合并成一个Structures列表
+    >>> pymatgen_Structures = build_Structures_from_datafile(datafile=['aimd1.h5','aimd2.h5'])
+    """
+    dfs = []
+    if isinstance(datafile, list):  # 续算模式，给的是多个文件
+        dfs = datafile
+    else:  # 单次计算模式，处理单个文件
+        if datafile.endswith(".h5") or datafile.endswith(".json"):
+            df = datafile
+        else:
+            raise FileNotFoundError("未找到h5或json文件！")
+        dfs.append(df)
+
+    # 读取结构数据
+    pymatgen_Structures = []
+    for df in dfs:
+        # TODO 支持选取特定帧
+        structure_list = _get_structure_list(df)
+        pymatgen_Structures.extend(structure_list)
+
+    return pymatgen_Structures
+
+
+def _get_structure_list(df: str = "aimd.h5") -> List[Structure]:
+    """get pymatgen structures from single datafile
+
+    Parameters
+    ----------
+    df : str, optional
+        datafile, by default "aimd.h5"
+
+    Returns
+    -------
+    List[Structure] : list of pymatgen structures
+
+    Examples
+    --------
+    >>> from dspawpy.analysis.aimdtools import get_structure_list
+    >>> structure_list = get_structure_list(df='aimd.h5')
+    """
+
+    # create Structure structure_list from aimd.h5
+    Nstep, elements, positions, lattices, D_mag_fix = get_sinfo(df)
+    strs = []
+    for i in range(Nstep):
+        strs.append(
+            Structure(
+                lattices[i],
+                elements,
+                positions[i],
+                coords_are_cartesian=False,
+                site_properties={
+                    "Mags": D_mag_fix["Mags"][i],
+                    "AtomFixs": D_mag_fix["AtomFixs"][i],
+                },
+            )
+        )
+
+    return strs
 
 
 def from_dspaw_as(as_file: str = "structure.as") -> Structure:
     """从DSPAW的as结构文件中读取结构信息
 
     Parameters
     ----------
@@ -37,15 +120,15 @@
         lattice.extend([float(vector[0]), float(vector[1]), float(vector[2])])
 
     lattice = np.asarray(lattice).reshape(3, 3)
     is_direct = lines[6].strip().split()[0].startswith("Direct")
     elements = []
     positions = []
     others = []
-    line6s = []
+    line6s = []  # Cartesian/Direct Mag Fix_x ...
     for i in range(N):
         atom = lines[i + 7].strip().split()
         elements.append(atom[0])
         positions.extend([float(atom[1]), float(atom[2]), float(atom[3])])
 
         if len(atom) > 4:
             other = atom[4:]
@@ -151,15 +234,15 @@
             positions.extend(atom["Position"])
 
         coords = np.asarray(positions).reshape(-1, 3)
         is_direct = atominfo["CoordinateType"] == "Direct"
         return Structure(
             lattice, elements, coords, coords_are_cartesian=(not is_direct)
         )
-    Nstep, elements, positions, lattices = read_h5(hpath, index)
+    Nstep, elements, positions, lattices = _sinfo_from_h5(hpath, index)
     return Structure(lattices[0], elements, positions[0], coords_are_cartesian=True)
 
 
 def from_dspaw_atominfo_json(atominfo: dict) -> Structure:
     lattice = np.asarray(atominfo["Lattice"]).reshape(3, 3)
     elements = []
     positions = []
@@ -191,42 +274,46 @@
         print("file - " + aimd_dir + " :  Unsupported format!")
         return
 
     return structures
 
 
 def to_dspaw_as(structure: Structure, filename: str, coords_are_cartesian=True):
+    """write dspaw as file
+    If converted from as file, will copy the mag and fix info,
+        otherwise, those info will be ignored!
+    """
     with open(filename, "w", encoding="utf-8") as file:
         file.write("Total number of atoms\n")
         file.write("%d\n" % len(structure))
 
         file.write("Lattice\n")
         for v in structure.lattice.matrix:
             file.write("%.6f %.6f %.6f\n" % (v[0], v[1], v[2]))
 
         i = 0
         for site in structure:
             if i == 0:
-                if 'line6s' in site.properties:
+                if "line6s" in site.properties:
                     file.write("%s\n" % site.properties["line6s"])
                 else:
                     if coords_are_cartesian:
                         file.write("Cartesian\n")
                     else:
                         file.write("Direct\n")
             i += 1
 
             coords = site.coords if coords_are_cartesian else site.frac_coords
-            if 'others' in site.properties:
+            if "others" in site.properties:
                 sp = " ".join(site.properties["others"])  # flatten str list
                 file.write(
                     "%s %.6f %.6f %.6f %s\n"
                     % (site.species_string, coords[0], coords[1], coords[2], sp)
                 )
-            else:
+            else:  # the most common case
                 file.write(
                     "%s %.6f %.6f %.6f\n"
                     % (site.species_string, coords[0], coords[1], coords[2])
                 )
 
 
 def to_hzw(structure: Structure, filename: str):
```

## dspawpy/io/utils.py

```diff
@@ -1,182 +1,292 @@
-from scipy import integrate
-import re
+import os
 from typing import List
+
 import numpy as np
-import os
 import pandas as pd
 from pymatgen.electronic_structure.core import OrbitalType
+from scipy import integrate
+
+from dspawpy.io.read import get_ele_from_h5
 
 Na = 6.02214179e23  # 阿伏伽德罗常数 单位 /mol
 h = 6.6260696e-34  # 普朗克常数 单位J*s
 kB = 1.3806503e-23  # 玻尔兹曼常数 J/K
 R = Na * kB  # 理想气体常数 J/(K*mol)
 amu = 1.66053906660e-27  # 原子质量单位 kg
-k = 1.380649e-23/1.602176634e-19 # eV/K
-atomic_masses_iupac2016 = np.array([
-    1.0,  # X
-    1.008,  # H [1.00784, 1.00811]
-    4.002602,  # He
-    6.94,  # Li [6.938, 6.997]
-    9.0121831,  # Be
-    10.81,  # B [10.806, 10.821]
-    12.011,  # C [12.0096, 12.0116]
-    14.007,  # N [14.00643, 14.00728]
-    15.999,  # O [15.99903, 15.99977]
-    18.998403163,  # F
-    20.1797,  # Ne
-    22.98976928,  # Na
-    24.305,  # Mg [24.304, 24.307]
-    26.9815385,  # Al
-    28.085,  # Si [28.084, 28.086]
-    30.973761998,  # P
-    32.06,  # S [32.059, 32.076]
-    35.45,  # Cl [35.446, 35.457]
-    39.948,  # Ar
-    39.0983,  # K
-    40.078,  # Ca
-    44.955908,  # Sc
-    47.867,  # Ti
-    50.9415,  # V
-    51.9961,  # Cr
-    54.938044,  # Mn
-    55.845,  # Fe
-    58.933194,  # Co
-    58.6934,  # Ni
-    63.546,  # Cu
-    65.38,  # Zn
-    69.723,  # Ga
-    72.630,  # Ge
-    74.921595,  # As
-    78.971,  # Se
-    79.904,  # Br [79.901, 79.907]
-    83.798,  # Kr
-    85.4678,  # Rb
-    87.62,  # Sr
-    88.90584,  # Y
-    91.224,  # Zr
-    92.90637,  # Nb
-    95.95,  # Mo
-    97.90721,  # 98Tc
-    101.07,  # Ru
-    102.90550,  # Rh
-    106.42,  # Pd
-    107.8682,  # Ag
-    112.414,  # Cd
-    114.818,  # In
-    118.710,  # Sn
-    121.760,  # Sb
-    127.60,  # Te
-    126.90447,  # I
-    131.293,  # Xe
-    132.90545196,  # Cs
-    137.327,  # Ba
-    138.90547,  # La
-    140.116,  # Ce
-    140.90766,  # Pr
-    144.242,  # Nd
-    144.91276,  # 145Pm
-    150.36,  # Sm
-    151.964,  # Eu
-    157.25,  # Gd
-    158.92535,  # Tb
-    162.500,  # Dy
-    164.93033,  # Ho
-    167.259,  # Er
-    168.93422,  # Tm
-    173.054,  # Yb
-    174.9668,  # Lu
-    178.49,  # Hf
-    180.94788,  # Ta
-    183.84,  # W
-    186.207,  # Re
-    190.23,  # Os
-    192.217,  # Ir
-    195.084,  # Pt
-    196.966569,  # Au
-    200.592,  # Hg
-    204.38,  # Tl [204.382, 204.385]
-    207.2,  # Pb
-    208.98040,  # Bi
-    208.98243,  # 209Po
-    209.98715,  # 210At
-    222.01758,  # 222Rn
-    223.01974,  # 223Fr
-    226.02541,  # 226Ra
-    227.02775,  # 227Ac
-    232.0377,  # Th
-    231.03588,  # Pa
-    238.02891,  # U
-    237.04817,  # 237Np
-    244.06421,  # 244Pu
-    243.06138,  # 243Am
-    247.07035,  # 247Cm
-    247.07031,  # 247Bk
-    251.07959,  # 251Cf
-    252.0830,  # 252Es
-    257.09511,  # 257Fm
-    258.09843,  # 258Md
-    259.1010,  # 259No
-    262.110,  # 262Lr
-    267.122,  # 267Rf
-    268.126,  # 268Db
-    271.134,  # 271Sg
-    270.133,  # 270Bh
-    269.1338,  # 269Hs
-    278.156,  # 278Mt
-    281.165,  # 281Ds
-    281.166,  # 281Rg
-    285.177,  # 285Cn
-    286.182,  # 286Nh
-    289.190,  # 289Fl
-    289.194,  # 289Mc
-    293.204,  # 293Lv
-    293.208,  # 293Ts
-    294.214,  # 294Og
-])
+k = 1.380649e-23 / 1.602176634e-19  # eV/K
+atomic_masses_iupac2016 = np.array(
+    [
+        1.0,  # X
+        1.008,  # H [1.00784, 1.00811]
+        4.002602,  # He
+        6.94,  # Li [6.938, 6.997]
+        9.0121831,  # Be
+        10.81,  # B [10.806, 10.821]
+        12.011,  # C [12.0096, 12.0116]
+        14.007,  # N [14.00643, 14.00728]
+        15.999,  # O [15.99903, 15.99977]
+        18.998403163,  # F
+        20.1797,  # Ne
+        22.98976928,  # Na
+        24.305,  # Mg [24.304, 24.307]
+        26.9815385,  # Al
+        28.085,  # Si [28.084, 28.086]
+        30.973761998,  # P
+        32.06,  # S [32.059, 32.076]
+        35.45,  # Cl [35.446, 35.457]
+        39.948,  # Ar
+        39.0983,  # K
+        40.078,  # Ca
+        44.955908,  # Sc
+        47.867,  # Ti
+        50.9415,  # V
+        51.9961,  # Cr
+        54.938044,  # Mn
+        55.845,  # Fe
+        58.933194,  # Co
+        58.6934,  # Ni
+        63.546,  # Cu
+        65.38,  # Zn
+        69.723,  # Ga
+        72.630,  # Ge
+        74.921595,  # As
+        78.971,  # Se
+        79.904,  # Br [79.901, 79.907]
+        83.798,  # Kr
+        85.4678,  # Rb
+        87.62,  # Sr
+        88.90584,  # Y
+        91.224,  # Zr
+        92.90637,  # Nb
+        95.95,  # Mo
+        97.90721,  # 98Tc
+        101.07,  # Ru
+        102.90550,  # Rh
+        106.42,  # Pd
+        107.8682,  # Ag
+        112.414,  # Cd
+        114.818,  # In
+        118.710,  # Sn
+        121.760,  # Sb
+        127.60,  # Te
+        126.90447,  # I
+        131.293,  # Xe
+        132.90545196,  # Cs
+        137.327,  # Ba
+        138.90547,  # La
+        140.116,  # Ce
+        140.90766,  # Pr
+        144.242,  # Nd
+        144.91276,  # 145Pm
+        150.36,  # Sm
+        151.964,  # Eu
+        157.25,  # Gd
+        158.92535,  # Tb
+        162.500,  # Dy
+        164.93033,  # Ho
+        167.259,  # Er
+        168.93422,  # Tm
+        173.054,  # Yb
+        174.9668,  # Lu
+        178.49,  # Hf
+        180.94788,  # Ta
+        183.84,  # W
+        186.207,  # Re
+        190.23,  # Os
+        192.217,  # Ir
+        195.084,  # Pt
+        196.966569,  # Au
+        200.592,  # Hg
+        204.38,  # Tl [204.382, 204.385]
+        207.2,  # Pb
+        208.98040,  # Bi
+        208.98243,  # 209Po
+        209.98715,  # 210At
+        222.01758,  # 222Rn
+        223.01974,  # 223Fr
+        226.02541,  # 226Ra
+        227.02775,  # 227Ac
+        232.0377,  # Th
+        231.03588,  # Pa
+        238.02891,  # U
+        237.04817,  # 237Np
+        244.06421,  # 244Pu
+        243.06138,  # 243Am
+        247.07035,  # 247Cm
+        247.07031,  # 247Bk
+        251.07959,  # 251Cf
+        252.0830,  # 252Es
+        257.09511,  # 257Fm
+        258.09843,  # 258Md
+        259.1010,  # 259No
+        262.110,  # 262Lr
+        267.122,  # 267Rf
+        268.126,  # 268Db
+        271.134,  # 271Sg
+        270.133,  # 270Bh
+        269.1338,  # 269Hs
+        278.156,  # 278Mt
+        281.165,  # 281Ds
+        281.166,  # 281Rg
+        285.177,  # 285Cn
+        286.182,  # 286Nh
+        289.190,  # 289Fl
+        289.194,  # 289Mc
+        293.204,  # 293Lv
+        293.208,  # 293Ts
+        294.214,  # 294Og
+    ]
+)
 
 chemical_symbols = [
     # 0
-    'X',
+    "X",
     # 1
-    'H', 'He',
+    "H",
+    "He",
     # 2
-    'Li', 'Be', 'B', 'C', 'N', 'O', 'F', 'Ne',
+    "Li",
+    "Be",
+    "B",
+    "C",
+    "N",
+    "O",
+    "F",
+    "Ne",
     # 3
-    'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'Cl', 'Ar',
+    "Na",
+    "Mg",
+    "Al",
+    "Si",
+    "P",
+    "S",
+    "Cl",
+    "Ar",
     # 4
-    'K', 'Ca', 'Sc', 'Ti', 'V', 'Cr', 'Mn', 'Fe', 'Co', 'Ni', 'Cu', 'Zn',
-    'Ga', 'Ge', 'As', 'Se', 'Br', 'Kr',
+    "K",
+    "Ca",
+    "Sc",
+    "Ti",
+    "V",
+    "Cr",
+    "Mn",
+    "Fe",
+    "Co",
+    "Ni",
+    "Cu",
+    "Zn",
+    "Ga",
+    "Ge",
+    "As",
+    "Se",
+    "Br",
+    "Kr",
     # 5
-    'Rb', 'Sr', 'Y', 'Zr', 'Nb', 'Mo', 'Tc', 'Ru', 'Rh', 'Pd', 'Ag', 'Cd',
-    'In', 'Sn', 'Sb', 'Te', 'I', 'Xe',
+    "Rb",
+    "Sr",
+    "Y",
+    "Zr",
+    "Nb",
+    "Mo",
+    "Tc",
+    "Ru",
+    "Rh",
+    "Pd",
+    "Ag",
+    "Cd",
+    "In",
+    "Sn",
+    "Sb",
+    "Te",
+    "I",
+    "Xe",
     # 6
-    'Cs', 'Ba', 'La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy',
-    'Ho', 'Er', 'Tm', 'Yb', 'Lu',
-    'Hf', 'Ta', 'W', 'Re', 'Os', 'Ir', 'Pt', 'Au', 'Hg', 'Tl', 'Pb', 'Bi',
-    'Po', 'At', 'Rn',
+    "Cs",
+    "Ba",
+    "La",
+    "Ce",
+    "Pr",
+    "Nd",
+    "Pm",
+    "Sm",
+    "Eu",
+    "Gd",
+    "Tb",
+    "Dy",
+    "Ho",
+    "Er",
+    "Tm",
+    "Yb",
+    "Lu",
+    "Hf",
+    "Ta",
+    "W",
+    "Re",
+    "Os",
+    "Ir",
+    "Pt",
+    "Au",
+    "Hg",
+    "Tl",
+    "Pb",
+    "Bi",
+    "Po",
+    "At",
+    "Rn",
     # 7
-    'Fr', 'Ra', 'Ac', 'Th', 'Pa', 'U', 'Np', 'Pu', 'Am', 'Cm', 'Bk',
-    'Cf', 'Es', 'Fm', 'Md', 'No', 'Lr',
-    'Rf', 'Db', 'Sg', 'Bh', 'Hs', 'Mt', 'Ds', 'Rg', 'Cn', 'Nh', 'Fl', 'Mc',
-    'Lv', 'Ts', 'Og']
+    "Fr",
+    "Ra",
+    "Ac",
+    "Th",
+    "Pa",
+    "U",
+    "Np",
+    "Pu",
+    "Am",
+    "Cm",
+    "Bk",
+    "Cf",
+    "Es",
+    "Fm",
+    "Md",
+    "No",
+    "Lr",
+    "Rf",
+    "Db",
+    "Sg",
+    "Bh",
+    "Hs",
+    "Mt",
+    "Ds",
+    "Rg",
+    "Cn",
+    "Nh",
+    "Fl",
+    "Mc",
+    "Lv",
+    "Ts",
+    "Og",
+]
 
 atomic_numbers = {}
 for Z, symbol in enumerate(chemical_symbols):
     atomic_numbers[symbol] = Z
 
+
 def symbols2numbers(symbols) -> List[int]:
     numbers = []
     for s in symbols:
         if isinstance(s, str):
             numbers.append(atomic_numbers[s])
         else:
             numbers.append(int(s))
     return numbers
 
+
 def eles2masses(eles: List[str]) -> List[float]:
     """将元素列表转换为质量列表
 
     Parameters
     ----------
     eles : List[str]
         元素列表
@@ -194,15 +304,16 @@
     >>> print(masses)
     [1.00794, 15.9994]
     """
     masses = []
     for e in eles:
         masses.append(atomic_masses_iupac2016[atomic_numbers[e]])
     return np.array(masses)
-        
+
+
 def get_ma(elements, positions, Natom):
     """Get the moments of inertia along the principal axes.
 
     The three principal moments of inertia are computed from the
     eigenvalues of the symmetric inertial tensor. Periodic boundary
     conditions are ignored. Units of the moments of inertia are
     amu*angstrom**2.
@@ -214,29 +325,28 @@
 
     # Initialize elements of the inertial tensor
     I11 = I22 = I33 = I12 = I13 = I23 = 0.0
     for i in range(Natom):
         x, y, z = positions[i]
         m = masses[i]
 
-        I11 += m * (y ** 2 + z ** 2)
-        I22 += m * (x ** 2 + z ** 2)
-        I33 += m * (x ** 2 + y ** 2)
+        I11 += m * (y**2 + z**2)
+        I22 += m * (x**2 + z**2)
+        I33 += m * (x**2 + y**2)
         I12 += -m * x * y
         I13 += -m * x * z
         I23 += -m * y * z
 
-    I = np.array([[I11, I12, I13],
-                    [I12, I22, I23],
-                    [I13, I23, I33]])
+    I = np.array([[I11, I12, I13], [I12, I22, I23], [I13, I23, I33]])
 
     evals, evecs = np.linalg.eigh(I)
     return evals
 
-class IdealGasThermo(): # TODO remove atoms obj
+
+class IdealGasThermo:  # TODO remove atoms obj
     """import from ase.thermochemistry.IdealGasThermo
 
     Parameters
     ----------
     vib_energies : list
         List of vibrational energies in eV.
     geometry : str
@@ -258,206 +368,225 @@
     >>> thermo = IdealGasThermo(vib_energies=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6],
     ...                         geometry='linear', potentialenergy=0.,  # eV
     ...                         elements=['H', 'O'], positions=[[0, 0, 0], [0, 0, 1]],  # angstrom
     ...                         symmetrynumber=None, spin=None, Natom=None)
     >>> thermo.get_free_energy(298.15)  # K
 
     """
+
     # 读取elements数组代替atoms
-    def __init__(self, vib_energies, geometry, potentialenergy=0.,
-                 elements=None, positions=None,symmetrynumber=None, spin=None, natoms=None):
+    def __init__(
+        self,
+        vib_energies,
+        geometry,
+        potentialenergy=0.0,
+        elements=None,
+        positions=None,
+        symmetrynumber=None,
+        spin=None,
+        natoms=None,
+    ):
         self.potentialenergy = potentialenergy
         self.geometry = geometry
         self.elements = elements
         if isinstance(positions, list):
             self.positions = np.array(positions, dtype=float)
         elif isinstance(positions, np.ndarray):
             self.positions = positions
         else:
-            raise TypeError('positions must be list or np.ndarray')
+            raise TypeError("positions must be list or np.ndarray")
         if isinstance(vib_energies, list):
             vib_energies = np.array(vib_energies)
         elif isinstance(vib_energies, np.ndarray):
             pass
         else:
-            raise TypeError('vib_energies must be list or np.ndarray')
+            raise TypeError("vib_energies must be list or np.ndarray")
         self.sigma = symmetrynumber
         self.spin = spin
         if natoms is None:
             if elements:
                 natoms = len(elements)
         # Cut the vibrations to those needed from the geometry.
         if natoms:
-            if geometry == 'nonlinear':
-                self.vib_energies = vib_energies[-(3 * natoms - 6):]
-            elif geometry == 'linear':
-                self.vib_energies = vib_energies[-(3 * natoms - 5):]
-            elif geometry == 'monatomic':
+            if geometry == "nonlinear":
+                self.vib_energies = vib_energies[-(3 * natoms - 6) :]
+            elif geometry == "linear":
+                self.vib_energies = vib_energies[-(3 * natoms - 5) :]
+            elif geometry == "monatomic":
                 self.vib_energies = []
         else:
             self.vib_energies = vib_energies
         # Make sure no imaginary frequencies remain.
         if sum(np.iscomplex(self.vib_energies)):
-            raise ValueError('Imaginary frequencies are present.')
+            raise ValueError("Imaginary frequencies are present.")
         else:
             self.vib_energies = np.real(self.vib_energies)  # clear +0.j
         self.referencepressure = 1.0e5  # Pa
         self.natoms = natoms
 
     def get_ZPE_correction(self):
         """Returns the zero-point vibrational energy correction in eV."""
-        zpe = 0.
+        zpe = 0.0
         for energy in self.vib_energies:
             zpe += 0.5 * energy
         return zpe
-    
+
     def _vibrational_energy_contribution(self, temperature):
         """Calculates the change in internal energy due to vibrations from
         0K to the specified temperature for a set of vibrations given in
         eV and a temperature given in Kelvin. Returns the energy change
         in eV."""
         kT = k * temperature
-        dU = 0.
+        dU = 0.0
         for energy in self.vib_energies:
-            dU += energy / (np.exp(energy / kT) - 1.)
+            dU += energy / (np.exp(energy / kT) - 1.0)
         return dU
-    
+
     def _vibrational_entropy_contribution(self, temperature):
         """Calculates the entropy due to vibrations for a set of vibrations
         given in eV and a temperature given in Kelvin.  Returns the entropy
         in eV/K."""
         kT = k * temperature
-        S_v = 0.
+        S_v = 0.0
         for energy in self.vib_energies:
             x = energy / kT
-            S_v += x / (np.exp(x) - 1.) - np.log(1. - np.exp(-x))
+            S_v += x / (np.exp(x) - 1.0) - np.log(1.0 - np.exp(-x))
         S_v *= k
         return S_v
-    
+
     def get_enthalpy(self, temperature):
         """Returns the enthalpy, in eV, in the ideal gas approximation
         at a specified temperature (K)."""
 
-        fmt = '%-15s%13.3f eV'
-        print('Enthalpy components at T = %.2f K:' % temperature)
-        print('=' * 31)
+        fmt = "%-15s%13.3f eV"
+        print("Enthalpy components at T = %.2f K:" % temperature)
+        print("=" * 31)
 
-        H = 0.
+        H = 0.0
 
-        print(fmt % ('E_pot', self.potentialenergy))
+        print(fmt % ("E_pot", self.potentialenergy))
         H += self.potentialenergy
 
         zpe = self.get_ZPE_correction()
-        print(fmt % ('E_ZPE', zpe))
+        print(fmt % ("E_ZPE", zpe))
         H += zpe
 
-        Cv_t = 3. / 2. * k  # translational heat capacity (3-d gas)
-        print(fmt % ('Cv_trans (0->T)', Cv_t * temperature))
+        Cv_t = 3.0 / 2.0 * k  # translational heat capacity (3-d gas)
+        print(fmt % ("Cv_trans (0->T)", Cv_t * temperature))
         H += Cv_t * temperature
 
-        if self.geometry == 'nonlinear':  # rotational heat capacity
-            Cv_r = 3. / 2. * k
-        elif self.geometry == 'linear':
+        if self.geometry == "nonlinear":  # rotational heat capacity
+            Cv_r = 3.0 / 2.0 * k
+        elif self.geometry == "linear":
             Cv_r = k
-        elif self.geometry == 'monatomic':
-            Cv_r = 0.
-        print(fmt % ('Cv_rot (0->T)', Cv_r * temperature))
+        elif self.geometry == "monatomic":
+            Cv_r = 0.0
+        print(fmt % ("Cv_rot (0->T)", Cv_r * temperature))
         H += Cv_r * temperature
 
         dH_v = self._vibrational_energy_contribution(temperature)
-        print(fmt % ('Cv_vib (0->T)', dH_v))
+        print(fmt % ("Cv_vib (0->T)", dH_v))
         H += dH_v
 
         Cp_corr = k * temperature
-        print(fmt % ('(C_v -> C_p)', Cp_corr))
+        print(fmt % ("(C_v -> C_p)", Cp_corr))
         H += Cp_corr
 
-        print('-' * 31)
-        print(fmt % ('H', H))
-        print('=' * 31)
+        print("-" * 31)
+        print(fmt % ("H", H))
+        print("=" * 31)
         return H
 
     def get_entropy(self, temperature, pressure):
         """Returns the entropy, in eV/K, in the ideal gas approximation
         at a specified temperature (K) and pressure (Pa)."""
 
         if self.elements is None or self.sigma is None or self.spin is None:
-            raise RuntimeError('elements, symmetrynumber, and spin must be '
-                               'specified for entropy and free energy '
-                               'calculations.')
+            raise RuntimeError(
+                "elements, symmetrynumber, and spin must be "
+                "specified for entropy and free energy "
+                "calculations."
+            )
         S = 0.0
         # Translational entropy (term inside the log is in SI units).
         mass = sum(eles2masses(self.elements)) * amu  # kg/molecule
-        S_t = (2 * np.pi * mass * kB *
-               temperature / h**2)**(3.0 / 2)
+        S_t = (2 * np.pi * mass * kB * temperature / h**2) ** (3.0 / 2)
         S_t *= kB * temperature / self.referencepressure
         S_t = k * (np.log(S_t) + 5.0 / 2.0)
         S += S_t
 
         # Rotational entropy (term inside the log is in SI units).
-        if self.geometry == 'monatomic':
+        if self.geometry == "monatomic":
             S_r = 0.0
-        elif self.geometry == 'nonlinear':
-            inertias = (get_ma(self.elements, self.positions, self.natoms) * amu /
-                        (10.0**10)**2)  # kg m^2
+        elif self.geometry == "nonlinear":
+            inertias = (
+                get_ma(self.elements, self.positions, self.natoms)
+                * amu
+                / (10.0**10) ** 2
+            )  # kg m^2
             S_r = np.sqrt(np.pi * np.product(inertias)) / self.sigma
-            S_r *= (8.0 * np.pi**2 * kB * temperature /
-                    h**2)**(3.0 / 2.0)
+            S_r *= (8.0 * np.pi**2 * kB * temperature / h**2) ** (3.0 / 2.0)
             S_r = k * (np.log(S_r) + 3.0 / 2.0)
-        elif self.geometry == 'linear':
-            inertias = (get_ma(self.elements, self.positions, self.natoms) * amu /
-                        (10.0**10)**2)  # kg m^2
+        elif self.geometry == "linear":
+            inertias = (
+                get_ma(self.elements, self.positions, self.natoms)
+                * amu
+                / (10.0**10) ** 2
+            )  # kg m^2
             inertia = max(inertias)  # should be two identical and one zero
-            S_r = (8 * np.pi**2 * inertia * kB * temperature /
-                   self.sigma / h**2)
-            S_r = k * (np.log(S_r) + 1.)
+            S_r = 8 * np.pi**2 * inertia * kB * temperature / self.sigma / h**2
+            S_r = k * (np.log(S_r) + 1.0)
         S += S_r
         # Electronic entropy.
         S_e = k * np.log(2 * self.spin + 1)
         S += S_e
         # Vibrational entropy.
         S_v = self._vibrational_entropy_contribution(temperature)
         S += S_v
         # Pressure correction to translational entropy.
-        S_p = - k * np.log(pressure / self.referencepressure)
+        S_p = -k * np.log(pressure / self.referencepressure)
         S += S_p
         return S
 
     def get_gibbs_energy(self, temperature, pressure):
         """Returns the Gibbs free energy, in eV, in the ideal gas
         approximation at a specified temperature (K) and pressure (Pa)."""
 
-
         H = self.get_enthalpy(temperature)
-        print('')
+        print("")
         S = self.get_entropy(temperature, pressure)
         G = H - temperature * S
 
-        print('')
-        print('Free energy components at T = %.2f K and P = %.1f Pa:' %
-              (temperature, pressure))
-        print('=' * 23)
-        fmt = '%5s%15.3f eV'
-        print(fmt % ('H', H))
-        print(fmt % ('-T*S', -temperature * S))
-        print('-' * 23)
-        print(fmt % ('G', G))
-        print('=' * 23)
+        print("")
+        print(
+            "Free energy components at T = %.2f K and P = %.1f Pa:"
+            % (temperature, pressure)
+        )
+        print("=" * 23)
+        fmt = "%5s%15.3f eV"
+        print(fmt % ("H", H))
+        print(fmt % ("-T*S", -temperature * S))
+        print("-" * 23)
+        print(fmt % ("G", G))
+        print("=" * 23)
         return G
 
-def getTSgas(fretxt='frequency.txt',
-            datafile='.',
-            potentialenergy=0, # eV
-            elements=None,
-            geometry='linear',
-            positions=None, # Angstrom
-            symmetrynumber=1,
-            spin=1,
-            temperature=298.15,
-            pressure=101325):
+
+def getTSgas(
+    fretxt="frequency.txt",
+    datafile=".",
+    potentialenergy=0,  # eV
+    elements=None,
+    geometry="linear",
+    positions=None,  # Angstrom
+    symmetrynumber=1,
+    spin=1,
+    temperature=298.15,
+    pressure=101325,
+):
     """理想气体近似下，计算熵的能量贡献
 
 
     Parameters
     ----------
     fretxt : str
         记录频率信息的文件所在路径, 默认当前路径下的'frequency.txt'
@@ -476,15 +605,15 @@
         对称数
     spin : int
         自旋数
     temperature : float
         温度，单位K
     pressure : float
         压强，单位Pa
-    
+
     Returns
     -------
     TSgas : float
         理想气体近似下，计算熵的能量贡献，单位eV
 
     Examples
     --------
@@ -496,20 +625,20 @@
     >>> TSgas
     0.6790991704342505
     """
     ve = []
     with open(fretxt) as ft:
         lines = ft.readlines()
         for i in range(2, len(lines)):
-            if lines[i].strip()[1] == 'f/i':
-                ve.append(complex(lines[i].split()[-1])/1000)
+            if lines[i].strip()[1] == "f/i":
+                ve.append(complex(lines[i].split()[-1]) / 1000)
             else:
-                ve.append(float(lines[i].split()[-1])/1000)
+                ve.append(float(lines[i].split()[-1]) / 1000)
 
-    if datafile: # skip if datafile is None
+    if datafile:  # skip if datafile is None
         # search datafile in the given directory
         if os.path.isdir(datafile):
             directory = datafile  # specified datafile is actually a directory
             print("您指定了一个文件夹，正在查找相关h5或json文件...")
             if os.path.exists(os.path.join(directory, "frequency.h5")):
                 datafile = os.path.join(directory, "frequency.h5")
                 print("Reading frequency.h5...")
@@ -517,44 +646,49 @@
                 datafile = os.path.join(directory, "frequency.json")
                 print("Reading frequency.json...")
             else:
                 raise FileNotFoundError("未找到frequency.h5/frequency.json文件！")
         if datafile.endswith(".h5"):
             eles = get_ele_from_h5(datafile)
             import h5py
+
             data = h5py.File(datafile)
             poses = np.array(data.get("/AtomInfo/Position")).reshape(-1, 3)
 
         elif datafile.endswith(".json"):
             import json
+
             with open(datafile) as f:
                 data = json.load(f)
-            atoms = data["AtomInfo"]['Atoms']
+            atoms = data["AtomInfo"]["Atoms"]
             eles = []
             poses = []
             for i in range(len(atoms)):
                 eles.append(atoms[i]["Element"])
                 poses.append(atoms[i]["Position"])
         else:
             raise TypeError("仅支持读取h5或json文件！")
     else:
         eles = elements
         poses = positions
 
     # 计算熵的能量贡献
-    thermo = IdealGasThermo(vib_energies=ve, # eV
-                            potentialenergy=potentialenergy, # eV
-                            elements=eles,
-                            geometry=geometry,
-                            positions=poses, # Angstrom
-                            symmetrynumber=symmetrynumber,
-                            spin=spin)
+    thermo = IdealGasThermo(
+        vib_energies=ve,  # eV
+        potentialenergy=potentialenergy,  # eV
+        elements=eles,
+        geometry=geometry,
+        positions=poses,  # Angstrom
+        symmetrynumber=symmetrynumber,
+        spin=spin,
+    )
     S = thermo.get_entropy(temperature, pressure)
 
-    return S*temperature
+    return S * temperature
+
 
 def d_band(spin, dos_data):  # 定义函数，括号里给出函数的两个变量
     """计算d带中心
 
     Parameters
     ----------
     spin : Spin.up或Spin.down
@@ -584,151 +718,14 @@
     M1 = epsilon * N1
     SummaM1 = integrate.simps(M1, epsilon)
     SummaN1 = integrate.simps(N1, epsilon)
 
     return SummaM1 / SummaN1
 
 
-def get_ele_from_h5(hpath: str = "aimd.h5"):
-    """从h5文件中读取元素列表
-
-    Parameters
-    ----------
-    hpath : str
-        h5文件路径
-
-    Returns
-    -------
-    ele : list
-        元素列表, Natom x 1
-
-    Examples
-    --------
-    >>> from dspawpy.io.utils import get_ele_from_h5
-    >>> ele = get_ele_from_h5(hpath='aimd.h5')
-    ['H', 'H', 'O']
-    """
-    import h5py
-
-    data = h5py.File(hpath)
-    Elements_bytes = np.array(data.get("/AtomInfo/Elements"))
-    tempdata = np.array([i.decode() for i in Elements_bytes])
-    ele = "".join(tempdata).split(";")
-
-    return ele
-
-
-def get_pos_ele_lat(spath: str):
-    """从DSPAW的as结构文件中读取坐标、元素列表，和晶胞信息
-
-    Parameters
-    ----------
-    spath : str
-        结构文件路径
-
-    Returns
-    -------
-    pos : np.ndarray
-        坐标分量数组，Natom x 3
-    ele : list
-        元素列表, Natom x 1
-    latv : np.ndarray
-        晶胞矢量数组，3 x 3
-
-    Examples
-    --------
-    >>> from dspawpy.io.utils import get_pos_ele_lat
-    >>> pos, ele, latv = get_pos_ele_lat(spath='structure.as')
-    >>> pos
-    array([[ 0.        ,  0.        ,  9.06355632],
-           [ 1.59203323,  0.91916082, 10.62711265],
-           [ 1.59203323,  0.91916082,  7.5       ]])
-    >>> ele
-    ['Mo', 'S', 'S']
-    >>> latv
-    array([[ 3.18406646,  0.        ,  0.        ],
-           [-1.59203323,  2.75748245,  0.        ],
-           [ 0.        ,  0.        , 30.        ]])
-    """
-
-    with open(spath, "r") as f:
-        lines = f.readlines()
-        Natom = int(lines[1])  # 原子总数
-        ele = [line.split()[0] for line in lines[7 : 7 + Natom]]  # 元素列表
-
-        # 晶格矢量
-        latv = np.array([line.split()[0:3] for line in lines[3:6]], dtype=float)
-        # xyz坐标分量
-        coord = np.array(
-            [line.split()[1:4] for line in lines[7 : 7 + Natom]], dtype=float
-        )
-        if lines[6].startswith("C"):
-            pos = coord
-        elif lines[6].startswith("D"):  # 分数 --> 笛卡尔
-            pos = np.dot(coord, latv)
-        else:
-            raise ValueError(f"{spath}中的坐标类型未知！")
-
-    return pos, ele, latv
-
-
-def get_spo_ele_lat(spath: str):
-    """从DSPAW的as结构文件中读取分数坐标、元素列表，和晶胞信息
-
-    Parameters
-    ----------
-    spath : str
-        结构文件路径
-
-    Returns
-    -------
-    spos : np.ndarray
-        分数坐标分量数组，Natom x 3
-    ele : list
-        元素列表, Natom x 1
-    latv : np.ndarray
-        晶胞矢量数组，3 x 3
-
-    Examples
-    --------
-    >>> from dspawpy.io.utils import get_spo_ele_lat
-    >>> spos, ele, latv = get_spo_ele_lat(spath='structure.as')
-    >>> spos
-    array([[0.        , 0.        , 0.30211854],
-           [0.66666667, 0.33333333, 0.35423709],
-           [0.66666667, 0.33333333, 0.25      ]])
-    >>> ele
-    ['Mo', 'S', 'S']
-    >>> latv
-    array([[ 3.18406646,  0.        ,  0.        ],
-           [-1.59203323,  2.75748245,  0.        ],
-           [ 0.        ,  0.        , 30.        ]])
-    """
-
-    with open(spath, "r") as f:
-        lines = f.readlines()
-        Natom = int(lines[1])  # 原子总数
-        ele = [line.split()[0] for line in lines[7 : 7 + Natom]]  # 元素列表
-
-        # 晶格矢量
-        latv = np.array([line.split() for line in lines[3:6]], dtype=float)
-        # xyz坐标分量
-        coord = np.array(
-            [line.split()[1:4] for line in lines[7 : 7 + Natom]], dtype=float
-        )
-        if lines[6].startswith("C"):  # 笛卡尔 --> 分数坐标
-            spos = np.linalg.solve(latv.T, np.transpose(coord)).T
-        elif lines[6].startswith("D"):
-            spos = coord
-        else:
-            raise ValueError(f"{spath}中的坐标类型未知！")
-
-    return spos, ele, latv
-
-
 def getZPE(fretxt: str = "frequency.txt"):
     """从fretext中读取数据，计算ZPE
 
     将另外保存结果到 ZPE_TS.dat 中
 
     Parameters
     ----------
@@ -758,15 +755,15 @@
             if data_line[1] == "f":
                 data_get_ZPE.append(float(data_line[5]))
 
     data_get_ZPE = np.array(data_get_ZPE)
 
     # 2. printout to check
     print(f"=== 从{fretxt}中读取到的相关如下 ===")
-    dt = pd.DataFrame({'Frequency (meV)':data_get_ZPE}, index=None)
+    dt = pd.DataFrame({"Frequency (meV)": data_get_ZPE}, index=None)
     print(dt)
 
     if len(data_get_ZPE) == 0:
         raise ValueError("全是虚频，请考虑重新优化结构...")
     else:
         print("\n正在写入ZPE.dat文件...")
         np.savetxt(
@@ -784,14 +781,15 @@
     print("\n--> Zero-point energy,  ZPE (eV):", ZPE)
 
     with open("ZPE.dat", "a") as f:
         f.write(f"\n--> Zero-point energy,  ZPE (eV): {ZPE}")
 
     return ZPE
 
+
 def getTSads(fretxt: str = "frequency.txt", T: float = 298.15):
     """从fretext中读取数据，计算ZPE和TS
 
     将另外保存结果到 ZPE_TS.dat 中
 
     Parameters
     ----------
@@ -821,15 +819,15 @@
             if data_line[1] == "f":
                 data_get_TS.append(float(data_line[2]))
 
     data_get_TS = np.array(data_get_TS)
 
     # 2. printout to check
     print(f"=== 从{fretxt}中读取到的相关如下 ===")
-    dt = pd.DataFrame({'Frequency (THz)':data_get_TS}, index=None)
+    dt = pd.DataFrame({"Frequency (THz)": data_get_TS}, index=None)
     print(dt)
 
     if len(data_get_TS) == 0:
         raise ValueError("全是虚频，请考虑重新优化结构...")
     else:
         print("\n正在写入TS.dat文件...")
         np.savetxt(
@@ -893,53 +891,7 @@
     0.18362317157111566
     """
 
     ZPE = getZPE(fretxt=fretxt)
     sum_S = getTSads(fretxt=fretxt, T=T)
 
     return ZPE, sum_S
-
-
-
-def get_lines_without_comment(filename: str, comment: str = "#") -> List[str]:
-    lines = []
-    with open(filename) as file:
-        while True:
-            line = file.readline()
-            if line:
-                line = re.sub(comment + r".*$", "", line)  # remove comment
-                line = line.strip()
-                if line:
-                    lines.append(line)
-            else:
-                break
-
-    return lines
-
-
-def _get_coordinateType_from_h5(hpath: str = "aimd.h5"):
-    """从h5文件中读取坐标类型
-
-    Parameters
-    ----------
-    hpath : str
-        h5文件路径
-
-    Returns
-    -------
-    coordinateType : list
-        坐标类型
-
-    Examples
-    --------
-    >>> from dspawpy.io.utils import get_coordinateType_from_h5
-    >>> coordinateType = get_coordinateType_from_h5(hpath='scf.h5')
-    ['Cartesian']
-    """
-    import h5py
-
-    data = h5py.File(hpath)
-    CoordinateType = np.array(data.get("/AtomInfo/CoordinateType"))
-    tempdata = np.array([i.decode() for i in CoordinateType])
-    coordinateType = "".join(tempdata).split(";")[0]
-
-    return coordinateType
```

## dspawpy/io/write.py

```diff
@@ -1,12 +1,184 @@
-# -*- coding: utf-8 -*-
+"""
+Functions to write files
+"""
+
 import json
+import os
+
 import numpy as np
-from typing import Dict, List
-from dspawpy.io.read import load_h5
+
+from dspawpy.io.read import (_get_lammps_non_orthogonal_box, _sinfo_from_h5,
+                             _sinfo_from_json, load_h5)
+
+
+def write_xyz_traj(
+    datafile="aimd.h5",
+    ai=None,
+    ele=None,
+    index=None,
+    xyzfile="aimdTraj.xyz",
+):
+    """保存xyz格式的轨迹文件
+
+    Parameters
+    ----------
+    datafile : str or list
+        DSPAW计算完成后保存的h5/json文件或包含它们的文件夹路径
+    ai : int
+        原子编号列表（体系中的第几号原子，不是质子数）
+    ele : str
+        元素，例如 'C'，'H'，'O'，'N'
+    index : int
+        优化过程中的第几步
+
+    Returns
+    -------
+    xyzfile: str
+        写入xyz格式的轨迹文件，默认为aimdTraj.xyz
+
+    Example
+    -------
+    >>> from dspawpy.analysis.aimdtools import write_xyz_traj
+    >>> write_xyz_traj(datafile='aimd.h5', ai=[1,2,3], index=1, xyzfile='aimdTraj.xyz')
+    """
+    if isinstance(datafile, list):
+        for i, df in enumerate(datafile):
+            write_xyz_traj(df, ai, ele, index, str(i + 1) + xyzfile)
+        return f"{xyzfile} 文件已保存！"
+    # search datafile in the given directory
+    elif os.path.isdir(datafile):
+        directory = datafile  # specified datafile is actually a directory
+        print("您指定了一个文件夹，正在查找相关h5或json文件...")
+        if os.path.exists(os.path.join(directory, "aimd.h5")):
+            datafile = os.path.join(directory, "aimd.h5")
+            print("Reading aimd.h5...")
+        elif os.path.exists(os.path.join(directory, "aimd.json")):
+            datafile = os.path.join(directory, "aimd.json")
+            print("Reading aimd.json...")
+        else:
+            raise FileNotFoundError("未找到aimd.h5/aimd.json文件！")
+    if datafile.endswith(".h5"):
+        Nstep, eles, poses, lats, line6s = _sinfo_from_h5(datafile, index, ele, ai)
+    elif datafile.endswith(".json"):
+        Nstep, eles, poses, lats, line6s = _sinfo_from_json(datafile, index, ele, ai)
+    else:
+        raise TypeError("仅支持读取h5或json文件！")
+
+    # 写入文件
+    with open(xyzfile, "w") as f:
+        # Nstep
+        for n in range(Nstep):
+            # 原子数不会变，就是不合并的元素总数
+            f.write("%d\n" % len(eles))
+            # lattice
+            f.write(
+                'Lattice="%f %f %f %f %f %f %f %f %f" Properties=species:S:1:pos:R:3 pbc="T T T"\n'
+                % (
+                    lats[n, 0, 0],
+                    lats[n, 0, 1],
+                    lats[n, 0, 2],
+                    lats[n, 1, 0],
+                    lats[n, 1, 1],
+                    lats[n, 1, 2],
+                    lats[n, 2, 0],
+                    lats[n, 2, 1],
+                    lats[n, 2, 2],
+                )
+            )
+            # position and element
+            for i in range(len(eles)):
+                f.write(
+                    "%s %f %f %f\n"
+                    % (eles[i], poses[n, i, 0], poses[n, i, 1], poses[n, i, 2])
+                )
+    print(f"{xyzfile} 文件已保存！")
+
+
+def write_dump_traj(
+    datafile="aimd.h5",
+    ai=None,
+    ele=None,
+    index=None,
+    dumpfile="aimdTraj.dump",
+):
+    """保存为lammps的dump格式的轨迹文件，暂时只支持正交晶胞
+
+    Parameters
+    ----------
+    datafile : str or list
+        DSPAW计算完成后保存的h5/json文件或包含它们的文件夹路径
+    ai : int
+        原子编号列表（体系中的第几号原子，不是质子数）
+    ele : str
+        元素，例如 'C'，'H'，'O'，'N'
+    index : int
+        优化过程中的第几步
+
+    Returns
+    -------
+    dumpfile: str
+        写入dump格式的轨迹文件，默认为aimdTraj.dump
+
+    Example
+    -------
+    >>> from dspawpy.analysis.aimdtools import write_dump_traj
+    >>> write_dump_traj(datafile='aimd.h5', ai=[1,2,3], index=1, dumpfile='aimdTraj.dump')
+    """
+    if isinstance(datafile, list):
+        for i, df in enumerate(datafile):
+            write_dump_traj(df, ai, ele, index, str(i + 1) + dumpfile)
+        return f"{dumpfile} 文件已保存！"
+    # search datafile in the given directory
+    elif os.path.isdir(datafile):
+        directory = datafile  # specified datafile is actually a directory
+        print("您指定了一个文件夹，正在查找相关h5或json文件...")
+        if os.path.exists(os.path.join(directory, "aimd.h5")):
+            datafile = os.path.join(directory, "aimd.h5")
+            print("Reading aimd.h5...")
+        elif os.path.exists(os.path.join(directory, "aimd.json")):
+            datafile = os.path.join(directory, "aimd.json")
+            print("Reading aimd.json...")
+        else:
+            raise FileNotFoundError("未找到aimd.h5/aimd.json文件！")
+    if datafile.endswith(".h5"):
+        Nstep, eles, poses, lats, line6s = _sinfo_from_h5(datafile, index, ele, ai)
+    elif datafile.endswith(".json"):
+        Nstep, eles, poses, lats, line6s = _sinfo_from_json(datafile, index, ele, ai)
+    else:
+        raise TypeError("仅支持读取h5或json文件！")
+
+    # 写入文件
+    with open(dumpfile, "w") as f:
+        for n in range(Nstep):
+            box_bounds = _get_lammps_non_orthogonal_box(lats[n])
+            f.write("ITEM: TIMESTEP\n%d\n" % n)
+            f.write("ITEM: NUMBER OF ATOMS\n%d\n" % (len(eles)))
+            f.write("ITEM: BOX BOUNDS xy xz yz xx yy zz\n")
+            f.write(
+                "%f %f %f\n%f %f %f\n %f %f %f\n"
+                % (
+                    box_bounds[0][0],
+                    box_bounds[0][1],
+                    box_bounds[0][2],
+                    box_bounds[1][0],
+                    box_bounds[1][1],
+                    box_bounds[1][2],
+                    box_bounds[2][0],
+                    box_bounds[2][1],
+                    box_bounds[2][2],
+                )
+            )
+            f.write("ITEM: ATOMS type x y z id\n")
+            for i in range(len(eles)):
+                f.write(
+                    "%s %f %f %f %d\n"
+                    % (eles[i], poses[n, i, 0], poses[n, i, 1], poses[n, i, 2], i + 1)
+                )
+    print(f"{dumpfile} 文件已保存！")
 
 
 def write_VESTA(in_filename: str, data_type, out_filename="DS-PAW.vesta"):
     """从包含电子体系信息的json或h5文件中读取数据并写入VESTA格式的文件中
 
     Parameters
     ----------
@@ -71,14 +243,15 @@
             )
         else:
             raise NotImplementedError("仅支持rho/potential/elf/pcharge/boundcharge")
 
     else:
         raise NotImplementedError("仅支持json或h5格式文件")
 
+
 def write_delta_rho_vesta(AB, A, B, output="delta_rho.vesta"):
     """电荷密度差分可视化
 
     DeviceStudio暂不支持大文件，临时写成可以用VESTA打开的格式
 
     Parameters
     ----------
@@ -100,15 +273,15 @@
     --------
     >>> from dspawpy.io.write import write_delta_rho_vesta
     >>> write_delta_rho_vesta('AB.h5', 'A.h5', 'B.h5', 'delta_rho.vesta')
     >>> write_delta_rho_vesta('AB.json', 'A.json', 'B.json', 'delta_rho.vesta')
     # 甚至可以混写
     >>> write_delta_rho_vesta('AB.h5', 'A.json', 'B.json', 'delta_rho.vesta')
     """
-    print(f'读取{AB}...')
+    print(f"读取{AB}...")
     if AB.endswith(".h5"):
         dataAB = load_h5(AB)
         rhoAB = np.array(dataAB["/Rho/TotalCharge"])
         nGrids = dataAB["/AtomInfo/Grid"]
         atom_symbol = dataAB["/AtomInfo/Elements"]
         atom_pos = dataAB["/AtomInfo/Position"]
         latticeConstantMatrix = dataAB["/AtomInfo/Lattice"]
@@ -125,50 +298,50 @@
             atom_pos.append(dataAB["AtomInfo"]["Atoms"][i]["Position"])
         atom_pos = np.array(atom_pos)
 
         latticeConstantMatrix = dataAB["AtomInfo"]["Lattice"]
     else:
         raise ValueError(f"file format must be either h5 or json: {AB}")
 
-    print(f'读取{A}...')
+    print(f"读取{A}...")
     if A.endswith(".h5"):
         dataA = load_h5(A)
         rhoA = np.array(dataA["/Rho/TotalCharge"])
     elif A.endswith(".json"):
         with open(A, "r") as f2:
             dataA = json.load(f2)
             rhoA = np.array(dataA["Rho"]["TotalCharge"])
     else:
         raise ValueError(f"file format must be either h5 or json: {A}")
 
-    print(f'读取{B}...')
+    print(f"读取{B}...")
     if B.endswith(".h5"):
         dataB = load_h5(B)
         rhoB = np.array(dataB["/Rho/TotalCharge"])
     elif B.endswith(".json"):
         with open(B, "r") as f3:
             dataB = json.load(f3)
             rhoB = np.array(dataB["Rho"]["TotalCharge"])
     else:
         raise ValueError(f"file format must be either h5 or json: {B}")
 
-    print(f'计算电荷差分...')
+    print(f"计算电荷差分...")
     rho = rhoAB - rhoA - rhoB
     rho = np.array(rho).reshape(nGrids[0], nGrids[1], nGrids[2])
 
     element = list(set(atom_symbol))
     element = sorted(set(atom_symbol), key=atom_symbol.index)
     element_num = np.zeros(len(element))
     for i in range(len(element)):
         element_num[i] = atom_symbol.count(element[i])
 
     latticeConstantMatrix = np.array(latticeConstantMatrix)
     latticeConstantMatrix = latticeConstantMatrix.reshape(3, 3)
 
-    print(f'写入文件{output}...')
+    print(f"写入文件{output}...")
     with open(output, "w") as out:
         out.write("DS-PAW_rho\n")
         out.write("    1.000000\n")
         for i in range(3):
             for j in range(3):
                 out.write("    " + str(latticeConstantMatrix[i, j]) + "    ")
             out.write("\n")
@@ -202,17 +375,23 @@
     print(f"成功写入 {output}")
 
 
 def write_atoms(fileobj, hdf5):
     fileobj.write("DS-PAW Structure\n")
     fileobj.write("  1.00\n")
     lattice = np.asarray(hdf5["/AtomInfo/Lattice"]).reshape(-1, 1)  # 将列表lattice下的多个列表整合
-    fileobj.write("%10.6f %10.6f %10.6f\n" % (lattice[0][0], lattice[1][0], lattice[2][0]))
-    fileobj.write("%10.6f %10.6f %10.6f\n" % (lattice[3][0], lattice[4][0], lattice[5][0]))
-    fileobj.write("%10.6f %10.6f %10.6f\n" % (lattice[6][0], lattice[7][0], lattice[8][0]))
+    fileobj.write(
+        "%10.6f %10.6f %10.6f\n" % (lattice[0][0], lattice[1][0], lattice[2][0])
+    )
+    fileobj.write(
+        "%10.6f %10.6f %10.6f\n" % (lattice[3][0], lattice[4][0], lattice[5][0])
+    )
+    fileobj.write(
+        "%10.6f %10.6f %10.6f\n" % (lattice[6][0], lattice[7][0], lattice[8][0])
+    )
 
     elements = hdf5["/AtomInfo/Elements"]
     elements_set = []
     elements_number = {}
     for e in elements:
         if e in elements_set:
             elements_number[e] = elements_number[e] + 1
@@ -234,15 +413,15 @@
     for i, p in enumerate(hdf5["/AtomInfo/Position"]):
         fileobj.write("%10.6f" % p)
         if (i + 1) % 3 == 0:
             fileobj.write("\n")
     fileobj.write("\n")
 
 
-def write_VESTA_format(hdf5: Dict, datakeys: list, filename):
+def write_VESTA_format(hdf5: dict, datakeys: list, filename):
     with open(filename, "w") as file:
         write_atoms(file, hdf5)
         for key in datakeys:
             d = np.asarray(hdf5[key]).reshape(-1, 1)  # 将列表hdf5[key]下的多个列表整合
             file.write("%5d %5d %5d\n" % tuple(hdf5["/AtomInfo/Grid"]))
             i = 0
             while i < len(d):
@@ -287,15 +466,15 @@
     else:
         fileobj.write("Cartesian\n")
     for atom in atom_info["Atoms"]:
         fileobj.write("%10.6f %10.6f %10.6f\n" % tuple(atom["Position"]))
     fileobj.write("\n")
 
 
-def write_VESTA_format_json(atom_info: Dict, data: List, filename):
+def write_VESTA_format_json(atom_info: dict, data: list, filename):
     with open(filename, "w") as file:
         write_atoms_json(file, atom_info)
         for d in data:
             file.write("%5d %5d %5d\n" % tuple(atom_info["Grid"]))
             i = 0
             while i < len(d):
                 for j in range(10):
```

## dspawpy/io/write_json.py

```diff
@@ -1,11 +1,9 @@
 # -*- coding: utf-8 -*-
 
-from typing import Dict, List
-
 
 def write_atoms(fileobj, atom_info):
     fileobj.write("DS-PAW Structure\n")
     fileobj.write("  1.00\n")
     lattice = atom_info["Lattice"]
 
     fileobj.write("%10.6f %10.6f %10.6f\n" % (lattice[0], lattice[1], lattice[2]))
@@ -34,15 +32,15 @@
     else:
         fileobj.write("Cartesian\n")
     for atom in atom_info["Atoms"]:
         fileobj.write("%10.6f %10.6f %10.6f\n" % tuple(atom["Position"]))
     fileobj.write("\n")
 
 
-def write_VESTA_format(atom_info: Dict, data: List, filename="DS-PAW.vesta"):
+def write_VESTA_format(atom_info: dict, data: list, filename="DS-PAW.vesta"):
     with open(filename, "w") as file:
         write_atoms(file, atom_info)
         for d in data:
             file.write("%5d %5d %5d\n" % tuple(atom_info["Grid"]))
             i = 0
             while i < len(d):
                 for j in range(10):
```

## Comparing `dspawpy-0.8.9.dist-info/METADATA` & `dspawpy-0.9.0.dist-info/METADATA`

 * *Files 10% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: dspawpy
-Version: 0.8.9
+Version: 0.9.0
 Summary: Tools for dspaw
 Home-page: http://www.hzwtech.com/
 Author: Hzwtech
 License: MIT
 Requires-Python: >=3
 Description-Content-Type: text/markdown
 Requires-Dist: pymatgen (>=2021.2.8.1)
@@ -27,14 +27,20 @@
 
 再重新用pip安装。
 
 详见 https://stackoverflow.com/questions/75542688/conda-installed-pip-failed-to-find-packages/75542962#75542962
 
 ## 版本更新简述
 
+### 0.9.0
+
+- 重要变更： 一些函数合并、所在模块迁移，请确认版本
+- 新增功能： 支持读取含多离子步计算结果的h5/json文件中的磁矩信息
+- BUG修复： get_band_data 函数指定efermi不生效
+
 ### 0.8.9
 
 - BUG修复： d_band 脚本运行错误
 
 ### 0.8.8
 
 - 新增功能： 支持读取正在进行中的NEB信息，生成movie轨迹文件（可用DS打开观察）
```

## Comparing `dspawpy-0.8.9.dist-info/RECORD` & `dspawpy-0.9.0.dist-info/RECORD`

 * *Files 10% similar despite different names*

```diff
@@ -1,20 +1,20 @@
 dspawpy/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-dspawpy/plot.py,sha256=WzzhfAHx0l4FcZXlp5fhb47DCAtjGwLBcs0El-epuQg,29176
+dspawpy/plot.py,sha256=ocLkU08WfMb2fyETrBSSZvxZFSg2sPX8rLusXZLT5BM,29208
 dspawpy/analysis/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-dspawpy/analysis/aimdtools.py,sha256=7nBbJ3EfyVxXqmbd5M-MK6wl66YvGCk-gWjatU7fK84,47547
+dspawpy/analysis/aimdtools.py,sha256=olmINWb4xRDZvdBohA2oUE3KzBiWq508w5DdslTEAWI,23956
 dspawpy/analysis/vacf.py,sha256=g5IS6Q7QGYa17XBVnYEH-MubGSpkUsDPpMaI_ELacw4,20152
 dspawpy/diffusion/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-dspawpy/diffusion/neb.py,sha256=0T8DDWlkLf1CHga4dncxF0muSXwH2-v2ZH6ZIqZKPP0,9607
-dspawpy/diffusion/nebtools.py,sha256=AGXQFx9C3CRboBOx4BsLXHkYzBVZsCVpdZbGJr7h3zU,52973
-dspawpy/diffusion/pathfinder.py,sha256=61n6qyeMZqFRwKnSb_xHlO7EXZGa45u6z-q9r_0xilk,10993
+dspawpy/diffusion/neb.py,sha256=dQEofdCZ7MbRwdfQKzp1_YMZwyZDcYceBYjXyahXL1c,9639
+dspawpy/diffusion/nebtools.py,sha256=4z0hFkGABLXFKugTTw6vaw-Sf2fUn0okBAdUmwL7RSk,53458
+dspawpy/diffusion/pathfinder.py,sha256=HhCVoh42Q2qIksBAruZ1atULfR5D55uzZvbaCtUxSig,11045
 dspawpy/io/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-dspawpy/io/read.py,sha256=A91X05HqvNVBmTDdjrmSb0J-oG3Wm196tOSGIYWrEsw,21646
-dspawpy/io/read_json.py,sha256=hDQK5lXHOQqEBvnxv6xczFdC3gl5kUhawmOq4i_gqlU,7910
-dspawpy/io/structure.py,sha256=THOd8pvna2u_Zb7FQBBFtKmPYiNaA9OdYzRtQnlEkN0,10331
-dspawpy/io/utils.py,sha256=CqTkTWftx05y--Aco9seJvfzYA9ZB2NceJROkA1i_T4,29454
-dspawpy/io/write.py,sha256=m9kcQIeG3fGNgd5Sw6Dl2a3jfS_M5OZp-AZY5bPPXI4,11045
-dspawpy/io/write_json.py,sha256=PZcu-7K-Yz97Jqh_q15P7dYqt66qspnmUboUPTQKMO8,1794
-dspawpy-0.8.9.dist-info/METADATA,sha256=R4zMj6LhU3jVnalqvhKKKbbCcNL9t06RmZkRxvZ6_VM,1523
-dspawpy-0.8.9.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
-dspawpy-0.8.9.dist-info/top_level.txt,sha256=esEMNTnd880qHE4wkZVKM3gzqZMuOobS886owAyaUmA,8
-dspawpy-0.8.9.dist-info/RECORD,,
+dspawpy/io/read.py,sha256=aq8LtjRqKHzBGmgP3gScovh4qdabe0T5cmY9L022t9k,41491
+dspawpy/io/read_json.py,sha256=2bcNQP51SR2yMyFE7c2TIutYp93K8IH-dpLmH5yy4bo,7721
+dspawpy/io/structure.py,sha256=CTENSGY9bEX0B3BCY4mgQYu20TEYOBOlgNNHJhgkREA,13268
+dspawpy/io/utils.py,sha256=1VDBKhXHiM0er2nGcHhu6_wD4cLpteOhS6W0UxT3MMo,25265
+dspawpy/io/write.py,sha256=7y35-1RxtjE3moma8ke9BUZKsyMFuJRLVRcz6AiJJ_k,17401
+dspawpy/io/write_json.py,sha256=n3GhdDnFFtW7eY4U5u7czdlpbSWnsGP7WUD5eS1ZmqI,1761
+dspawpy-0.9.0.dist-info/METADATA,sha256=HSirmPHTTKR0-WmU6ZKp0ihYBbOzuTSKKhWymnWRiT4,1766
+dspawpy-0.9.0.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
+dspawpy-0.9.0.dist-info/top_level.txt,sha256=esEMNTnd880qHE4wkZVKM3gzqZMuOobS886owAyaUmA,8
+dspawpy-0.9.0.dist-info/RECORD,,
```


# Comparing `tmp/habu_snowflake_cli-3.6.4-py3-none-any.whl.zip` & `tmp/habu_snowflake_cli-4.0.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,37 +1,37 @@
-Zip file size: 32989 bytes, number of entries: 35
--rw-r--r--  2.0 unx      351 b- defN 23-Apr-07 16:42 redbeard.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-07 16:42 redbeard_cli/__init__.py
--rw-r--r--  2.0 unx      122 b- defN 23-Apr-07 16:42 redbeard_cli/file_utils.py
--rw-r--r--  2.0 unx     4580 b- defN 23-Apr-07 16:42 redbeard_cli/snowflake_utils.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-07 16:42 redbeard_cli/commands/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-07 16:42 redbeard_cli/commands/init/__init__.py
--rw-r--r--  2.0 unx     2109 b- defN 23-Apr-07 16:42 redbeard_cli/commands/init/clean_room_setup.py
--rw-r--r--  2.0 unx     2259 b- defN 23-Apr-07 16:42 redbeard_cli/commands/init/cli.py
--rw-r--r--  2.0 unx     3686 b- defN 23-Apr-07 16:42 redbeard_cli/commands/init/habu_setup.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-07 16:42 redbeard_cli/example/__init__.py
--rw-r--r--  2.0 unx     5110 b- defN 23-Apr-07 16:42 redbeard_cli/example/dataset.py
--rw-r--r--  2.0 unx     5678 b- defN 23-Apr-07 16:42 redbeard_cli/example/overlap_queries.py
--rw-r--r--  2.0 unx     3438 b- defN 23-Apr-07 16:42 redbeard_cli/sqlfiles/R__1init_habu_installer.sql
--rw-r--r--  2.0 unx     8620 b- defN 23-Apr-07 16:42 redbeard_cli/sqlfiles/R__create_new_dataset.sql
--rw-r--r--  2.0 unx      772 b- defN 23-Apr-07 16:42 redbeard_cli/sqlfiles/R__handle_error.sql
--rw-r--r--  2.0 unx     3427 b- defN 23-Apr-07 16:42 redbeard_cli/sqlfiles/R__handle_management_command.sql
--rw-r--r--  2.0 unx     8179 b- defN 23-Apr-07 16:42 redbeard_cli/sqlfiles/R__handle_new_cleanrooms.sql
--rw-r--r--  2.0 unx     2101 b- defN 23-Apr-07 16:42 redbeard_cli/sqlfiles/R__init_habu_shares.sql
--rw-r--r--  2.0 unx     8847 b- defN 23-Apr-07 16:42 redbeard_cli/sqlfiles/R__new_data_connection.sql
--rw-r--r--  2.0 unx     8719 b- defN 23-Apr-07 16:42 redbeard_cli/sqlfiles/R__new_question_run.sql
--rw-r--r--  2.0 unx     5008 b- defN 23-Apr-07 16:42 redbeard_cli/sqlfiles/R__post_run_query.sql
--rw-r--r--  2.0 unx     1240 b- defN 23-Apr-07 16:42 redbeard_cli/sqlfiles/R__process_request.sql
--rw-r--r--  2.0 unx     4658 b- defN 23-Apr-07 16:42 redbeard_cli/sqlfiles/R__question_run_cleanup.sql
--rw-r--r--  2.0 unx     4992 b- defN 23-Apr-07 16:42 redbeard_cli/sqlfiles/R__question_run_data_share.sql
--rw-r--r--  2.0 unx     4066 b- defN 23-Apr-07 16:42 redbeard_cli/sqlfiles/R__setup_cleanroom_common.sql
--rw-r--r--  2.0 unx     3181 b- defN 23-Apr-07 16:42 redbeard_cli/sqlfiles/R__setup_data_connection_objects.sql
--rw-r--r--  2.0 unx     5641 b- defN 23-Apr-07 16:42 redbeard_cli/sqlfiles/R__setup_streams_tasks.sql
--rw-r--r--  2.0 unx      603 b- defN 23-Apr-07 16:42 redbeard_cli/sqlfiles/R__sp_logger.sql
--rw-r--r--  2.0 unx      230 b- defN 23-Apr-07 16:42 redbeard_cli/sqlfiles/V1_0_0_create.sql
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-07 16:42 redbeard_cli/sqlfiles/__init__.py
--rw-r--r--  2.0 unx     1370 b- defN 23-Apr-07 16:42 habu_snowflake_cli-3.6.4.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Apr-07 16:42 habu_snowflake_cli-3.6.4.dist-info/WHEEL
--rw-r--r--  2.0 unx       42 b- defN 23-Apr-07 16:42 habu_snowflake_cli-3.6.4.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       22 b- defN 23-Apr-07 16:42 habu_snowflake_cli-3.6.4.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     3356 b- defN 23-Apr-07 16:42 habu_snowflake_cli-3.6.4.dist-info/RECORD
-35 files, 102499 bytes uncompressed, 27425 bytes compressed:  73.2%
+Zip file size: 35162 bytes, number of entries: 35
+-rw-r--r--  2.0 unx      351 b- defN 23-Apr-26 18:34 redbeard.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-26 18:34 redbeard_cli/__init__.py
+-rw-r--r--  2.0 unx      122 b- defN 23-Apr-26 18:34 redbeard_cli/file_utils.py
+-rw-r--r--  2.0 unx     4580 b- defN 23-Apr-26 18:34 redbeard_cli/snowflake_utils.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-26 18:34 redbeard_cli/commands/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-26 18:34 redbeard_cli/commands/init/__init__.py
+-rw-r--r--  2.0 unx     2109 b- defN 23-Apr-26 18:34 redbeard_cli/commands/init/clean_room_setup.py
+-rw-r--r--  2.0 unx     2259 b- defN 23-Apr-26 18:34 redbeard_cli/commands/init/cli.py
+-rw-r--r--  2.0 unx     3686 b- defN 23-Apr-26 18:34 redbeard_cli/commands/init/habu_setup.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-26 18:34 redbeard_cli/example/__init__.py
+-rw-r--r--  2.0 unx     5110 b- defN 23-Apr-26 18:34 redbeard_cli/example/dataset.py
+-rw-r--r--  2.0 unx     5678 b- defN 23-Apr-26 18:34 redbeard_cli/example/overlap_queries.py
+-rw-r--r--  2.0 unx     3449 b- defN 23-Apr-26 18:34 redbeard_cli/sqlfiles/R__1init_habu_installer.sql
+-rw-r--r--  2.0 unx    10769 b- defN 23-Apr-26 18:34 redbeard_cli/sqlfiles/R__create_new_dataset.sql
+-rw-r--r--  2.0 unx      772 b- defN 23-Apr-26 18:34 redbeard_cli/sqlfiles/R__handle_error.sql
+-rw-r--r--  2.0 unx     3403 b- defN 23-Apr-26 18:34 redbeard_cli/sqlfiles/R__handle_management_command.sql
+-rw-r--r--  2.0 unx    14012 b- defN 23-Apr-26 18:34 redbeard_cli/sqlfiles/R__handle_new_cleanrooms.sql
+-rw-r--r--  2.0 unx     2092 b- defN 23-Apr-26 18:34 redbeard_cli/sqlfiles/R__init_habu_shares.sql
+-rw-r--r--  2.0 unx     8799 b- defN 23-Apr-26 18:34 redbeard_cli/sqlfiles/R__new_data_connection.sql
+-rw-r--r--  2.0 unx    10879 b- defN 23-Apr-26 18:34 redbeard_cli/sqlfiles/R__new_question_run.sql
+-rw-r--r--  2.0 unx     4960 b- defN 23-Apr-26 18:34 redbeard_cli/sqlfiles/R__post_run_query.sql
+-rw-r--r--  2.0 unx     1232 b- defN 23-Apr-26 18:34 redbeard_cli/sqlfiles/R__process_request.sql
+-rw-r--r--  2.0 unx     5624 b- defN 23-Apr-26 18:34 redbeard_cli/sqlfiles/R__question_run_cleanup.sql
+-rw-r--r--  2.0 unx     6346 b- defN 23-Apr-26 18:34 redbeard_cli/sqlfiles/R__question_run_data_share.sql
+-rw-r--r--  2.0 unx     4063 b- defN 23-Apr-26 18:34 redbeard_cli/sqlfiles/R__setup_cleanroom_common.sql
+-rw-r--r--  2.0 unx     3173 b- defN 23-Apr-26 18:34 redbeard_cli/sqlfiles/R__setup_data_connection_objects.sql
+-rw-r--r--  2.0 unx     5653 b- defN 23-Apr-26 18:34 redbeard_cli/sqlfiles/R__setup_streams_tasks.sql
+-rw-r--r--  2.0 unx      603 b- defN 23-Apr-26 18:34 redbeard_cli/sqlfiles/R__sp_logger.sql
+-rw-r--r--  2.0 unx      230 b- defN 23-Apr-26 18:34 redbeard_cli/sqlfiles/V1_0_0_create.sql
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-26 18:34 redbeard_cli/sqlfiles/__init__.py
+-rw-r--r--  2.0 unx     1370 b- defN 23-Apr-26 18:34 habu_snowflake_cli-4.0.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Apr-26 18:34 habu_snowflake_cli-4.0.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx       42 b- defN 23-Apr-26 18:34 habu_snowflake_cli-4.0.0.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       22 b- defN 23-Apr-26 18:34 habu_snowflake_cli-4.0.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     3359 b- defN 23-Apr-26 18:34 habu_snowflake_cli-4.0.0.dist-info/RECORD
+35 files, 114839 bytes uncompressed, 29598 bytes compressed:  74.2%
```

## zipnote {}

```diff
@@ -84,23 +84,23 @@
 
 Filename: redbeard_cli/sqlfiles/V1_0_0_create.sql
 Comment: 
 
 Filename: redbeard_cli/sqlfiles/__init__.py
 Comment: 
 
-Filename: habu_snowflake_cli-3.6.4.dist-info/METADATA
+Filename: habu_snowflake_cli-4.0.0.dist-info/METADATA
 Comment: 
 
-Filename: habu_snowflake_cli-3.6.4.dist-info/WHEEL
+Filename: habu_snowflake_cli-4.0.0.dist-info/WHEEL
 Comment: 
 
-Filename: habu_snowflake_cli-3.6.4.dist-info/entry_points.txt
+Filename: habu_snowflake_cli-4.0.0.dist-info/entry_points.txt
 Comment: 
 
-Filename: habu_snowflake_cli-3.6.4.dist-info/top_level.txt
+Filename: habu_snowflake_cli-4.0.0.dist-info/top_level.txt
 Comment: 
 
-Filename: habu_snowflake_cli-3.6.4.dist-info/RECORD
+Filename: habu_snowflake_cli-4.0.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## redbeard_cli/sqlfiles/R__1init_habu_installer.sql

```diff
@@ -25,61 +25,60 @@
     snowflake.execute({ sqlText: `CREATE SCHEMA IF NOT EXISTS HABU_SCHEMA` });
     snowflake.execute({ sqlText: `CREATE SCHEMA IF NOT EXISTS CLEAN_ROOM` });
     snowflake.execute({ sqlText: `CREATE OR REPLACE PROCEDURE
         HABU_SCHEMA.INIT_FRAMEWORK(ORGANIZATON_ID VARCHAR)
         returns string
         language javascript
         execute as owner as
-        \$\$
+        '
 
             sqlcmd = "SELECT HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.HABU_ORCHESTRATOR(current_region())";
             rset = snowflake.execute({ sqlText: sqlcmd });
             rset.next()
             var HABU_ORG_NAME_ACCOUNT_NAME_COMBO = rset.getColumnValue(1);
 
-            sqlcmd = "CALL HABU_CLEAN_ROOM_COMMON.HABU_SCHEMA.INIT_FRAMEWORK('" + ORGANIZATON_ID + "', '" + HABU_ORG_NAME_ACCOUNT_NAME_COMBO + "')";
+            sqlcmd = "CALL HABU_CLEAN_ROOM_COMMON.HABU_SCHEMA.INIT_FRAMEWORK(''" + ORGANIZATON_ID + "'', ''" + HABU_ORG_NAME_ACCOUNT_NAME_COMBO + "'')";
             rset = snowflake.execute({ sqlText: sqlcmd });
             rset.next()
 
             return rset.getColumnValue(1);
-        \$\$`
+        '`
     });
 
 
     snowflake.execute({ sqlText: `CREATE OR REPLACE PROCEDURE
         HABU_SCHEMA.INIT_FRAMEWORK(ORGANIZATON_ID VARCHAR, HABU_ORG_NAME_ACCOUNT_NAME_COMBO VARCHAR)
         returns string
         language javascript
         execute as owner as
-        \$\$
-
+        '
             sqlcmd = "SELECT current_account()";
             rset = snowflake.execute({ sqlText: sqlcmd });
             rset.next()
             var CUSTOMER_ACCOUNT_ID = rset.getColumnValue(1);
 
             var SHARE_RESTRICTIONS = "false";
 
-            sqlcmd = "CALL HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.INIT_HABU_SHARES('" + ORGANIZATON_ID + "', '" + HABU_ORG_NAME_ACCOUNT_NAME_COMBO + "', '" + CUSTOMER_ACCOUNT_ID + "')";
+            sqlcmd = "CALL HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.INIT_HABU_SHARES(''" + ORGANIZATON_ID + "'', ''" + HABU_ORG_NAME_ACCOUNT_NAME_COMBO + "'', ''" + CUSTOMER_ACCOUNT_ID + "'')";
             var rset = snowflake.execute({ sqlText: sqlcmd });
             rset.next()
             if (rset.getColumnValue(1) != "Init Habu shares successful") {
                 return rset.getColumnValue(1);
             }
-            sqlcmd = "CALL HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.SETUP_DATA_CONNECTION_OBJECTS('" + HABU_ORG_NAME_ACCOUNT_NAME_COMBO + "', '" + CUSTOMER_ACCOUNT_ID + "', '" + SHARE_RESTRICTIONS + "')";
+            sqlcmd = "CALL HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.SETUP_DATA_CONNECTION_OBJECTS(''" + HABU_ORG_NAME_ACCOUNT_NAME_COMBO + "'', ''" + CUSTOMER_ACCOUNT_ID + "'', ''" + SHARE_RESTRICTIONS + "'')";
             snowflake.execute({ sqlText: sqlcmd });
-            sqlcmd = "CALL HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.SETUP_CLEANROOM_COMMON('" + HABU_ORG_NAME_ACCOUNT_NAME_COMBO + "', '" + CUSTOMER_ACCOUNT_ID + "', '" + SHARE_RESTRICTIONS + "')";
+            sqlcmd = "CALL HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.SETUP_CLEANROOM_COMMON(''" + HABU_ORG_NAME_ACCOUNT_NAME_COMBO + "'', ''" + CUSTOMER_ACCOUNT_ID + "'', ''" + SHARE_RESTRICTIONS + "'')";
             snowflake.execute({ sqlText: sqlcmd });
-            sqlcmd = "CALL HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.SETUP_STREAM_TASKS('" + ORGANIZATON_ID + "', '" + HABU_ORG_NAME_ACCOUNT_NAME_COMBO + "', '" + CUSTOMER_ACCOUNT_ID + "')";
+            sqlcmd = "CALL HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.SETUP_STREAM_TASKS(''" + ORGANIZATON_ID + "'', ''" + HABU_ORG_NAME_ACCOUNT_NAME_COMBO + "'', ''" + CUSTOMER_ACCOUNT_ID + "'')";
             snowflake.execute({ sqlText: sqlcmd });
             return "Habu framework init successful";
-        \$\$`
+        '`
     });
 
-    
+
     return "Habu installer done";
 $$;
 
 
 end;
```

## redbeard_cli/sqlfiles/R__create_new_dataset.sql

```diff
@@ -12,17 +12,18 @@
                                     " id AS request_id, " +
                                     " request_data:clean_room_id AS clean_room_id, " +
                                     " request_data:source_db AS source_db, " +
                                     " request_data:view_name AS view_name, " +
                                     " request_data:view_sql AS view_sql, " +
                                     " request_data:available_values_sql AS available_values_sql, " +
                                     " request_data:source_table_name AS source_table_name, " +
-                                    " request_data:source_schema_name AS source_schema_name " +
-            " FROM HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.CLEAN_ROOM_REQUESTS " +
-            " WHERE request_type = :1 AND request_status = :2 ORDER BY CREATED_AT ASC";
+                                    " request_data:source_schema_name AS source_schema_name, " +
+                                    " request_data:clean_room_version AS clean_room_version " +
+                                    " FROM HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.CLEAN_ROOM_REQUESTS " +
+                                    " WHERE request_type = :1 AND request_status = :2 ORDER BY CREATED_AT ASC";
             var stmt = snowflake.createStatement({
                 sqlText: crRequestSql,
                 binds: ['NEW_DATASET', 'PENDING']
             });
 
             var rs = stmt.execute();
             var newDatasetParams = [];
@@ -31,69 +32,73 @@
                 var cleanRoomID = rs.getColumnValue(2);
                 var sourceDB = rs.getColumnValue(3);
                 var viewName = rs.getColumnValue(4);
                 var viewSql = rs.getColumnValue(5);
                 var availableValuesSql = rs.getColumnValue(6);
                 var sourceViewOrTableName = rs.getColumnValue(7);
                 var sourceSchemaName = rs.getColumnValue(8);
+                var cleanRoomVersion = rs.getColumnValue(9);
+
                 newDatasetParams.push({
                     'rID': requestID,
                     'crID': cleanRoomID,
                     'sourceDB': sourceDB,
                     'vn': viewName,
                     'vs': viewSql,
                     'avs': availableValuesSql,
                     'sourceTableName': sourceViewOrTableName,
-                    'sourceSchemaName': sourceSchemaName
+                    'sourceSchemaName': sourceSchemaName,
+                    'cleanRoomVersion': cleanRoomVersion,
                 })
                 snowflake.execute({
                         sqlText: "UPDATE HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.CLEAN_ROOM_REQUESTS SET REQUEST_STATUS = :1, UPDATED_AT = CURRENT_TIMESTAMP() WHERE ID = :2",
                         binds: ["IN_PROGRESS", requestID]
                 });
             }
 
             for (var i = 0; i < newDatasetParams.length; i++) {
                 var stmt = snowflake.createStatement({
-                    sqlText: 'CALL CLEAN_ROOM.CREATE_NEW_DATASET(:1, :2, :3, :4, :5, :6, :7, :8)',
+                    sqlText: 'CALL CLEAN_ROOM.CREATE_NEW_DATASET(:1, :2, :3, :4, :5, :6, :7, :8, :9)',
                     binds: [
                         newDatasetParams[i]['rID'],
                         newDatasetParams[i]['crID'],
                         newDatasetParams[i]['sourceDB'],
                         newDatasetParams[i]['vn'],
                         newDatasetParams[i]['vs'],
                         newDatasetParams[i]['avs'],
                         newDatasetParams[i]['sourceTableName'],
-                        newDatasetParams[i]['sourceSchemaName']
+                        newDatasetParams[i]['sourceSchemaName'],
+                        newDatasetParams[i]['cleanRoomVersion']
                     ]
                 });
                 stmt.execute();
             }
             result = "SUCCESS";
         } catch (err) {
-                        result = "FAILED";
+            result = "FAILED";
             var stmt = snowflake.createStatement({
                 sqlText: 'CALL CLEAN_ROOM.HANDLE_ERROR(:1, :2, :3, :4, :5, :6)',
                 binds: [
                     err.code, err.state, err.message, err.stackTraceTxt, "", Object.keys(this)[0]
                 ]
             });
             var res = stmt.execute();
         }
         return result;
 	$$;
 
-CREATE OR REPLACE PROCEDURE HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.CREATE_NEW_DATASET(REQUEST_ID VARCHAR, CLEAN_ROOM_ID VARCHAR, SOURCE_DB VARCHAR, VIEW_NAME VARCHAR, VIEW_SQL VARCHAR, AVAILABLE_VALUES_SQL VARCHAR, SOURCE_TABLE_NAME VARCHAR, SOURCE_SCHEMA_NAME VARCHAR)
+CREATE OR REPLACE PROCEDURE HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.CREATE_NEW_DATASET(REQUEST_ID VARCHAR, CLEAN_ROOM_ID VARCHAR, SOURCE_DB VARCHAR, VIEW_NAME VARCHAR, VIEW_SQL VARCHAR, AVAILABLE_VALUES_SQL VARCHAR, SOURCE_TABLE_NAME VARCHAR, SOURCE_SCHEMA_NAME VARCHAR, CLEAN_ROOM_VERSION VARCHAR)
 	returns string
 	language javascript
 	execute as owner as
 	$$
         // Handles new data set command
 
         try {
-            
+
             var sf_clean_room_id = CLEAN_ROOM_ID.replace(/-/g, '').toUpperCase();
 
             var habuShareDb = "HABU_CR_" + sf_clean_room_id + "_HABU_SHARE"
             var partnerShareDb = "HABU_CR_" + sf_clean_room_id + "_PARTNER_SHARE"
 
             snowflake.execute({
                 sqlText: "GRANT REFERENCE_USAGE ON DATABASE " + SOURCE_DB + " TO SHARE " + habuShareDb
@@ -152,18 +157,54 @@
                 })
             }
 
             snowflake.execute({
                 sqlText: "GRANT SELECT ON VIEW HABU_CLEAN_ROOM_" + sf_clean_room_id + ".CLEAN_ROOM." + VIEW_NAME + " TO SHARE " + partnerShareDb
             });
 
+            /*
+                    if cleanroom v2
+                    2 main things to be achieve
+                        1. add new view to shared_schema (partner logic)
+                            allow access to shared_schema.view to app
+                        2. allow access on the view to TO_APP_ROLE (owner logic)
+             */
+            if (CLEAN_ROOM_VERSION != null && CLEAN_ROOM_VERSION.trim().length != 0 && CLEAN_ROOM_VERSION === "2") {
+                var sharedSchemaViewSql = VIEW_SQL.replace(".CLEAN_ROOM."+VIEW_NAME, ".SHARED_SCHEMA."+VIEW_NAME)
+                snowflake.execute({sqlText: sharedSchemaViewSql});
+
+                snowflake.execute({
+                    sqlText: `GRANT SELECT ON VIEW HABU_CLEAN_ROOM_${sf_clean_room_id}.SHARED_SCHEMA.${VIEW_NAME} TO SHARE ${partnerShareDb}`
+                });
+
+                // grant view access to owner (partner logic)
+                snowflake.execute({
+                    sqlText: `grant select on view HABU_CLEAN_ROOM_${sf_clean_room_id}.CLEAN_ROOM.${VIEW_NAME} to DATABASE ROLE HABU_CLEAN_ROOM_${sf_clean_room_id}.habu_db_role_app_${sf_clean_room_id};`
+                });
+
+                // grant usage appRole (owner logic)
+                var appRole = `HABU_CR_${sf_clean_room_id}_APP_ROLE`;
+
+                snowflake.execute({
+                    sqlText: `grant usage on database HABU_CLEAN_ROOM_${sf_clean_room_id} to role ${appRole}`
+                });
+
+                snowflake.execute({
+                    sqlText: `grant usage on schema HABU_CLEAN_ROOM_${sf_clean_room_id}.SHARED_SCHEMA to role ${appRole}`
+                });
+
+                snowflake.execute({
+                    sqlText: `grant select on view HABU_CLEAN_ROOM_${sf_clean_room_id}.SHARED_SCHEMA.${VIEW_NAME} to role ${appRole}`
+                });
+
+            }
             result = "COMPLETE";
             msg = "Dataset created successfully"
         } catch (err) {
-            
+
             result = "FAILED";
             var stmt = snowflake.createStatement({
                 sqlText: 'CALL CLEAN_ROOM.HANDLE_ERROR(:1, :2, :3, :4, :5, :6)',
                 binds: [
                     err.code, err.state, err.message, err.stackTraceTxt, REQUEST_ID, Object.keys(this)[0]
                 ]
             });
@@ -171,15 +212,15 @@
             var res = stmt.execute();
         } finally {
             snowflake.execute({
                 sqlText: "UPDATE HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.CLEAN_ROOM_REQUESTS SET REQUEST_STATUS = :1, UPDATED_AT = CURRENT_TIMESTAMP() WHERE ID = :2",
                 binds: [result, REQUEST_ID]
             });
 
-            
+
             opMsg = Object.keys(this)[0] + " - OPERATION STATUS - " + result + " - Detail: " + msg
             snowflake.createStatement({
                 sqlText: 'CALL CLEAN_ROOM.SP_LOGGER(:1, :2, :3)',
                 binds:[opMsg, REQUEST_ID, Object.keys(this)[0]]
             }).execute();
         }
         return result;
```

## redbeard_cli/sqlfiles/R__handle_management_command.sql

```diff
@@ -37,15 +37,15 @@
                         mgmtCmdParams[i]['managementCommandQuery']
                     ]
                 });
                 stmt.execute();
 }
             result = "SUCCESS";
 } catch (err) {
-                        result = "FAILED";
+            result = "FAILED";
             var stmt = snowflake.createStatement({
                 sqlText: 'CALL CLEAN_ROOM.HANDLE_ERROR(:1, :2, :3, :4, :5, :6)',
                 binds: [
                     err.code, err.state, err.message, err.stackTraceTxt, "", Object.keys(this)[0]
                 ]
             });
             var res = stmt.execute();
@@ -63,15 +63,15 @@
     AS
     $$
         // Install management command runner procedure
         try {
             var resultSet = snowflake.execute({sqlText: MANAGEMENT_COMMAND_QUERY})
             result = "COMPLETE";
 } catch (err) {
-                        result = "FAILED";
+            result = "FAILED";
             var stmt = snowflake.createStatement({
                 sqlText: 'CALL CLEAN_ROOM.HANDLE_ERROR(:1, :2, :3, :4, :5, :6)',
                 binds: [
                     err.code, err.state, err.message, err.stackTraceTxt, REQUEST_ID, Object.keys(this)[0]
                 ]
             });
             msg = err.message
```

## redbeard_cli/sqlfiles/R__handle_new_cleanrooms.sql

```diff
@@ -9,15 +9,16 @@
         // that are present in the HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.CLEAN_ROOM_REQUESTS table.
 
         try {
             var crRequestSql = "SELECT id AS request_id, " +
                             "request_data:clean_room_id AS clean_room_id, " +
                             "request_data:account_id AS account_id, " +
                             "request_data:habu_sf_account_name AS habu_sf_account_name, " +
-                            "request_data:habu_sf_organization_name AS habu_sf_organization_name " +
+                            "request_data:habu_sf_organization_name AS habu_sf_organization_name, " +
+                            "request_data:clean_room_version AS clean_room_version " +
                             "FROM HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.CLEAN_ROOM_REQUESTS  " +
                             "WHERE request_type = :1 AND request_status = :2 ORDER BY CREATED_AT ASC";
             var stmt = snowflake.createStatement({
                 sqlText: crRequestSql,
                 binds: ['NEW_CLEAN_ROOM', 'PENDING']
             });
 
@@ -25,78 +26,81 @@
             var newCleanRoomRequestParams = [];
             while (rs.next()) {
                 var requestID = rs.getColumnValue(1)
                 var cleanRoomID = rs.getColumnValue(2);
                 var accountID = rs.getColumnValue(3);
                 var habuSfAccountName = rs.getColumnValue(4);
                 var habuSfOrganizationName = rs.getColumnValue(5);
+                var cleanRoomVersion = rs.getColumnValue(6);
 
                 newCleanRoomRequestParams.push({
                     'rID': requestID,
                     'crID': cleanRoomID,
                     'acID': accountID,
                     'hacSfAccntName': habuSfAccountName,
                     'hacSfOrgName': habuSfOrganizationName,
+                    'cleanRoomVersion': cleanRoomVersion,
                 })
 
                 snowflake.execute({
                         sqlText: "UPDATE HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.CLEAN_ROOM_REQUESTS SET REQUEST_STATUS = :1, UPDATED_AT = CURRENT_TIMESTAMP() WHERE ID = :2",
                         binds: ["IN_PROGRESS", requestID]
                 });
             }
 
             for (var i = 0; i < newCleanRoomRequestParams.length; i++) {
                 var stmt = snowflake.createStatement({
-                    sqlText: 'CALL CLEAN_ROOM.CREATE_NEW_CLEAN_ROOM(:1, :2, :3, :4, :5)',
+                    sqlText: 'CALL CLEAN_ROOM.CREATE_NEW_CLEAN_ROOM(:1, :2, :3, :4, :5, :6)',
                     binds: [
                         newCleanRoomRequestParams[i]['rID'],
                         newCleanRoomRequestParams[i]['crID'],
                         newCleanRoomRequestParams[i]['acID'],
                         newCleanRoomRequestParams[i]['hacSfAccntName'],
-                        newCleanRoomRequestParams[i]['hacSfOrgName']
+                        newCleanRoomRequestParams[i]['hacSfOrgName'],
+                        newCleanRoomRequestParams[i]['cleanRoomVersion']
                     ]
                 });
                 var res = stmt.execute();
             }
             result = "COMPLETE";
         } catch (err) {
-            
+
             result = "FAILED";
             var stmt = snowflake.createStatement({
                 sqlText: 'CALL CLEAN_ROOM.HANDLE_ERROR(:1, :2, :3, :4, :5, :6)',
                 binds: [
                     err.code, err.state, err.message, err.stackTraceTxt, "", Object.keys(this)[0]
                 ]
             });
             var res = stmt.execute();
         }
         return result;
 	$$;
 
 
-CREATE OR REPLACE PROCEDURE HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.CREATE_NEW_CLEAN_ROOM(REQUEST_ID VARCHAR, CLEAN_ROOM_ID VARCHAR, OWNER_ACCOUNT_ID VARCHAR, HABU_SF_ACCOUNT_NAME VARCHAR, HABU_SF_ORGANIZATION_NAME VARCHAR)
+CREATE OR REPLACE PROCEDURE HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.CREATE_NEW_CLEAN_ROOM(REQUEST_ID VARCHAR, CLEAN_ROOM_ID VARCHAR, OWNER_ACCOUNT_ID VARCHAR, HABU_SF_ACCOUNT_NAME VARCHAR, HABU_SF_ORGANIZATION_NAME VARCHAR, CLEAN_ROOM_VERSION VARCHAR)
 	returns string
 	language javascript
 	execute as owner as
 	$$
         // Handles new clean room command
         try {
-            
+
             var sf_clean_room_id = CLEAN_ROOM_ID.replace(/-/g, '').toUpperCase();
             snowflake.execute({
                 sqlText: "CREATE DATABASE IF NOT EXISTS HABU_CLEAN_ROOM_" + sf_clean_room_id + " COMMENT = 'HABU_" + OWNER_ACCOUNT_ID + "'"
             });
 
-            
+
             snowflake.createStatement({
                 sqlText: "CALL CLEAN_ROOM.SP_LOGGER(:1, :2, :3)",
                 binds: ["Database created", REQUEST_ID, Object.keys(this)[0]]
             }).execute();
 
-            
+
             snowflake.execute({
                 sqlText: "CREATE SCHEMA IF NOT EXISTS HABU_CLEAN_ROOM_" + sf_clean_room_id + ".CLEAN_ROOM COMMENT = 'HABU_" + OWNER_ACCOUNT_ID + "'"
             });
 
             // habu share
             var habuShareDb = "HABU_CR_" + sf_clean_room_id + "_HABU_SHARE"
 
@@ -153,18 +157,123 @@
                 sqlText: "GRANT REFERENCE_USAGE ON DATABASE HABU_CLEAN_ROOM_COMMON TO SHARE " + partnerShareDb
             });
 
             snowflake.execute({
                 sqlText: "GRANT SELECT ON VIEW HABU_CLEAN_ROOM_" + sf_clean_room_id + ".CLEAN_ROOM.V_ALLOWED_STATEMENTS TO SHARE " + partnerShareDb
             });
 
+            if (CLEAN_ROOM_VERSION != null && CLEAN_ROOM_VERSION.trim().length != 0 && CLEAN_ROOM_VERSION === "2") {
+                var appDbRole = "habu_db_role_app_" + sf_clean_room_id;
+
+                snowflake.execute({
+                    sqlText: "create schema if not exists HABU_CLEAN_ROOM_" + sf_clean_room_id + ".installer;"
+                });
+
+                snowflake.execute({
+                    sqlText: `create or replace procedure HABU_CLEAN_ROOM_${sf_clean_room_id}.installer.install_cleanroom()
+                                returns string
+                                language javascript
+                                execute as owner
+                                as '
+
+                                // grant db role
+                                var result = snowflake.execute({ sqlText:  "grant DATABASE ROLE ${appDbRole} TO DATABASE ROLE APP_EXPORTER"} );
+
+                                // create schemas
+                                snowflake.execute({ sqlText: "create schema app_internal_schema" });
+                                snowflake.execute({ sqlText: "create schema cleanroom" });
+
+                                // allow consumer to access the local cleanroom schema
+                                snowflake.execute({ sqlText: "grant usage on schema cleanroom to database role app_exporter" });
+
+                                // create initial dummy stage so consumer can create the inferencing function
+                                snowflake.execute({ sqlText: "create or replace stage cleanroom.ml " });
+                                snowflake.execute({ sqlText: "grant read on stage cleanroom.ml to database role app_exporter " });
+                            '`
+                });
+
+                snowflake.execute({
+                    sqlText: "create or replace share " + partnerShareDb + " installer = HABU_CLEAN_ROOM_" + sf_clean_room_id + ".installer.install_cleanroom();"
+                });
+                snowflake.execute({
+                    sqlText: "grant usage on database HABU_CLEAN_ROOM_" + sf_clean_room_id + " to share " + partnerShareDb
+                });
+
+                snowflake.execute({
+                    sqlText: "grant usage on schema HABU_CLEAN_ROOM_" + sf_clean_room_id + ".installer to share " + partnerShareDb
+                });
+
+                snowflake.execute({
+                    sqlText: "grant usage on schema HABU_CLEAN_ROOM_" + sf_clean_room_id + ".clean_room to share " + partnerShareDb
+                });
+
+                snowflake.execute({
+                    sqlText: "grant usage on procedure HABU_CLEAN_ROOM_" + sf_clean_room_id + ".installer.install_cleanroom() to share " + partnerShareDb
+                });
+                snowflake.execute({
+                    sqlText: "CREATE DATABASE ROLE IF NOT EXISTS HABU_CLEAN_ROOM_" + sf_clean_room_id + "." + appDbRole
+                });
+                snowflake.execute({
+                    sqlText: "create schema if not exists HABU_CLEAN_ROOM_" + sf_clean_room_id + ".ALLOWED_SPROCS;"
+                });
+
+                snowflake.execute({
+                    sqlText: `GRANT USAGE ON schema HABU_CLEAN_ROOM_${sf_clean_room_id}.ALLOWED_SPROCS TO DATABASE ROLE HABU_CLEAN_ROOM_${sf_clean_room_id}.${appDbRole}`
+                });
+
+                // app role also requires access to the clean_room shares along with the shared_schema
+                snowflake.execute({
+                    sqlText: `GRANT USAGE ON schema HABU_CLEAN_ROOM_${sf_clean_room_id}.CLEAN_ROOM TO DATABASE ROLE HABU_CLEAN_ROOM_${sf_clean_room_id}.${appDbRole}`
+                });
+                snowflake.execute({
+                    sqlText: `GRANT SELECT ON VIEW HABU_CLEAN_ROOM_${sf_clean_room_id}.CLEAN_ROOM.V_ALLOWED_STATEMENTS TO DATABASE ROLE HABU_CLEAN_ROOM_${sf_clean_room_id}.${appDbRole}`
+                });
+
+                snowflake.execute({
+                    sqlText: "create schema if not exists HABU_CLEAN_ROOM_" + sf_clean_room_id + ".shared_schema;"
+                });
+
+                snowflake.execute({
+                    sqlText: "GRANT USAGE ON schema HABU_CLEAN_ROOM_" + sf_clean_room_id + ".shared_schema TO SHARE " + partnerShareDb
+                });
+
+                snowflake.execute({
+                    sqlText: "GRANT REFERENCE_USAGE ON DATABASE HABU_CLEAN_ROOM_COMMON TO SHARE " + partnerShareDb
+                });
+
+                 snowflake.execute({
+                    sqlText: "grant database role HABU_CLEAN_ROOM_" + sf_clean_room_id + "." + appDbRole + " to share " + partnerShareDb
+                });
+
+                // owner logic creation of database role which will be granted to the installed app, it should be able to read from shared_schema and write to CLEAN_ROOM_RUN_RESULTS
+
+                var appToDbRole = "HABU_CR_" + sf_clean_room_id + "_APP_ROLE"
+
+                snowflake.execute({
+                    sqlText: `create or replace role ${appToDbRole}`
+                });
+
+                snowflake.execute({
+                    sqlText: `grant usage on database HABU_CLEAN_ROOM_${sf_clean_room_id} to role ${appToDbRole}`
+                });
+
+                snowflake.execute({
+                    sqlText: `grant usage on schema HABU_CLEAN_ROOM_${sf_clean_room_id}.CLEAN_ROOM_RUN_RESULTS to role ${appToDbRole}`
+                });
+
+                snowflake.execute({
+                    sqlText: `grant insert on future tables in schema HABU_CLEAN_ROOM_${sf_clean_room_id}.CLEAN_ROOM_RUN_RESULTS to role ${appToDbRole}`
+                });
+
+            }
+
             result = "COMPLETE";
             msg = "Clean room created successfully"
         } catch (err) {
-            
+
             result = "FAILED";
             var stmt = snowflake.createStatement({
                 sqlText: 'CALL CLEAN_ROOM.HANDLE_ERROR(:1, :2, :3, :4, :5, :6)',
                 binds: [
                     err.code, err.state, err.message, err.stackTraceTxt, REQUEST_ID, Object.keys(this)[0]
                 ]
             });
@@ -172,15 +281,15 @@
             var res = stmt.execute();
         } finally {
             snowflake.execute({
                 sqlText: "UPDATE HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.CLEAN_ROOM_REQUESTS SET REQUEST_STATUS = :1, UPDATED_AT = CURRENT_TIMESTAMP() WHERE ID = :2",
                 binds: [result, REQUEST_ID]
             });
 
-            
+
             opMsg = Object.keys(this)[0] + " - OPERATION STATUS - " + result + " - Detail: " + msg
             snowflake.createStatement({
                 sqlText: 'CALL CLEAN_ROOM.SP_LOGGER(:1, :2, :3)',
                 binds:[opMsg, REQUEST_ID, Object.keys(this)[0]]
             }).execute();
         }
         return result;
```

## redbeard_cli/sqlfiles/R__init_habu_shares.sql

```diff
@@ -1,30 +1,29 @@
 BEGIN
 
 CREATE OR REPLACE PROCEDURE HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.INIT_HABU_SHARES(ORGANIZATON_ID VARCHAR, HABU_ACCOUNT VARCHAR, CUSTOMER_ACCOUNT_ID VARCHAR)
 	returns string
 	language javascript
 	execute as owner as
 	$$
-        
+
         // Since "SHOW SHARES" does not work within native app just try to accept shares
         // if it works we are good and else initialization fails as desired.
         var sf_org_id = ORGANIZATON_ID.replace(/-/g, '').toUpperCase();
         var org_share_name = "HABU_ORG_" + sf_org_id + "_SHARE";
         var org_share_db_name = org_share_name + "_DB";
         var customer_account_locator = CUSTOMER_ACCOUNT_ID.split(".")[0].toUpperCase()
         try {
             // Accept share of HABU Org DB
             sqlcmd = "CREATE DATABASE IF NOT EXISTS " + org_share_db_name + " FROM SHARE " + HABU_ACCOUNT + "." + org_share_name + " COMMENT = 'HABU_" + customer_account_locator + "'";
             snowflake.execute({ sqlText: sqlcmd });
             sqlcmd = "GRANT IMPORTED PRIVILEGES ON DATABASE " + org_share_db_name + " TO ROLE ACCOUNTADMIN";
             snowflake.execute({ sqlText: sqlcmd });
             sqlcmd = "GRANT IMPORTED PRIVILEGES ON DATABASE " + org_share_db_name + " TO ROLE SYSADMIN";
             snowflake.execute({ sqlText: sqlcmd });
-
             // Accept share of HABU Identity graph
             sqlcmd = "CREATE OR REPLACE DATABASE HABU_ID_GRAPH_SHARE_DB FROM SHARE " + HABU_ACCOUNT + "." + "HABU_ID_GRAPH_SHARE COMMENT = 'HABU_" + customer_account_locator + "'";
             snowflake.execute({ sqlText: sqlcmd });
             sqlcmd = "GRANT IMPORTED PRIVILEGES ON DATABASE HABU_ID_GRAPH_SHARE_DB TO ROLE ACCOUNTADMIN";
             snowflake.execute({ sqlText: sqlcmd });
             sqlcmd = "GRANT IMPORTED PRIVILEGES ON DATABASE HABU_ID_GRAPH_SHARE_DB TO ROLE SYSADMIN";
             snowflake.execute({ sqlText: sqlcmd });
```

## redbeard_cli/sqlfiles/R__new_data_connection.sql

```diff
@@ -62,15 +62,15 @@
                         newDatasetParams[i]['tableName']
                     ]
                 });
                 stmt.execute();
             }
             result = "SUCCESS";
         } catch (err) {
-            
+
             result = "FAILED";
             var stmt = snowflake.createStatement({
                 sqlText: 'CALL CLEAN_ROOM.HANDLE_ERROR(:1, :2, :3, :4, :5, :6)',
                 binds: [
                     err.code, err.state, err.message, err.stackTraceTxt, "", Object.keys(this)[0]
                 ]
             });
@@ -81,15 +81,15 @@
 
 CREATE OR REPLACE PROCEDURE HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.CREATE_DATA_CONNECTION(REQUEST_ID VARCHAR, ORG_ID VARCHAR, DATA_CONNECTION_ID VARCHAR, DATASET_TYPE VARCHAR, DB_NM VARCHAR, SCHEMA_NM VARCHAR, TABLE_NM VARCHAR)
 	returns string
 	language javascript
 	execute as owner as
 	$$
         try {
-            
+
             var msg = "";
             var existsDbSchemaTable = "select 1 from " + DB_NM +"." + SCHEMA_NM + "." + TABLE_NM + " limit 1";
 
             var result_scan = snowflake.execute({
                 sqlText:  existsDbSchemaTable
             });
 
@@ -150,15 +150,15 @@
                     sqlText: "GRANT REFERENCE_USAGE ON DATABASE " + referencedDatabase + " TO SHARE HABU_DATA_CONNECTIONS_SHARE"
                 })
             }
 
             result = "COMPLETE";
             msg = "Data connection created successfully"
         } catch (err) {
-            
+
             result = "FAILED";
             var stmt = snowflake.createStatement({
                 sqlText: 'CALL CLEAN_ROOM.HANDLE_ERROR(:1, :2, :3, :4, :5, :6)',
                 binds: [
                     err.code, err.state, err.message, err.stackTraceTxt, REQUEST_ID, Object.keys(this)[0]
                 ]
             });
@@ -166,15 +166,15 @@
             var res = stmt.execute();
         } finally {
             snowflake.execute({
                 sqlText: "UPDATE HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.CLEAN_ROOM_REQUESTS SET REQUEST_STATUS = :1, UPDATED_AT = CURRENT_TIMESTAMP() WHERE ID = :2",
                 binds: [result, REQUEST_ID]
             });
 
-            
+
             opMsg = Object.keys(this)[0] + " - OPERATION STATUS - " + result + " - Detail: " + msg
             snowflake.createStatement({
                 sqlText: 'CALL CLEAN_ROOM.SP_LOGGER(:1, :2, :3)',
                 binds:[opMsg, REQUEST_ID, Object.keys(this)[0]]
             }).execute();
         }
         return result;
```

## redbeard_cli/sqlfiles/R__new_question_run.sql

```diff
@@ -14,15 +14,16 @@
             " request_data:result_table AS result_table, " +
             " request_data:result_table_ddl AS result_table_ddl, " +
             " request_data:accounts AS accounts, " +
             " request_data:accountNames AS accountNames, " +
             " request_data:organizationNames AS organizationNames, " +
             " request_data:compute_account_id AS compute_account_id, " +
             " request_data:statement_hash AS statement_hash, " +
-            " request_data:question_run_query AS question_run_query " +
+            " request_data:question_run_query AS question_run_query, " +
+            " request_data:clean_room_version AS clean_room_version " +
             " FROM HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.CLEAN_ROOM_REQUESTS " +
             " WHERE request_type = :1 AND request_status = :2 ORDER BY CREATED_AT ASC";
 
             var stmt = snowflake.createStatement({
                 sqlText: crRequestSql,
                 binds: ['NEW_QUESTION_RUN', 'PENDING']
             });
@@ -36,76 +37,92 @@
                 var resultTableDDL = rs.getColumnValue(4);
                 var accounts = rs.getColumnValue(5);
                 var accountNames = rs.getColumnValue(6);
                 var organizationNames = rs.getColumnValue(7);
                 var computeAccountId = rs.getColumnValue(8);
                 var statementHash = rs.getColumnValue(9);
                 var query = rs.getColumnValue(10);
+                var cleanRoomVersion = rs.getColumnValue(11);
 
                 newQuestionRunParams.push({
                     'requestID' : requestID,
                     'cleanRoomID' : cleanRoomID,
                     'resultTable' : resultTable,
                     'resultTableDDL' : resultTableDDL,
                     'accounts' : accounts,
                     'accountNames': accountNames,
                     'organizationNames': organizationNames,
                     'computeAccountId': computeAccountId,
                     'statementHash': statementHash,
-                    'query' : query
+                    'query' : query,
+                    'cleanRoomVersion' : cleanRoomVersion
                 })
                 snowflake.execute({
                         sqlText: "UPDATE HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.CLEAN_ROOM_REQUESTS SET REQUEST_STATUS = :1, UPDATED_AT = CURRENT_TIMESTAMP() WHERE ID = :2",
                         binds: ["IN_PROGRESS", requestID]
                 });
             }
 
-            
+
             for (var i = 0; i < newQuestionRunParams.length; i++) {
                 var stmt = snowflake.createStatement({
-                    sqlText: 'CALL CLEAN_ROOM.ADD_NEW_QUESTION_RUN(:1, :2, :3, :4, :5, :6, :7, :8, :9, :10)',
+                    sqlText: 'CALL CLEAN_ROOM.ADD_NEW_QUESTION_RUN(:1, :2, :3, :4, :5, :6, :7, :8, :9, :10, :11)',
                     binds: [
                         newQuestionRunParams[i]['requestID'],
                         newQuestionRunParams[i]['cleanRoomID'],
                         newQuestionRunParams[i]['resultTable'],
                         newQuestionRunParams[i]['resultTableDDL'],
                         newQuestionRunParams[i]['accounts'],
                         newQuestionRunParams[i]['accountNames'],
                         newQuestionRunParams[i]['organizationNames'],
                         newQuestionRunParams[i]['computeAccountId'],
                         newQuestionRunParams[i]['statementHash'],
-                        newQuestionRunParams[i]['query']
+                        newQuestionRunParams[i]['query'],
+                        newQuestionRunParams[i]['cleanRoomVersion']
                     ]
                 });
                 stmt.execute();
             }
             result = "SUCCESS";
         } catch (err) {
-            
+
             result = "FAILED";
             var stmt = snowflake.createStatement({
                 sqlText: 'CALL CLEAN_ROOM.HANDLE_ERROR(:1, :2, :3, :4, :5, :6)',
                 binds: [
                     err.code, err.state, err.message, err.stackTraceTxt, "", Object.keys(this)[0]
                 ]
             });
             var res = stmt.execute();
         }
         return result;
 	$$;
 
-CREATE OR REPLACE PROCEDURE HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.ADD_NEW_QUESTION_RUN(REQUEST_ID VARCHAR, CLEAN_ROOM_ID VARCHAR, RESULT_TABLE VARCHAR, RESULT_TABLE_DDL VARCHAR, ACCOUNTS_INPUT VARCHAR, ACCOUNT_NAMES_INPUT VARCHAR, ORG_NAMES_INPUT VARCHAR, COMPUTE_ACCOUNT_ID VARCHAR, STATEMENT_HASH VARCHAR, QUESTION_RUN_QUERY VARCHAR)
+CREATE OR REPLACE PROCEDURE HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.ADD_NEW_QUESTION_RUN(REQUEST_ID VARCHAR, CLEAN_ROOM_ID VARCHAR, RESULT_TABLE VARCHAR, RESULT_TABLE_DDL VARCHAR, ACCOUNTS_INPUT VARCHAR, ACCOUNT_NAMES_INPUT VARCHAR, ORG_NAMES_INPUT VARCHAR, COMPUTE_ACCOUNT_ID VARCHAR, STATEMENT_HASH VARCHAR, QUESTION_RUN_QUERY VARCHAR, CLEAN_ROOM_VERSION VARCHAR)
 	returns string
 	language javascript
 	execute as owner as
 	$$
+       // Function for checking Valid JSON String or not.
+
+        function isValidJSON(jsonString) {
+            try {
+                var o = JSON.parse(jsonString);
+                if (o && typeof o === "object") {
+                    return o;
+                }
+            }
+            catch (e) { }
+            return null;
+        }
+
         // Install the New question run stored procedure
 
         try {
-            
+
             var sf_clean_room_id = CLEAN_ROOM_ID.replace(/-/g, '').toUpperCase();
 
             var habuShareDb = "HABU_CR_" + sf_clean_room_id + "_HABU_SHARE"
 
             snowflake.execute({
                 sqlText: RESULT_TABLE_DDL
             });
@@ -126,14 +143,25 @@
                     var partnerShareDb = "HABU_CR_" + ACCOUNTS[i] + "_" + sf_clean_room_id + "_PARTNER_SHARE_DB"
                     var shareName = ORG_NAMES[i] + "." + ACCOUNT_NAMES[i] + "." + partnerShare
 
                     snowflake.execute({
                         sqlText: "CREATE DATABASE IF NOT EXISTS " + partnerShareDb + " FROM SHARE " + shareName + " COMMENT = 'HABU_" + ACCOUNTS[i] + "'"
                     });
 
+                    // grant to_app_role to installed share database
+                    if (CLEAN_ROOM_VERSION != null && CLEAN_ROOM_VERSION.trim().length != 0 && CLEAN_ROOM_VERSION == "2") {
+                        snowflake.execute({
+                            sqlText: `grant select on table HABU_CLEAN_ROOM_${sf_clean_room_id}.CLEAN_ROOM_RUN_RESULTS.${RESULT_TABLE} to role HABU_CR_${sf_clean_room_id}_APP_ROLE`
+                        });
+
+                        snowflake.execute({
+                            sqlText: `grant role HABU_CR_${sf_clean_room_id}_APP_ROLE to database ${partnerShareDb}`
+                        });
+                    }
+
                     snowflake.execute({
                         sqlText: "GRANT IMPORTED PRIVILEGES ON DATABASE " + partnerShareDb + " TO ROLE ACCOUNTADMIN"
                     })
                     snowflake.execute({
                         sqlText: "GRANT IMPORTED PRIVILEGES ON DATABASE " + partnerShareDb + " TO ROLE SYSADMIN"
                     });
                 }
@@ -144,29 +172,49 @@
                 binds: [COMPUTE_ACCOUNT_ID, CLEAN_ROOM_ID, STATEMENT_HASH]
             })
 
             // Execute the actual question query
             var resultSet = snowflake.execute({sqlText: QUESTION_RUN_QUERY})
             qId = Object.keys(this)[0] + " - QUESTION_RUN_QUERY - Query ID: " + resultSet.getQueryId()
 
-            
+            while (resultSet.next()) {
+                var runQueryResponse = resultSet.getColumnValueAsString(1);
+                var json = isValidJSON(runQueryResponse);
+                if (json != null) {
+                    if (json.loggerMessage && json.loggerMessage.length != 0) {
+                        opMsg = json.loggerMessage
+                        snowflake.createStatement({
+                            sqlText: 'CALL CLEAN_ROOM.SP_LOGGER(:1, :2, :3)',
+                            binds:[opMsg, REQUEST_ID, Object.keys(this)[0]]
+                        }).execute();
+                    }
+
+                    // Throw Error if Message is not success for Python.
+                    if (json.message && json.message != "SUCCESS") {
+                        throw { code : json.code, message: json.message, state : json.state, stackTraceTxt : json.stackTraceTxt }
+                    }
+
+                }
+            }
+
+
             snowflake.createStatement({
                 sqlText: 'CALL CLEAN_ROOM.SP_LOGGER(:1, :2, :3)',
                 binds:[qId, REQUEST_ID, Object.keys(this)[0]]
             }).execute();
 
             snowflake.execute({
                 sqlText: "DELETE FROM HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.ALLOWED_STATEMENTS where ACCOUNT_ID = :1 and CLEAN_ROOM_ID = :2 and STATEMENT_HASH = :3",
                 binds: [COMPUTE_ACCOUNT_ID, CLEAN_ROOM_ID, STATEMENT_HASH]
             })
 
             result = "COMPLETE";
             msg = "New question run added successfully"
         } catch (err) {
-            
+
             result = "FAILED";
             var stmt = snowflake.createStatement({
                 sqlText: 'CALL CLEAN_ROOM.HANDLE_ERROR(:1, :2, :3, :4, :5, :6)',
                 binds: [
                     err.code, err.state, err.message, err.stackTraceTxt, REQUEST_ID, Object.keys(this)[0]
                 ]
             });
@@ -174,15 +222,15 @@
             var res = stmt.execute();
         } finally {
             snowflake.execute({
                 sqlText: "UPDATE HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.CLEAN_ROOM_REQUESTS SET REQUEST_STATUS = :1, UPDATED_AT = CURRENT_TIMESTAMP() WHERE ID = :2",
                 binds: [result, REQUEST_ID]
             });
 
-            
+
             opMsg = Object.keys(this)[0] + " - OPERATION STATUS - " + result + " - Detail: " + msg
             snowflake.createStatement({
                 sqlText: 'CALL CLEAN_ROOM.SP_LOGGER(:1, :2, :3)',
                 binds:[opMsg, REQUEST_ID, Object.keys(this)[0]]
             }).execute();
         }
         return result;
```

## redbeard_cli/sqlfiles/R__post_run_query.sql

```diff
@@ -53,15 +53,15 @@
                         postRunQueryParams[i]['insertQueryCount']
                     ]
                 });
                 stmt.execute();
 }
             result = "SUCCESS";
 } catch (err) {
-            
+
             result = "FAILED";
             var stmt = snowflake.createStatement({
                 sqlText: 'CALL CLEAN_ROOM.HANDLE_ERROR(:1, :2, :3, :4, :5, :6)',
                 binds: [
                     err.code, err.state, err.message, err.stackTraceTxt, "", Object.keys(this)[0]
                 ]
             });
@@ -74,15 +74,15 @@
 	returns string
 	language javascript
 	execute as owner as
 	$$
         // Installs post run query procedure
 
         try {
-            
+
             snowflake.execute({sqlText: POST_RUN_QUERY});
 
             snowflake.createStatement({
                 sqlText: 'CALL CLEAN_ROOM.SP_LOGGER(:1, :2, :3)',
                 binds:["Post Run query executed", REQUEST_ID, Object.keys(this)[0]]
             }).execute();
 
@@ -92,15 +92,15 @@
                 sqlText: 'CALL CLEAN_ROOM.SP_LOGGER(:1, :2, :3)',
                 binds:["Query count inserted", REQUEST_ID, Object.keys(this)[0]]
             }).execute();
 
             result = "COMPLETE";
             msg = "Post Run Query successful"
         } catch (err) {
-            
+
             result = "FAILED";
             var stmt = snowflake.createStatement({
                 sqlText: 'CALL CLEAN_ROOM.HANDLE_ERROR(:1, :2, :3, :4, :5, :6)',
                 binds: [
                     err.code, err.state, err.message, err.stackTraceTxt, REQUEST_ID, Object.keys(this)[0]
                 ]
             });
@@ -108,15 +108,15 @@
             var res = stmt.execute();
         } finally {
             snowflake.execute({
                 sqlText: "UPDATE HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.CLEAN_ROOM_REQUESTS SET REQUEST_STATUS = :1, UPDATED_AT = CURRENT_TIMESTAMP() WHERE ID = :2",
                 binds: [result, REQUEST_ID]
             });
 
-            
+
             opMsg = Object.keys(this)[0] + " - OPERATION STATUS - " + result + " - Detail: " + msg
             snowflake.createStatement({
                 sqlText: 'CALL CLEAN_ROOM.SP_LOGGER(:1, :2, :3)',
                 binds:[opMsg, REQUEST_ID, Object.keys(this)[0]]
             }).execute();
         }
         return result;
```

## redbeard_cli/sqlfiles/R__process_request.sql

```diff
@@ -12,15 +12,15 @@
     try {
         // copy all new requests from stream into a local table to reset the stream
         var sqlCommand = "INSERT INTO HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.CLEAN_ROOM_REQUESTS (ID, REQUEST_TYPE, REQUEST_DATA, CREATED_AT, UPDATED_AT, REQUEST_STATUS) (SELECT ID, REQUEST_TYPE, REQUEST_DATA, CREATED_AT, UPDATED_AT, REQUEST_STATUS FROM CLEAN_ROOM.CLEAN_ROOM_REQUESTS_STREAM)";
         snowflake.execute({sqlText: sqlCommand});
 
         result = "SUCCESS";
 } catch (err) {
-        
+
         result = "FAILED";
         var stmt = snowflake.createStatement({
             sqlText: 'CALL CLEAN_ROOM.HANDLE_ERROR(:1, :2, :3, :4, :5, :6)',
             binds: [
                 err.code, err.state, err.message, err.stackTraceTxt, "", Object.keys(this)[0]
             ]
         });
```

## redbeard_cli/sqlfiles/R__question_run_cleanup.sql

```diff
@@ -6,15 +6,17 @@
     EXECUTE AS OWNER AS
     $$
         // Installs the handler for question cleanup
 
         try {
             var crRequestSql = "SELECT id AS request_id, request_data:clean_room_id AS clean_room_id,  " +
             " request_data:compute_account_id AS compute_account_id, " +
-            " request_data:statement_hash AS statement_hash " +
+            " request_data:statement_hash AS statement_hash, " +
+            " request_data:procedure_name AS procedure_name, " +
+            " request_data:clean_room_version AS clean_room_version " +
             " FROM HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.CLEAN_ROOM_REQUESTS " +
             " WHERE request_type = :1 AND request_status = :2 ORDER BY CREATED_AT ASC";
 
             var stmt = snowflake.createStatement({
                 sqlText: crRequestSql,
                 binds: ['QUESTION_RUN_CLEANUP', 'PENDING']
             });
@@ -22,88 +24,100 @@
             var rs = stmt.execute();
             var questionDataShareParams = [];
             while (rs.next()) {
                 var requestID = rs.getColumnValue(1);
                 var cleanRoomID = rs.getColumnValue(2);
                 var computeAccountId = rs.getColumnValue(3);
                 var statementHash = rs.getColumnValue(4);
+                var procedureName = rs.getColumnValue(5);
+                var cleanRoomVersion = rs.getColumnValue(6);
 
                 questionDataShareParams.push({
                     'requestID': requestID,
                     'cleanRoomID': cleanRoomID,
                     'computeAccountId': computeAccountId,
-                    'statementHash': statementHash
+                    'statementHash': statementHash,
+                    'procedureName': procedureName,
+                    'cleanRoomVersion': cleanRoomVersion,
                 })
                 snowflake.execute({
                         sqlText: "UPDATE HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.CLEAN_ROOM_REQUESTS SET REQUEST_STATUS = :1, UPDATED_AT = CURRENT_TIMESTAMP() WHERE ID = :2",
                         binds: ["IN_PROGRESS", requestID]
                 });
-}
+            }
 
             for (var i = 0; i < questionDataShareParams.length; i++){
                 var stmt = snowflake.createStatement({
-                    sqlText: 'CALL CLEAN_ROOM.QUESTION_RUN_CLEANUP(:1, :2, :3, :4)',
+                    sqlText: 'CALL CLEAN_ROOM.QUESTION_RUN_CLEANUP(:1, :2, :3, :4, :5, :6)',
                     binds: [
                         questionDataShareParams[i]['requestID'],
                         questionDataShareParams[i]['cleanRoomID'],
                         questionDataShareParams[i]['computeAccountId'],
-                        questionDataShareParams[i]['statementHash']
+                        questionDataShareParams[i]['statementHash'],
+                        questionDataShareParams[i]['procedureName'],
+                        questionDataShareParams[i]['cleanRoomVersion']
                     ]
                 });
                 stmt.execute();
-}
+            }
             result = "SUCCESS";
-} catch (err) {
-            
+        } catch (err) {
+
             result = "FAILED";
             var stmt = snowflake.createStatement({
                 sqlText: 'CALL CLEAN_ROOM.HANDLE_ERROR(:1, :2, :3, :4, :5, :6)',
                 binds: [
                     err.code, err.state, err.message, err.stackTraceTxt, "", Object.keys(this)[0]
                 ]
             });
             var res = stmt.execute();
-}
+        }
         return result;
     $$;
 
 CREATE OR REPLACE PROCEDURE HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.QUESTION_RUN_CLEANUP
-    (REQUEST_ID VARCHAR, CLEAN_ROOM_ID VARCHAR, COMPUTE_ACCOUNT_ID VARCHAR, STATEMENT_HASH VARCHAR)
+    (REQUEST_ID VARCHAR, CLEAN_ROOM_ID VARCHAR, COMPUTE_ACCOUNT_ID VARCHAR, STATEMENT_HASH VARCHAR, PROCEDURE_SQL VARCHAR, CLEAN_ROOM_VERSION VARCHAR)
     RETURNS STRING
     LANGUAGE JAVASCRIPT STRICT
     EXECUTE AS OWNER AS
     $$
         // Installs run clean up procedure
 
         try {
-            
+
             snowflake.execute({
                 sqlText: "DELETE FROM HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.ALLOWED_STATEMENTS WHERE ACCOUNT_ID = ? and CLEAN_ROOM_ID = ? and STATEMENT_HASH = ?",
                 binds: [COMPUTE_ACCOUNT_ID, CLEAN_ROOM_ID, STATEMENT_HASH]
-            })
+            });
+
+            if (CLEAN_ROOM_VERSION != null && CLEAN_ROOM_VERSION.trim().length != 0 && CLEAN_ROOM_VERSION === "2" && PROCEDURE_SQL != null && PROCEDURE_SQL.trim().length != 0) {
+                // drop procedure within allowed_procs schema
+                var dropProcedureSQL = "DROP PROCEDURE IF EXISTS " + PROCEDURE_SQL + "()"
+                snowflake.execute({sqlText: dropProcedureSQL});
+            }
 
-            // we can't remove partnersharedb because another parallel report run maybe using the same db and a different table.
+            // we cant remove partnersharedb because another parallel report run maybe using the same db and a different table.
             result = "COMPLETE";
-            msg = "Question run data share successful"
+            msg = "Question run cleanup successful"
         } catch (err) {
-                        result = "FAILED";
+            result = "FAILED";
             var stmt = snowflake.createStatement({
                 sqlText: 'CALL CLEAN_ROOM.HANDLE_ERROR(:1, :2, :3, :4, :5, :6)',
                 binds: [
                     err.code, err.state, err.message, err.stackTraceTxt, REQUEST_ID, Object.keys(this)[0]
                 ]
             });
             msg = err.message
             var res = stmt.execute();
         } finally {
             snowflake.execute({
                 sqlText: "UPDATE HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.CLEAN_ROOM_REQUESTS SET REQUEST_STATUS = :1, UPDATED_AT = CURRENT_TIMESTAMP() WHERE ID = :2",
                 binds: [result, REQUEST_ID]
             });
-                        opMsg = Object.keys(this)[0] + " - OPERATION STATUS - " + result + " - Detail: " + msg
+            opMsg = Object.keys(this)[0] + " - OPERATION STATUS - " + result + " - Detail: " + msg
             snowflake.createStatement({
                 sqlText: 'CALL CLEAN_ROOM.SP_LOGGER(:1, :2, :3)',
                 binds:[opMsg, REQUEST_ID, Object.keys(this)[0]]
             }).execute();
         }
         return result;
     $$;
```

## redbeard_cli/sqlfiles/R__question_run_data_share.sql

```diff
@@ -6,15 +6,18 @@
 	execute as owner as
 	$$
         // Installs the handler for question run data share
 
         try {
             var crRequestSql = "SELECT id AS request_id, request_data:clean_room_id AS clean_room_id,  " +
             " request_data:compute_account_id AS compute_account_id, " +
-            " request_data:statement_hash AS statement_hash " +
+            " request_data:statement_hash AS statement_hash, " +
+            " request_data:procedure_name AS procedure_name, " +
+            " request_data:procedure_sql AS procedure_sql, " +
+            " request_data:clean_room_version AS clean_room_version " +
             " FROM HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.CLEAN_ROOM_REQUESTS " +
             " WHERE request_type = :1 AND request_status = :2 ORDER BY CREATED_AT ASC";
 
             var stmt = snowflake.createStatement({
                 sqlText: crRequestSql,
                 binds: ['QUESTION_DATA_SHARE', 'PENDING']
             });
@@ -22,82 +25,100 @@
             var rs = stmt.execute();
             var questionDataShareParams = [];
             while (rs.next()) {
                 var requestID = rs.getColumnValue(1);
                 var cleanRoomID = rs.getColumnValue(2);
                 var computeAccountId = rs.getColumnValue(3);
                 var statementHash = rs.getColumnValue(4);
+                var procedureName = rs.getColumnValue(5);
+                var procedureSql = rs.getColumnValue(6);
+                var cleanRoomVersion = rs.getColumnValue(7);
 
                 questionDataShareParams.push({
                     'requestID': requestID,
                     'cleanRoomID': cleanRoomID,
                     'computeAccountId': computeAccountId,
-                    'statementHash': statementHash
+                    'statementHash': statementHash,
+                    'procedureName': procedureName,
+                    'procedureSql': procedureSql,
+                    'cleanRoomVersion': cleanRoomVersion,
+
                 })
                 snowflake.execute({
                         sqlText: "UPDATE HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.CLEAN_ROOM_REQUESTS SET REQUEST_STATUS = :1, UPDATED_AT = CURRENT_TIMESTAMP() WHERE ID = :2",
                         binds: ["IN_PROGRESS", requestID]
                 });
 }
 
             for (var i = 0; i < questionDataShareParams.length; i++){
                 var stmt = snowflake.createStatement({
-                    sqlText: 'CALL CLEAN_ROOM.QUESTION_RUN_DATA_SHARE(:1, :2, :3, :4)',
+                    sqlText: 'CALL CLEAN_ROOM.QUESTION_RUN_DATA_SHARE(:1, :2, :3, :4, :5, :6, :7)',
                     binds: [
                         questionDataShareParams[i]['requestID'],
                         questionDataShareParams[i]['cleanRoomID'],
                         questionDataShareParams[i]['computeAccountId'],
-                        questionDataShareParams[i]['statementHash']
+                        questionDataShareParams[i]['statementHash'],
+                        questionDataShareParams[i]['procedureName'],
+                        questionDataShareParams[i]['procedureSql'],
+                        questionDataShareParams[i]['cleanRoomVersion']
                     ]
                 });
                 stmt.execute();
 }
             result = "SUCCESS";
 } catch (err) {
-            
+
             result = "FAILED";
             var stmt = snowflake.createStatement({
                 sqlText: 'CALL CLEAN_ROOM.HANDLE_ERROR(:1, :2, :3, :4, :5, :6)',
                 binds: [
                     err.code, err.state, err.message, err.stackTraceTxt, "", Object.keys(this)[0]
                 ]
             });
             var res = stmt.execute();
 }
         return result;
 	$$;
 
 -- TODO: this requires share_restriction to be passed, how to do??
-CREATE OR REPLACE PROCEDURE HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.QUESTION_RUN_DATA_SHARE(REQUEST_ID VARCHAR, CLEAN_ROOM_ID VARCHAR, COMPUTE_ACCOUNT_ID VARCHAR, STATEMENT_HASH VARCHAR)
+CREATE OR REPLACE PROCEDURE HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.QUESTION_RUN_DATA_SHARE(REQUEST_ID VARCHAR, CLEAN_ROOM_ID VARCHAR, COMPUTE_ACCOUNT_ID VARCHAR, STATEMENT_HASH VARCHAR, PROCEDURE_NAME VARCHAR, PROCEDURE_SQL VARCHAR, CLEAN_ROOM_VERSION VARCHAR)
 	returns string
 	language javascript
 	execute as owner as
 	$$
         // Installs question run data share procedure
 
         try {
-            
+
             var sf_clean_room_id = CLEAN_ROOM_ID.replace(/-/g, '').toUpperCase();
             var partnerShareDb = "HABU_CR_" + sf_clean_room_id + "_PARTNER_SHARE"
 
             snowflake.execute({
                 sqlText: "INSERT INTO HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.ALLOWED_STATEMENTS (ACCOUNT_ID, CLEAN_ROOM_ID, STATEMENT_HASH) VALUES (:1, :2, :3)",
                 binds: [COMPUTE_ACCOUNT_ID, CLEAN_ROOM_ID, STATEMENT_HASH]
             })
 
             // TODO: for now hardcoding SHARE_RESTRICTIONS to false
             snowflake.execute({
                 sqlText: "ALTER SHARE " + partnerShareDb + " ADD ACCOUNTS = :1 SHARE_RESTRICTIONS=false",
                 binds: [COMPUTE_ACCOUNT_ID]
             });
 
+            if (CLEAN_ROOM_VERSION != null && CLEAN_ROOM_VERSION.trim().length != 0 && CLEAN_ROOM_VERSION === "2" && PROCEDURE_SQL != null && PROCEDURE_SQL.trim().length != 0) {
+                // create procedure within allowed_procs schema
+                snowflake.execute({sqlText: PROCEDURE_SQL});
+
+                // grants procedure access to the database role
+                snowflake.execute({sqlText: `GRANT USAGE ON PROCEDURE ${PROCEDURE_NAME}() TO DATABASE ROLE HABU_CLEAN_ROOM_${sf_clean_room_id}.habu_db_role_app_${sf_clean_room_id}`});
+            }
+
             result = "COMPLETE";
             msg = "Question run data share successful"
         } catch (err) {
-            
+
             result = "FAILED";
             var stmt = snowflake.createStatement({
                 sqlText: 'CALL CLEAN_ROOM.HANDLE_ERROR(:1, :2, :3, :4, :5, :6)',
                 binds: [
                     err.code, err.state, err.message, err.stackTraceTxt, REQUEST_ID, Object.keys(this)[0]
                 ]
             });
@@ -105,15 +126,15 @@
             var res = stmt.execute();
 } finally {
             snowflake.execute({
                 sqlText: "UPDATE HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.CLEAN_ROOM_REQUESTS SET REQUEST_STATUS = :1, UPDATED_AT = CURRENT_TIMESTAMP() WHERE ID = :2",
                 binds: [result, REQUEST_ID]
             });
 
-            
+
             opMsg = Object.keys(this)[0] + " - OPERATION STATUS - " + result + " - Detail: " + msg
             snowflake.createStatement({
                 sqlText: 'CALL CLEAN_ROOM.SP_LOGGER(:1, :2, :3)',
                 binds:[opMsg, REQUEST_ID, Object.keys(this)[0]]
             }).execute();
 }
         return result;
```

## redbeard_cli/sqlfiles/R__setup_cleanroom_common.sql

```diff
@@ -1,15 +1,15 @@
 BEGIN
 
 CREATE OR REPLACE PROCEDURE HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.SETUP_CLEANROOM_COMMON(HABU_ACCOUNT VARCHAR, CUSTOMER_ACCOUNT_ID VARCHAR, SHARE_RESTRICTIONS VARCHAR)
 	returns string
 	language javascript
 	execute as owner as
 	$$
-        
+
         sqlcmd = "CREATE DATABASE IF NOT EXISTS HABU_CLEAN_ROOM_COMMON COMMENT = 'HABU_" + CUSTOMER_ACCOUNT_ID + "'";
         snowflake.execute({ sqlText: sqlcmd });
         sqlcmd = "CREATE SCHEMA IF NOT EXISTS HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM COMMENT = 'HABU_" + CUSTOMER_ACCOUNT_ID + "'";
         snowflake.execute({ sqlText: sqlcmd });
         sqlcmd = "CREATE TABLE IF NOT EXISTS HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.ALLOWED_STATEMENTS " +
             "(ACCOUNT_ID VARCHAR(100), CLEAN_ROOM_ID VARCHAR(100), STATEMENT_HASH VARCHAR(100))";
         snowflake.execute({ sqlText: sqlcmd });
@@ -17,15 +17,15 @@
             "ID VARCHAR(40) NOT NULL," +
             "REQUEST_TYPE VARCHAR(50) NOT NULL," +
             "REQUEST_DATA VARIANT," +
             "CREATED_AT TIMESTAMP," +
             "UPDATED_AT TIMESTAMP," +
             "REQUEST_STATUS VARCHAR(50))";
         snowflake.execute({ sqlText: sqlcmd });
-	  sqlcmd = "ALTER TABLE HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.CLEAN_ROOM_REQUESTS SET CHANGE_TRACKING = TRUE;"
+        sqlcmd = "ALTER TABLE HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.CLEAN_ROOM_REQUESTS SET CHANGE_TRACKING = TRUE;"
         snowflake.execute({ sqlText: sqlcmd });
         sqlcmd = "CREATE TABLE IF NOT EXISTS HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.CLEAN_ROOM_ERRORS (" +
             "CODE NUMBER," +
             "STATE STRING," +
             "MESSAGE STRING," +
             "STACK_TRACE STRING," +
             "CREATED_AT TIMESTAMP," +
```

## redbeard_cli/sqlfiles/R__setup_data_connection_objects.sql

```diff
@@ -1,15 +1,15 @@
 BEGIN
 
 CREATE OR REPLACE PROCEDURE HABU_CLEAN_ROOM_COMMON.CLEAN_ROOM.SETUP_DATA_CONNECTION_OBJECTS(HABU_ORG_NAME_ACCOUNT_NAME_COMBO VARCHAR, CUSTOMER_ACCOUNT_ID VARCHAR, SHARE_RESTRICTIONS VARCHAR)
 	returns string
 	language javascript
 	execute as owner as
 	$$
-        
+
         var customer_account_locator = CUSTOMER_ACCOUNT_ID.split(".")[0].toUpperCase();
         sqlcmd = "CREATE DATABASE IF NOT EXISTS HABU_DATA_CONNECTIONS COMMENT = 'HABU_" + customer_account_locator + "'";
         snowflake.execute({ sqlText: sqlcmd });
         sqlcmd = "CREATE SCHEMA IF NOT EXISTS HABU_DATA_CONNECTIONS.DATA_CONNECTIONS COMMENT = 'HABU_" + customer_account_locator + "'";
         snowflake.execute({ sqlText: sqlcmd });
         sqlcmd = "CREATE TABLE IF NOT EXISTS HABU_DATA_CONNECTIONS.DATA_CONNECTIONS.DATA_CONNECTIONS (" +
             "ID VARCHAR(40) NOT NULL," +
```

## redbeard_cli/sqlfiles/R__setup_streams_tasks.sql

```diff
@@ -11,15 +11,15 @@
     // the machinery for db-rpc
     var sf_org_id = ORGANIZATON_ID.replace(/-/g, '').toUpperCase();
     var setup_stream_sql = "CREATE OR REPLACE STREAM CLEAN_ROOM.CLEAN_ROOM_REQUESTS_STREAM \
         ON TABLE HABU_ORG_" + sf_org_id + "_SHARE_DB.CLEAN_ROOM.CLEAN_ROOM_REQUESTS \
         APPEND_ONLY=TRUE \
         COMMENT = 'HABU_" + CUSTOMER_ACCOUNT_ID + "'";
     snowflake.execute({ sqlText: setup_stream_sql });
-// stream has been setup, now create a task that listens to the stream and triggers the
+    // stream has been setup, now create a task that listens to the stream and triggers the
     // PROCESS_ORG_REQUEST stored procedure to process pending clean room requests
     var copy_task_sql = "CREATE OR REPLACE TASK CLEAN_ROOM.CLEAN_ROOM_REQUESTS_TASK \
         SCHEDULE = '1 MINUTE' \
         ALLOW_OVERLAPPING_EXECUTION = TRUE \
         USER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE = 'XSMALL' \
         WHEN SYSTEM$STREAM_HAS_DATA('CLEAN_ROOM.CLEAN_ROOM_REQUESTS_STREAM') \
         AS CALL CLEAN_ROOM.PROCESS_ORG_REQUEST()"
@@ -60,18 +60,18 @@
         AS CALL CLEAN_ROOM.HANDLE_MANAGEMENT_COMMANDS()"
     snowflake.execute({ sqlText: mgmt_commands_task });
     add_data_connection_task = "CREATE OR REPLACE TASK CLEAN_ROOM.HANDLE_ADD_DATA_CONNECTION_TASK \
             USER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE = 'XSMALL' \
             AFTER CLEAN_ROOM.CLEAN_ROOM_REQUESTS_TASK \
             AS CALL CLEAN_ROOM.HANDLE_ADD_DATA_CONNECTION()"
     snowflake.execute({ sqlText: add_data_connection_task });
-// tasks are created in 'suspend' mode root and all dependent tasks need to be enabled explicitly
+    // tasks are created in 'suspend' mode root and all dependent tasks need to be enabled explicitly
     // TODO: fails with error - SQL compilation error: Query called from a stored procedure contains a function with side effects [SYSTEM$TASK_DEPENDENTS_ENABLE]
     // snowflake.execute({ sqlText: "SELECT SYSTEM$TASK_DEPENDENTS_ENABLE('CLEAN_ROOM.CLEAN_ROOM_REQUESTS_TASK')" });
-// Since recursively resuming all the dependent task tied to root task is not working,
+    // Since recursively resuming all the dependent task tied to root task is not working,
     // explicitly resuming all the tasks in reverse order. Children tasks muste be started before the root task.
     snowflake.execute({ sqlText: "ALTER TASK CLEAN_ROOM.HANDLE_POST_RUN_QUERY_TASK RESUME" });
     snowflake.execute({ sqlText: "ALTER TASK CLEAN_ROOM.HANDLE_ADD_DATA_CONNECTION_TASK RESUME" });
     snowflake.execute({ sqlText: "ALTER TASK CLEAN_ROOM.HANDLE_MGMT_COMMANDS_TASK RESUME" });
     snowflake.execute({ sqlText: "ALTER TASK CLEAN_ROOM.HANDLE_NEW_QUESTION_RUNS_TASK RESUME" });
     snowflake.execute({ sqlText: "ALTER TASK CLEAN_ROOM.HANDLE_QUESTION_RUN_CLEANUP_TASK RESUME" });
     snowflake.execute({ sqlText: "ALTER TASK CLEAN_ROOM.HANDLE_QUESTION_RUN_DATA_SHARE_TASK RESUME" });
```

## Comparing `habu_snowflake_cli-3.6.4.dist-info/METADATA` & `habu_snowflake_cli-4.0.0.dist-info/METADATA`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: habu-snowflake-cli
-Version: 3.6.4
+Version: 4.0.0
 Summary: Redbeard - Habu Snowflake CLI
 Home-page: https://github.com/deklareddotcom/redbeard
 Author: Habu Engineering
 Author-email: engineering@habu.com
 Requires-Python: >=3.7.10
 Description-Content-Type: text/markdown
 Requires-Dist: python-dotenv (~=0.17.0)
```

## Comparing `habu_snowflake_cli-3.6.4.dist-info/RECORD` & `habu_snowflake_cli-4.0.0.dist-info/RECORD`

 * *Files 20% similar despite different names*

```diff
@@ -6,30 +6,30 @@
 redbeard_cli/commands/init/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 redbeard_cli/commands/init/clean_room_setup.py,sha256=WFkyIYfBJlRa9Hb60gVlb2vnOv4Fkh1vTL7Mrm_4afM,2109
 redbeard_cli/commands/init/cli.py,sha256=CHxf2NiS8mCPnY4TJQPai6Bu6i9T-i3ZQuRXB6Av2Wg,2259
 redbeard_cli/commands/init/habu_setup.py,sha256=mxY49fPBmNpPKuapnvhdN2_EYu4soi9ESkumf4q0HBU,3686
 redbeard_cli/example/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 redbeard_cli/example/dataset.py,sha256=_BA2SvWSzQDP5PDlOsdxsZGOyFL6mskWrUifx2whXrk,5110
 redbeard_cli/example/overlap_queries.py,sha256=eTjgpHD6Z0Bz7E-gHBrc0YUDlpe4oBXvjJO2XlPdvK4,5678
-redbeard_cli/sqlfiles/R__1init_habu_installer.sql,sha256=oSgjLvZrGke3LcKNAEaFo6pw7tqdmX-miv662uJoekU,3438
-redbeard_cli/sqlfiles/R__create_new_dataset.sql,sha256=Dhul1qsJ33IcdAVkazMaEYG_4eWn-YXUxQ7and7gA1U,8620
+redbeard_cli/sqlfiles/R__1init_habu_installer.sql,sha256=n82olM-HfQ0NX9a91xPAE0SCDqt1zYaEoPc5fzBbgOE,3449
+redbeard_cli/sqlfiles/R__create_new_dataset.sql,sha256=O9UEKtxTf5RO_IbgQpYILlM-BYB-_1fhHWevqh5CoGU,10769
 redbeard_cli/sqlfiles/R__handle_error.sql,sha256=O7F7KGxU7cTWReSXRrIl0FIVTgZsEPGBpWuhsQHJaJM,772
-redbeard_cli/sqlfiles/R__handle_management_command.sql,sha256=P9V9I-CJTo3T-QkE4PiT082KR4nHkZriiZU2z6K_wag,3427
-redbeard_cli/sqlfiles/R__handle_new_cleanrooms.sql,sha256=-QKb3fvci4X2OKMOBHOoG0MWiSvof9envR2eBgZYql0,8179
-redbeard_cli/sqlfiles/R__init_habu_shares.sql,sha256=Lx88m6RVKAaWdrlDFpj7K__ei1Twyx8rEDLz24C6w40,2101
-redbeard_cli/sqlfiles/R__new_data_connection.sql,sha256=XoT5P5Ko2w0EPluzUNk0jyc3xdshvOgX5LyjxYHF7kE,8847
-redbeard_cli/sqlfiles/R__new_question_run.sql,sha256=-9MjHd9-vfl1kkgYHeao_O2ZaxLLNRa0tN0-ITv-cqQ,8719
-redbeard_cli/sqlfiles/R__post_run_query.sql,sha256=Ie-Gal2YtA-eoGPjj7DJ8O_7J62KSw2Pv3zdHQ3M-RI,5008
-redbeard_cli/sqlfiles/R__process_request.sql,sha256=3yH5EuHBGLkRubZSclyz4-jRcFsxXGXvFqCPjneTYco,1240
-redbeard_cli/sqlfiles/R__question_run_cleanup.sql,sha256=dFMiadN2DrbzVTZk248f0Wu_WkfDGwK-74-UFXZ50XQ,4658
-redbeard_cli/sqlfiles/R__question_run_data_share.sql,sha256=nylTCxntlceTSWcbnf2U8Gvfq_6SrGZpaXqegTzH8nI,4992
-redbeard_cli/sqlfiles/R__setup_cleanroom_common.sql,sha256=WnZtsSc3o0H0mz-TMCWOgeSa5S93Ycg6YzdNADsHqz8,4066
-redbeard_cli/sqlfiles/R__setup_data_connection_objects.sql,sha256=U5FuHpq_uIKbIrVLozAAe_Crzz1La5bEHQN9FDQBFQU,3181
-redbeard_cli/sqlfiles/R__setup_streams_tasks.sql,sha256=5qFqkwUfYkVxw1g3MH1hL19LazyqrMWPh8g0f_hPA8s,5641
+redbeard_cli/sqlfiles/R__handle_management_command.sql,sha256=EGP9GNt8nE9lKynzqlGohBeH9HSyaAPl_5tyvrQ5N40,3403
+redbeard_cli/sqlfiles/R__handle_new_cleanrooms.sql,sha256=F_eBco_PTo1FIvTTSMLMOujqnIHY8sLcmlwi3EWOqQ8,14012
+redbeard_cli/sqlfiles/R__init_habu_shares.sql,sha256=eWiskB-Dc1J-flvL0YtBHUKEjuEolpMO_YsnyPH7HU8,2092
+redbeard_cli/sqlfiles/R__new_data_connection.sql,sha256=j7bxCMl1lyfd9pGjXXgKPhEClr5AtsnuK0o34oW0rYY,8799
+redbeard_cli/sqlfiles/R__new_question_run.sql,sha256=lqx42QIBL-GiNW6feS3P6ueORgmUk2yFrxQN0wQqvX8,10879
+redbeard_cli/sqlfiles/R__post_run_query.sql,sha256=gBHFYote4IXxXyAcQgQrxQvsWHTgcfGfHUQVmTyrE-k,4960
+redbeard_cli/sqlfiles/R__process_request.sql,sha256=92ww0gUZ2OCNlE7zfL8iv_jaGCVc4KtjcKir7HwM4ko,1232
+redbeard_cli/sqlfiles/R__question_run_cleanup.sql,sha256=4MdhO19KzcykHE8bZieOvihY57lqaaHtOIXjDfFpqv8,5624
+redbeard_cli/sqlfiles/R__question_run_data_share.sql,sha256=2ZEzlnCHv6bWoug7ZzpfqzmqivVnGPytjB50bmKa3uY,6346
+redbeard_cli/sqlfiles/R__setup_cleanroom_common.sql,sha256=JKUVVtYr4uZt8nFcUUzJkyIoVoSsg1dMmQipFTfgkOU,4063
+redbeard_cli/sqlfiles/R__setup_data_connection_objects.sql,sha256=A0TjYFN2kshUWA1tonnvjV3GaoWg1eoA1p2tv5_CRaE,3173
+redbeard_cli/sqlfiles/R__setup_streams_tasks.sql,sha256=IQKGJdGY2kbYJCCghHFGZPwlWxFBz7xZqSzXP-vdk8Y,5653
 redbeard_cli/sqlfiles/R__sp_logger.sql,sha256=qPlR74KPyCqwtPV2aTscBu5ibDHKFfFF2WpG1GFNVIE,603
 redbeard_cli/sqlfiles/V1_0_0_create.sql,sha256=wSHv2p4FLQaB86zT4Z6mJNY7c3-yBSPTnn5z3cJTau4,230
 redbeard_cli/sqlfiles/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-habu_snowflake_cli-3.6.4.dist-info/METADATA,sha256=b92XMiHmT_y1rSUby3-_J6R8rOUOELUTQKU6EBvqpuY,1370
-habu_snowflake_cli-3.6.4.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-habu_snowflake_cli-3.6.4.dist-info/entry_points.txt,sha256=9mLwEgYq-eMv3F-c_p2EuoHFvOcQV8H-ozKR7BIF3Og,42
-habu_snowflake_cli-3.6.4.dist-info/top_level.txt,sha256=n-bjqTpxh0D3sxTdlhDISfzTBZQR-i_qg9rHbFXL40A,22
-habu_snowflake_cli-3.6.4.dist-info/RECORD,,
+habu_snowflake_cli-4.0.0.dist-info/METADATA,sha256=K_tGUCBq0iSKzm1cuscFE4SEMZPYBT3GnTWrFaSYl30,1370
+habu_snowflake_cli-4.0.0.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+habu_snowflake_cli-4.0.0.dist-info/entry_points.txt,sha256=9mLwEgYq-eMv3F-c_p2EuoHFvOcQV8H-ozKR7BIF3Og,42
+habu_snowflake_cli-4.0.0.dist-info/top_level.txt,sha256=n-bjqTpxh0D3sxTdlhDISfzTBZQR-i_qg9rHbFXL40A,22
+habu_snowflake_cli-4.0.0.dist-info/RECORD,,
```


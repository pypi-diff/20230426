# Comparing `tmp/plato_learn-0.4.8-py36.py37.py38.py39-none-any.whl.zip` & `tmp/plato_learn-0.4.9-py36.py37.py38.py39-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,184 +1,185 @@
-Zip file size: 240599 bytes, number of entries: 182
--rw-r--r--  2.0 unx       22 b- defN 23-Apr-18 19:23 plato/__init__.py
--rw-r--r--  2.0 unx     1957 b- defN 23-Apr-18 19:23 plato/client.py
--rw-r--r--  2.0 unx    13592 b- defN 23-Apr-18 19:23 plato/config.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 19:23 plato/algorithms/__init__.py
--rw-r--r--  2.0 unx     1102 b- defN 23-Apr-18 19:23 plato/algorithms/base.py
--rw-r--r--  2.0 unx     1576 b- defN 23-Apr-18 19:23 plato/algorithms/fedavg.py
--rw-r--r--  2.0 unx     2867 b- defN 23-Apr-18 19:23 plato/algorithms/fedavg_gan.py
--rw-r--r--  2.0 unx     5558 b- defN 23-Apr-18 19:23 plato/algorithms/fedavg_partial.py
--rw-r--r--  2.0 unx     1476 b- defN 23-Apr-18 19:23 plato/algorithms/mistnet.py
--rw-r--r--  2.0 unx     1445 b- defN 23-Apr-18 19:23 plato/algorithms/registry.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 19:23 plato/callbacks/__init__.py
--rw-r--r--  2.0 unx     1654 b- defN 23-Apr-18 19:23 plato/callbacks/client.py
--rw-r--r--  2.0 unx     2639 b- defN 23-Apr-18 19:23 plato/callbacks/handler.py
--rw-r--r--  2.0 unx     4244 b- defN 23-Apr-18 19:23 plato/callbacks/server.py
--rw-r--r--  2.0 unx     3804 b- defN 23-Apr-18 19:23 plato/callbacks/trainer.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 19:23 plato/clients/__init__.py
--rw-r--r--  2.0 unx    16728 b- defN 23-Apr-18 19:23 plato/clients/base.py
--rw-r--r--  2.0 unx     3455 b- defN 23-Apr-18 19:23 plato/clients/edge.py
--rw-r--r--  2.0 unx     1491 b- defN 23-Apr-18 19:23 plato/clients/mistnet.py
--rw-r--r--  2.0 unx     1067 b- defN 23-Apr-18 19:23 plato/clients/registry.py
--rw-r--r--  2.0 unx     8173 b- defN 23-Apr-18 19:23 plato/clients/simple.py
--rw-r--r--  2.0 unx    13477 b- defN 23-Apr-18 19:23 plato/clients/simple_personalized.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 19:23 plato/datasources/__init__.py
--rw-r--r--  2.0 unx     4090 b- defN 23-Apr-18 19:23 plato/datasources/base.py
--rw-r--r--  2.0 unx     4563 b- defN 23-Apr-18 19:23 plato/datasources/celeba.py
--rw-r--r--  2.0 unx     1716 b- defN 23-Apr-18 19:23 plato/datasources/cifar10.py
--rw-r--r--  2.0 unx     1720 b- defN 23-Apr-18 19:23 plato/datasources/cifar100.py
--rw-r--r--  2.0 unx     1723 b- defN 23-Apr-18 19:23 plato/datasources/cinic10.py
--rw-r--r--  2.0 unx     4507 b- defN 23-Apr-18 19:23 plato/datasources/coco.py
--rw-r--r--  2.0 unx     1737 b- defN 23-Apr-18 19:23 plato/datasources/emnist.py
--rw-r--r--  2.0 unx     1073 b- defN 23-Apr-18 19:23 plato/datasources/fashion_mnist.py
--rw-r--r--  2.0 unx      612 b- defN 23-Apr-18 19:23 plato/datasources/feature.py
--rw-r--r--  2.0 unx      361 b- defN 23-Apr-18 19:23 plato/datasources/feature_dataset.py
--rw-r--r--  2.0 unx     4673 b- defN 23-Apr-18 19:23 plato/datasources/femnist.py
--rw-r--r--  2.0 unx    13862 b- defN 23-Apr-18 19:23 plato/datasources/flickr30k_entities.py
--rw-r--r--  2.0 unx    16869 b- defN 23-Apr-18 19:23 plato/datasources/gym.py
--rw-r--r--  2.0 unx     5572 b- defN 23-Apr-18 19:23 plato/datasources/huggingface.py
--rw-r--r--  2.0 unx    23377 b- defN 23-Apr-18 19:23 plato/datasources/kinetics.py
--rw-r--r--  2.0 unx     1032 b- defN 23-Apr-18 19:23 plato/datasources/mnist.py
--rw-r--r--  2.0 unx    13106 b- defN 23-Apr-18 19:23 plato/datasources/multimodal_base.py
--rw-r--r--  2.0 unx     1482 b- defN 23-Apr-18 19:23 plato/datasources/pascal_voc.py
--rw-r--r--  2.0 unx     3022 b- defN 23-Apr-18 19:23 plato/datasources/purchase.py
--rw-r--r--  2.0 unx     4224 b- defN 23-Apr-18 19:23 plato/datasources/qoenflx.py
--rw-r--r--  2.0 unx    11322 b- defN 23-Apr-18 19:23 plato/datasources/referitgame.py
--rw-r--r--  2.0 unx     3720 b- defN 23-Apr-18 19:23 plato/datasources/registry.py
--rw-r--r--  2.0 unx     3189 b- defN 23-Apr-18 19:23 plato/datasources/texas.py
--rw-r--r--  2.0 unx     1943 b- defN 23-Apr-18 19:23 plato/datasources/tiny_imagenet.py
--rw-r--r--  2.0 unx     5189 b- defN 23-Apr-18 19:23 plato/datasources/yolo.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 19:23 plato/datasources/datalib/__init__.py
--rw-r--r--  2.0 unx     4718 b- defN 23-Apr-18 19:23 plato/datasources/datalib/audio_extraction_tools.py
--rw-r--r--  2.0 unx     3816 b- defN 23-Apr-18 19:23 plato/datasources/datalib/data_utils.py
--rw-r--r--  2.0 unx    12779 b- defN 23-Apr-18 19:23 plato/datasources/datalib/flickr30kE_utils.py
--rw-r--r--  2.0 unx     8170 b- defN 23-Apr-18 19:23 plato/datasources/datalib/frames_extraction_tools.py
--rw-r--r--  2.0 unx     6699 b- defN 23-Apr-18 19:23 plato/datasources/datalib/modality_data_anntation_tools.py
--rw-r--r--  2.0 unx     2253 b- defN 23-Apr-18 19:23 plato/datasources/datalib/modality_extraction_base.py
--rw-r--r--  2.0 unx     7717 b- defN 23-Apr-18 19:23 plato/datasources/datalib/parse_datasets.py
--rw-r--r--  2.0 unx     3248 b- defN 23-Apr-18 19:23 plato/datasources/datalib/tiny_data_tools.py
--rw-r--r--  2.0 unx     2262 b- defN 23-Apr-18 19:23 plato/datasources/datalib/video_transform.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 19:23 plato/datasources/datalib/gym_utils/__init__.py
--rw-r--r--  2.0 unx     6056 b- defN 23-Apr-18 19:23 plato/datasources/datalib/gym_utils/gym_trim.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 19:23 plato/datasources/datalib/refer_utils/__init__.py
--rw-r--r--  2.0 unx     9358 b- defN 23-Apr-18 19:23 plato/datasources/datalib/refer_utils/referitgame_utils.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 19:23 plato/models/__init__.py
--rw-r--r--  2.0 unx     3528 b- defN 23-Apr-18 19:23 plato/models/cnn_encoder.py
--rw-r--r--  2.0 unx     3396 b- defN 23-Apr-18 19:23 plato/models/dcgan.py
--rw-r--r--  2.0 unx     9498 b- defN 23-Apr-18 19:23 plato/models/general_multilayer.py
--rw-r--r--  2.0 unx      750 b- defN 23-Apr-18 19:23 plato/models/huggingface.py
--rw-r--r--  2.0 unx     3644 b- defN 23-Apr-18 19:23 plato/models/lenet5.py
--rw-r--r--  2.0 unx     2552 b- defN 23-Apr-18 19:23 plato/models/multilayer.py
--rw-r--r--  2.0 unx     2497 b- defN 23-Apr-18 19:23 plato/models/registry.py
--rw-r--r--  2.0 unx     6442 b- defN 23-Apr-18 19:23 plato/models/resnet.py
--rw-r--r--  2.0 unx      445 b- defN 23-Apr-18 19:23 plato/models/torch_hub.py
--rw-r--r--  2.0 unx     2981 b- defN 23-Apr-18 19:23 plato/models/vgg.py
--rw-r--r--  2.0 unx     5151 b- defN 23-Apr-18 19:23 plato/models/vit.py
--rw-r--r--  2.0 unx     1849 b- defN 23-Apr-18 19:23 plato/models/yolov5.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 19:23 plato/models/multimodal/__init__.py
--rw-r--r--  2.0 unx     3020 b- defN 23-Apr-18 19:23 plato/models/multimodal/base_net.py
--rw-r--r--  2.0 unx     5055 b- defN 23-Apr-18 19:23 plato/models/multimodal/blending.py
--rw-r--r--  2.0 unx     2414 b- defN 23-Apr-18 19:23 plato/models/multimodal/fc_net.py
--rw-r--r--  2.0 unx     3183 b- defN 23-Apr-18 19:23 plato/models/multimodal/fusion_net.py
--rw-r--r--  2.0 unx     6560 b- defN 23-Apr-18 19:23 plato/models/multimodal/multimodal_module.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 19:23 plato/processors/__init__.py
--rw-r--r--  2.0 unx      888 b- defN 23-Apr-18 19:23 plato/processors/base.py
--rw-r--r--  2.0 unx     1240 b- defN 23-Apr-18 19:23 plato/processors/compress.py
--rw-r--r--  2.0 unx     1564 b- defN 23-Apr-18 19:23 plato/processors/decompress.py
--rw-r--r--  2.0 unx     1320 b- defN 23-Apr-18 19:23 plato/processors/feature.py
--rw-r--r--  2.0 unx     1127 b- defN 23-Apr-18 19:23 plato/processors/feature_additive_noise.py
--rw-r--r--  2.0 unx      878 b- defN 23-Apr-18 19:23 plato/processors/feature_dequantize.py
--rw-r--r--  2.0 unx      619 b- defN 23-Apr-18 19:23 plato/processors/feature_gaussian.py
--rw-r--r--  2.0 unx      493 b- defN 23-Apr-18 19:23 plato/processors/feature_laplace.py
--rw-r--r--  2.0 unx     1022 b- defN 23-Apr-18 19:23 plato/processors/feature_quantize.py
--rw-r--r--  2.0 unx     1411 b- defN 23-Apr-18 19:23 plato/processors/feature_randomized_response.py
--rw-r--r--  2.0 unx     1006 b- defN 23-Apr-18 19:23 plato/processors/feature_unbatch.py
--rw-r--r--  2.0 unx     1115 b- defN 23-Apr-18 19:23 plato/processors/inbound_feature_tensors.py
--rw-r--r--  2.0 unx     1626 b- defN 23-Apr-18 19:23 plato/processors/model.py
--rw-r--r--  2.0 unx      860 b- defN 23-Apr-18 19:23 plato/processors/model_compress.py
--rw-r--r--  2.0 unx      853 b- defN 23-Apr-18 19:23 plato/processors/model_decompress.py
--rw-r--r--  2.0 unx     1071 b- defN 23-Apr-18 19:23 plato/processors/model_decrypt.py
--rw-r--r--  2.0 unx      427 b- defN 23-Apr-18 19:23 plato/processors/model_deepcopy.py
--rw-r--r--  2.0 unx      398 b- defN 23-Apr-18 19:23 plato/processors/model_dequantize.py
--rw-r--r--  2.0 unx     1950 b- defN 23-Apr-18 19:23 plato/processors/model_dequantize_qsgd.py
--rw-r--r--  2.0 unx     1088 b- defN 23-Apr-18 19:23 plato/processors/model_encrypt.py
--rw-r--r--  2.0 unx      420 b- defN 23-Apr-18 19:23 plato/processors/model_quantize.py
--rw-r--r--  2.0 unx     2922 b- defN 23-Apr-18 19:23 plato/processors/model_quantize_qsgd.py
--rw-r--r--  2.0 unx      939 b- defN 23-Apr-18 19:23 plato/processors/model_randomized_response.py
--rw-r--r--  2.0 unx      994 b- defN 23-Apr-18 19:23 plato/processors/outbound_feature_ndarrays.py
--rw-r--r--  2.0 unx      675 b- defN 23-Apr-18 19:23 plato/processors/pipeline.py
--rw-r--r--  2.0 unx     4267 b- defN 23-Apr-18 19:23 plato/processors/registry.py
--rw-r--r--  2.0 unx     1534 b- defN 23-Apr-18 19:23 plato/processors/send_mask.py
--rw-r--r--  2.0 unx     2066 b- defN 23-Apr-18 19:23 plato/processors/structured_pruning.py
--rw-r--r--  2.0 unx     1928 b- defN 23-Apr-18 19:23 plato/processors/unstructured_pruning.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 19:23 plato/samplers/__init__.py
--rw-r--r--  2.0 unx     1540 b- defN 23-Apr-18 19:23 plato/samplers/all_inclusive.py
--rw-r--r--  2.0 unx      906 b- defN 23-Apr-18 19:23 plato/samplers/base.py
--rw-r--r--  2.0 unx     2703 b- defN 23-Apr-18 19:23 plato/samplers/dirichlet.py
--rw-r--r--  2.0 unx     5184 b- defN 23-Apr-18 19:23 plato/samplers/distribution_noniid.py
--rw-r--r--  2.0 unx     1738 b- defN 23-Apr-18 19:23 plato/samplers/iid.py
--rw-r--r--  2.0 unx     4613 b- defN 23-Apr-18 19:23 plato/samplers/label_quantity_noniid.py
--rw-r--r--  2.0 unx     1599 b- defN 23-Apr-18 19:23 plato/samplers/mixed.py
--rw-r--r--  2.0 unx     5276 b- defN 23-Apr-18 19:23 plato/samplers/mixed_label_quantity_noniid.py
--rw-r--r--  2.0 unx     1246 b- defN 23-Apr-18 19:23 plato/samplers/modality_iid.py
--rw-r--r--  2.0 unx     1715 b- defN 23-Apr-18 19:23 plato/samplers/modality_quantity_noniid.py
--rw-r--r--  2.0 unx     3461 b- defN 23-Apr-18 19:23 plato/samplers/orthogonal.py
--rw-r--r--  2.0 unx     2631 b- defN 23-Apr-18 19:23 plato/samplers/registry.py
--rw-r--r--  2.0 unx     4124 b- defN 23-Apr-18 19:23 plato/samplers/sample_quantity_noniid.py
--rw-r--r--  2.0 unx     7650 b- defN 23-Apr-18 19:23 plato/samplers/sampler_utils.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 19:23 plato/servers/__init__.py
--rw-r--r--  2.0 unx    56762 b- defN 23-Apr-18 19:23 plato/servers/base.py
--rw-r--r--  2.0 unx    10236 b- defN 23-Apr-18 19:23 plato/servers/fedavg.py
--rw-r--r--  2.0 unx    13169 b- defN 23-Apr-18 19:23 plato/servers/fedavg_cs.py
--rw-r--r--  2.0 unx     2691 b- defN 23-Apr-18 19:23 plato/servers/fedavg_gan.py
--rw-r--r--  2.0 unx     3952 b- defN 23-Apr-18 19:23 plato/servers/fedavg_he.py
--rw-r--r--  2.0 unx    16998 b- defN 23-Apr-18 19:23 plato/servers/fedavg_personalized.py
--rw-r--r--  2.0 unx     2279 b- defN 23-Apr-18 19:23 plato/servers/mistnet.py
--rw-r--r--  2.0 unx     1386 b- defN 23-Apr-18 19:23 plato/servers/registry.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 19:23 plato/trainers/__init__.py
--rw-r--r--  2.0 unx     3128 b- defN 23-Apr-18 19:23 plato/trainers/base.py
--rw-r--r--  2.0 unx    22736 b- defN 23-Apr-18 19:23 plato/trainers/basic.py
--rw-r--r--  2.0 unx    25810 b- defN 23-Apr-18 19:23 plato/trainers/basic_personalized.py
--rw-r--r--  2.0 unx     6789 b- defN 23-Apr-18 19:23 plato/trainers/diff_privacy.py
--rw-r--r--  2.0 unx    12763 b- defN 23-Apr-18 19:23 plato/trainers/gan.py
--rw-r--r--  2.0 unx     4901 b- defN 23-Apr-18 19:23 plato/trainers/huggingface.py
--rw-r--r--  2.0 unx     1463 b- defN 23-Apr-18 19:23 plato/trainers/loss_criterion.py
--rw-r--r--  2.0 unx     8685 b- defN 23-Apr-18 19:23 plato/trainers/lr_schedulers.py
--rw-r--r--  2.0 unx     1329 b- defN 23-Apr-18 19:23 plato/trainers/optimizers.py
--rw-r--r--  2.0 unx     2705 b- defN 23-Apr-18 19:23 plato/trainers/pascal_voc.py
--rw-r--r--  2.0 unx     1640 b- defN 23-Apr-18 19:23 plato/trainers/registry.py
--rw-r--r--  2.0 unx     2828 b- defN 23-Apr-18 19:23 plato/trainers/tracking.py
--rw-r--r--  2.0 unx    16487 b- defN 23-Apr-18 19:23 plato/trainers/yolov5.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 19:23 plato/trainers/mindspore/__init__.py
--rw-r--r--  2.0 unx     4481 b- defN 23-Apr-18 19:23 plato/trainers/mindspore/basic.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 19:23 plato/utils/__init__.py
--rw-r--r--  2.0 unx     9238 b- defN 23-Apr-18 19:23 plato/utils/checkpoint_operator.py
--rw-r--r--  2.0 unx      879 b- defN 23-Apr-18 19:23 plato/utils/count_parameters.py
--rw-r--r--  2.0 unx      843 b- defN 23-Apr-18 19:23 plato/utils/csv_processor.py
--rw-r--r--  2.0 unx     5300 b- defN 23-Apr-18 19:23 plato/utils/data_loaders.py
--rw-r--r--  2.0 unx      590 b- defN 23-Apr-18 19:23 plato/utils/decorators.py
--rw-r--r--  2.0 unx     1353 b- defN 23-Apr-18 19:23 plato/utils/filename_formatter.py
--rw-r--r--  2.0 unx      716 b- defN 23-Apr-18 19:23 plato/utils/fonts.py
--rw-r--r--  2.0 unx     5873 b- defN 23-Apr-18 19:23 plato/utils/homo_enc.py
--rw-r--r--  2.0 unx     5173 b- defN 23-Apr-18 19:23 plato/utils/rl_env.py
--rw-r--r--  2.0 unx     5550 b- defN 23-Apr-18 19:23 plato/utils/s3.py
--rw-r--r--  2.0 unx     1355 b- defN 23-Apr-18 19:23 plato/utils/unary_encoding.py
--rw-r--r--  2.0 unx    12179 b- defN 23-Apr-18 19:23 plato/utils/visual_augmentations.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 19:23 plato/utils/lib_mia/__init__.py
--rw-r--r--  2.0 unx     4308 b- defN 23-Apr-18 19:23 plato/utils/lib_mia/mia.py
--rw-r--r--  2.0 unx     1183 b- defN 23-Apr-18 19:23 plato/utils/lib_mia/mia_client.py
--rw-r--r--  2.0 unx     3617 b- defN 23-Apr-18 19:23 plato/utils/lib_mia/mia_server.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 19:23 plato/utils/reinforcement_learning/__init__.py
--rw-r--r--  2.0 unx     4487 b- defN 23-Apr-18 19:23 plato/utils/reinforcement_learning/rl_agent.py
--rw-r--r--  2.0 unx     3305 b- defN 23-Apr-18 19:23 plato/utils/reinforcement_learning/rl_server.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 19:23 plato/utils/reinforcement_learning/policies/__init__.py
--rw-r--r--  2.0 unx     5250 b- defN 23-Apr-18 19:23 plato/utils/reinforcement_learning/policies/base.py
--rw-r--r--  2.0 unx     2816 b- defN 23-Apr-18 19:23 plato/utils/reinforcement_learning/policies/ddpg.py
--rw-r--r--  2.0 unx      918 b- defN 23-Apr-18 19:23 plato/utils/reinforcement_learning/policies/registry.py
--rw-r--r--  2.0 unx    12031 b- defN 23-Apr-18 19:23 plato/utils/reinforcement_learning/policies/sac.py
--rw-r--r--  2.0 unx    19055 b- defN 23-Apr-18 19:23 plato/utils/reinforcement_learning/policies/td3.py
--rw-r--r--  2.0 unx    11357 b- defN 23-Apr-18 19:24 plato_learn-0.4.8.dist-info/LICENSE
--rw-r--r--  2.0 unx     1544 b- defN 23-Apr-18 19:24 plato_learn-0.4.8.dist-info/METADATA
--rw-r--r--  2.0 unx      150 b- defN 23-Apr-18 19:24 plato_learn-0.4.8.dist-info/WHEEL
--rw-r--r--  2.0 unx        6 b- defN 23-Apr-18 19:24 plato_learn-0.4.8.dist-info/top_level.txt
--rw-rw-r--  2.0 unx    16067 b- defN 23-Apr-18 19:24 plato_learn-0.4.8.dist-info/RECORD
-182 files, 790500 bytes uncompressed, 215129 bytes compressed:  72.8%
+Zip file size: 242017 bytes, number of entries: 183
+-rw-r--r--  2.0 unx       22 b- defN 23-Apr-26 03:58 plato/__init__.py
+-rw-r--r--  2.0 unx     1957 b- defN 23-Apr-26 03:58 plato/client.py
+-rw-r--r--  2.0 unx    13592 b- defN 23-Apr-26 03:58 plato/config.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-26 03:58 plato/algorithms/__init__.py
+-rw-r--r--  2.0 unx     1102 b- defN 23-Apr-26 03:58 plato/algorithms/base.py
+-rw-r--r--  2.0 unx     1576 b- defN 23-Apr-26 03:58 plato/algorithms/fedavg.py
+-rw-r--r--  2.0 unx     2867 b- defN 23-Apr-26 03:58 plato/algorithms/fedavg_gan.py
+-rw-r--r--  2.0 unx     5334 b- defN 23-Apr-26 03:58 plato/algorithms/fedavg_partial.py
+-rw-r--r--  2.0 unx     1476 b- defN 23-Apr-26 03:58 plato/algorithms/mistnet.py
+-rw-r--r--  2.0 unx     1445 b- defN 23-Apr-26 03:58 plato/algorithms/registry.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-26 03:58 plato/callbacks/__init__.py
+-rw-r--r--  2.0 unx     1654 b- defN 23-Apr-26 03:58 plato/callbacks/client.py
+-rw-r--r--  2.0 unx     2639 b- defN 23-Apr-26 03:58 plato/callbacks/handler.py
+-rw-r--r--  2.0 unx     4244 b- defN 23-Apr-26 03:58 plato/callbacks/server.py
+-rw-r--r--  2.0 unx     3804 b- defN 23-Apr-26 03:58 plato/callbacks/trainer.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-26 03:58 plato/clients/__init__.py
+-rw-r--r--  2.0 unx    16728 b- defN 23-Apr-26 03:58 plato/clients/base.py
+-rw-r--r--  2.0 unx     3455 b- defN 23-Apr-26 03:58 plato/clients/edge.py
+-rw-r--r--  2.0 unx     1491 b- defN 23-Apr-26 03:58 plato/clients/mistnet.py
+-rw-r--r--  2.0 unx     1067 b- defN 23-Apr-26 03:58 plato/clients/registry.py
+-rw-r--r--  2.0 unx     8173 b- defN 23-Apr-26 03:58 plato/clients/simple.py
+-rw-r--r--  2.0 unx    13650 b- defN 23-Apr-26 03:58 plato/clients/simple_personalized.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-26 03:58 plato/datasources/__init__.py
+-rw-r--r--  2.0 unx     4090 b- defN 23-Apr-26 03:58 plato/datasources/base.py
+-rw-r--r--  2.0 unx     4563 b- defN 23-Apr-26 03:58 plato/datasources/celeba.py
+-rw-r--r--  2.0 unx     1716 b- defN 23-Apr-26 03:58 plato/datasources/cifar10.py
+-rw-r--r--  2.0 unx     1720 b- defN 23-Apr-26 03:58 plato/datasources/cifar100.py
+-rw-r--r--  2.0 unx     1723 b- defN 23-Apr-26 03:58 plato/datasources/cinic10.py
+-rw-r--r--  2.0 unx     4507 b- defN 23-Apr-26 03:58 plato/datasources/coco.py
+-rw-r--r--  2.0 unx     1737 b- defN 23-Apr-26 03:58 plato/datasources/emnist.py
+-rw-r--r--  2.0 unx     1073 b- defN 23-Apr-26 03:58 plato/datasources/fashion_mnist.py
+-rw-r--r--  2.0 unx      612 b- defN 23-Apr-26 03:58 plato/datasources/feature.py
+-rw-r--r--  2.0 unx      361 b- defN 23-Apr-26 03:58 plato/datasources/feature_dataset.py
+-rw-r--r--  2.0 unx     4673 b- defN 23-Apr-26 03:58 plato/datasources/femnist.py
+-rw-r--r--  2.0 unx    13862 b- defN 23-Apr-26 03:58 plato/datasources/flickr30k_entities.py
+-rw-r--r--  2.0 unx    16869 b- defN 23-Apr-26 03:58 plato/datasources/gym.py
+-rw-r--r--  2.0 unx     5572 b- defN 23-Apr-26 03:58 plato/datasources/huggingface.py
+-rw-r--r--  2.0 unx    23377 b- defN 23-Apr-26 03:58 plato/datasources/kinetics.py
+-rw-r--r--  2.0 unx     1032 b- defN 23-Apr-26 03:58 plato/datasources/mnist.py
+-rw-r--r--  2.0 unx    13106 b- defN 23-Apr-26 03:58 plato/datasources/multimodal_base.py
+-rw-r--r--  2.0 unx     1482 b- defN 23-Apr-26 03:58 plato/datasources/pascal_voc.py
+-rw-r--r--  2.0 unx     3022 b- defN 23-Apr-26 03:58 plato/datasources/purchase.py
+-rw-r--r--  2.0 unx     4224 b- defN 23-Apr-26 03:58 plato/datasources/qoenflx.py
+-rw-r--r--  2.0 unx    11322 b- defN 23-Apr-26 03:58 plato/datasources/referitgame.py
+-rw-r--r--  2.0 unx     3757 b- defN 23-Apr-26 03:58 plato/datasources/registry.py
+-rw-r--r--  2.0 unx     3032 b- defN 23-Apr-26 03:58 plato/datasources/stl10.py
+-rw-r--r--  2.0 unx     3189 b- defN 23-Apr-26 03:58 plato/datasources/texas.py
+-rw-r--r--  2.0 unx     1943 b- defN 23-Apr-26 03:58 plato/datasources/tiny_imagenet.py
+-rw-r--r--  2.0 unx     5189 b- defN 23-Apr-26 03:58 plato/datasources/yolo.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-26 03:58 plato/datasources/datalib/__init__.py
+-rw-r--r--  2.0 unx     4718 b- defN 23-Apr-26 03:58 plato/datasources/datalib/audio_extraction_tools.py
+-rw-r--r--  2.0 unx     3816 b- defN 23-Apr-26 03:58 plato/datasources/datalib/data_utils.py
+-rw-r--r--  2.0 unx    12779 b- defN 23-Apr-26 03:58 plato/datasources/datalib/flickr30kE_utils.py
+-rw-r--r--  2.0 unx     8170 b- defN 23-Apr-26 03:58 plato/datasources/datalib/frames_extraction_tools.py
+-rw-r--r--  2.0 unx     6699 b- defN 23-Apr-26 03:58 plato/datasources/datalib/modality_data_anntation_tools.py
+-rw-r--r--  2.0 unx     2253 b- defN 23-Apr-26 03:58 plato/datasources/datalib/modality_extraction_base.py
+-rw-r--r--  2.0 unx     7717 b- defN 23-Apr-26 03:58 plato/datasources/datalib/parse_datasets.py
+-rw-r--r--  2.0 unx     3248 b- defN 23-Apr-26 03:58 plato/datasources/datalib/tiny_data_tools.py
+-rw-r--r--  2.0 unx     2262 b- defN 23-Apr-26 03:58 plato/datasources/datalib/video_transform.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-26 03:58 plato/datasources/datalib/gym_utils/__init__.py
+-rw-r--r--  2.0 unx     6056 b- defN 23-Apr-26 03:58 plato/datasources/datalib/gym_utils/gym_trim.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-26 03:58 plato/datasources/datalib/refer_utils/__init__.py
+-rw-r--r--  2.0 unx     9358 b- defN 23-Apr-26 03:58 plato/datasources/datalib/refer_utils/referitgame_utils.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-26 03:58 plato/models/__init__.py
+-rw-r--r--  2.0 unx     3528 b- defN 23-Apr-26 03:58 plato/models/cnn_encoder.py
+-rw-r--r--  2.0 unx     3396 b- defN 23-Apr-26 03:58 plato/models/dcgan.py
+-rw-r--r--  2.0 unx     9498 b- defN 23-Apr-26 03:58 plato/models/general_multilayer.py
+-rw-r--r--  2.0 unx      749 b- defN 23-Apr-26 03:58 plato/models/huggingface.py
+-rw-r--r--  2.0 unx     3644 b- defN 23-Apr-26 03:58 plato/models/lenet5.py
+-rw-r--r--  2.0 unx     2552 b- defN 23-Apr-26 03:58 plato/models/multilayer.py
+-rw-r--r--  2.0 unx     2497 b- defN 23-Apr-26 03:58 plato/models/registry.py
+-rw-r--r--  2.0 unx     6442 b- defN 23-Apr-26 03:58 plato/models/resnet.py
+-rw-r--r--  2.0 unx      445 b- defN 23-Apr-26 03:58 plato/models/torch_hub.py
+-rw-r--r--  2.0 unx     2981 b- defN 23-Apr-26 03:58 plato/models/vgg.py
+-rw-r--r--  2.0 unx     5151 b- defN 23-Apr-26 03:58 plato/models/vit.py
+-rw-r--r--  2.0 unx     1849 b- defN 23-Apr-26 03:58 plato/models/yolov5.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-26 03:58 plato/models/multimodal/__init__.py
+-rw-r--r--  2.0 unx     3020 b- defN 23-Apr-26 03:58 plato/models/multimodal/base_net.py
+-rw-r--r--  2.0 unx     5055 b- defN 23-Apr-26 03:58 plato/models/multimodal/blending.py
+-rw-r--r--  2.0 unx     2414 b- defN 23-Apr-26 03:58 plato/models/multimodal/fc_net.py
+-rw-r--r--  2.0 unx     3183 b- defN 23-Apr-26 03:58 plato/models/multimodal/fusion_net.py
+-rw-r--r--  2.0 unx     6560 b- defN 23-Apr-26 03:58 plato/models/multimodal/multimodal_module.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-26 03:58 plato/processors/__init__.py
+-rw-r--r--  2.0 unx      888 b- defN 23-Apr-26 03:58 plato/processors/base.py
+-rw-r--r--  2.0 unx     1240 b- defN 23-Apr-26 03:58 plato/processors/compress.py
+-rw-r--r--  2.0 unx     1564 b- defN 23-Apr-26 03:58 plato/processors/decompress.py
+-rw-r--r--  2.0 unx     1320 b- defN 23-Apr-26 03:58 plato/processors/feature.py
+-rw-r--r--  2.0 unx     1127 b- defN 23-Apr-26 03:58 plato/processors/feature_additive_noise.py
+-rw-r--r--  2.0 unx      878 b- defN 23-Apr-26 03:58 plato/processors/feature_dequantize.py
+-rw-r--r--  2.0 unx      619 b- defN 23-Apr-26 03:58 plato/processors/feature_gaussian.py
+-rw-r--r--  2.0 unx      493 b- defN 23-Apr-26 03:58 plato/processors/feature_laplace.py
+-rw-r--r--  2.0 unx     1022 b- defN 23-Apr-26 03:58 plato/processors/feature_quantize.py
+-rw-r--r--  2.0 unx     1411 b- defN 23-Apr-26 03:58 plato/processors/feature_randomized_response.py
+-rw-r--r--  2.0 unx     1006 b- defN 23-Apr-26 03:58 plato/processors/feature_unbatch.py
+-rw-r--r--  2.0 unx     1115 b- defN 23-Apr-26 03:58 plato/processors/inbound_feature_tensors.py
+-rw-r--r--  2.0 unx     1626 b- defN 23-Apr-26 03:58 plato/processors/model.py
+-rw-r--r--  2.0 unx      860 b- defN 23-Apr-26 03:58 plato/processors/model_compress.py
+-rw-r--r--  2.0 unx      853 b- defN 23-Apr-26 03:58 plato/processors/model_decompress.py
+-rw-r--r--  2.0 unx     1071 b- defN 23-Apr-26 03:58 plato/processors/model_decrypt.py
+-rw-r--r--  2.0 unx      427 b- defN 23-Apr-26 03:58 plato/processors/model_deepcopy.py
+-rw-r--r--  2.0 unx      398 b- defN 23-Apr-26 03:58 plato/processors/model_dequantize.py
+-rw-r--r--  2.0 unx     1950 b- defN 23-Apr-26 03:58 plato/processors/model_dequantize_qsgd.py
+-rw-r--r--  2.0 unx     1088 b- defN 23-Apr-26 03:58 plato/processors/model_encrypt.py
+-rw-r--r--  2.0 unx      420 b- defN 23-Apr-26 03:58 plato/processors/model_quantize.py
+-rw-r--r--  2.0 unx     2922 b- defN 23-Apr-26 03:58 plato/processors/model_quantize_qsgd.py
+-rw-r--r--  2.0 unx      939 b- defN 23-Apr-26 03:58 plato/processors/model_randomized_response.py
+-rw-r--r--  2.0 unx      994 b- defN 23-Apr-26 03:58 plato/processors/outbound_feature_ndarrays.py
+-rw-r--r--  2.0 unx      675 b- defN 23-Apr-26 03:58 plato/processors/pipeline.py
+-rw-r--r--  2.0 unx     4267 b- defN 23-Apr-26 03:58 plato/processors/registry.py
+-rw-r--r--  2.0 unx     1534 b- defN 23-Apr-26 03:58 plato/processors/send_mask.py
+-rw-r--r--  2.0 unx     2066 b- defN 23-Apr-26 03:58 plato/processors/structured_pruning.py
+-rw-r--r--  2.0 unx     1928 b- defN 23-Apr-26 03:58 plato/processors/unstructured_pruning.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-26 03:58 plato/samplers/__init__.py
+-rw-r--r--  2.0 unx     1540 b- defN 23-Apr-26 03:58 plato/samplers/all_inclusive.py
+-rw-r--r--  2.0 unx      906 b- defN 23-Apr-26 03:58 plato/samplers/base.py
+-rw-r--r--  2.0 unx     2703 b- defN 23-Apr-26 03:58 plato/samplers/dirichlet.py
+-rw-r--r--  2.0 unx     5188 b- defN 23-Apr-26 03:58 plato/samplers/distribution_noniid.py
+-rw-r--r--  2.0 unx     1738 b- defN 23-Apr-26 03:58 plato/samplers/iid.py
+-rw-r--r--  2.0 unx     4613 b- defN 23-Apr-26 03:58 plato/samplers/label_quantity_noniid.py
+-rw-r--r--  2.0 unx     1722 b- defN 23-Apr-26 03:58 plato/samplers/mixed.py
+-rw-r--r--  2.0 unx     5276 b- defN 23-Apr-26 03:58 plato/samplers/mixed_label_quantity_noniid.py
+-rw-r--r--  2.0 unx     1246 b- defN 23-Apr-26 03:58 plato/samplers/modality_iid.py
+-rw-r--r--  2.0 unx     1715 b- defN 23-Apr-26 03:58 plato/samplers/modality_quantity_noniid.py
+-rw-r--r--  2.0 unx     3461 b- defN 23-Apr-26 03:58 plato/samplers/orthogonal.py
+-rw-r--r--  2.0 unx     2631 b- defN 23-Apr-26 03:58 plato/samplers/registry.py
+-rw-r--r--  2.0 unx     4124 b- defN 23-Apr-26 03:58 plato/samplers/sample_quantity_noniid.py
+-rw-r--r--  2.0 unx     7650 b- defN 23-Apr-26 03:58 plato/samplers/sampler_utils.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-26 03:58 plato/servers/__init__.py
+-rw-r--r--  2.0 unx    56772 b- defN 23-Apr-26 03:58 plato/servers/base.py
+-rw-r--r--  2.0 unx    10236 b- defN 23-Apr-26 03:58 plato/servers/fedavg.py
+-rw-r--r--  2.0 unx    13169 b- defN 23-Apr-26 03:58 plato/servers/fedavg_cs.py
+-rw-r--r--  2.0 unx     2691 b- defN 23-Apr-26 03:58 plato/servers/fedavg_gan.py
+-rw-r--r--  2.0 unx     3952 b- defN 23-Apr-26 03:58 plato/servers/fedavg_he.py
+-rw-r--r--  2.0 unx    16301 b- defN 23-Apr-26 03:58 plato/servers/fedavg_personalized.py
+-rw-r--r--  2.0 unx     2279 b- defN 23-Apr-26 03:58 plato/servers/mistnet.py
+-rw-r--r--  2.0 unx     1386 b- defN 23-Apr-26 03:58 plato/servers/registry.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-26 03:58 plato/trainers/__init__.py
+-rw-r--r--  2.0 unx     3128 b- defN 23-Apr-26 03:58 plato/trainers/base.py
+-rw-r--r--  2.0 unx    22736 b- defN 23-Apr-26 03:58 plato/trainers/basic.py
+-rw-r--r--  2.0 unx    26725 b- defN 23-Apr-26 03:58 plato/trainers/basic_personalized.py
+-rw-r--r--  2.0 unx     6789 b- defN 23-Apr-26 03:58 plato/trainers/diff_privacy.py
+-rw-r--r--  2.0 unx    12763 b- defN 23-Apr-26 03:58 plato/trainers/gan.py
+-rw-r--r--  2.0 unx     4901 b- defN 23-Apr-26 03:58 plato/trainers/huggingface.py
+-rw-r--r--  2.0 unx     1463 b- defN 23-Apr-26 03:58 plato/trainers/loss_criterion.py
+-rw-r--r--  2.0 unx     8685 b- defN 23-Apr-26 03:58 plato/trainers/lr_schedulers.py
+-rw-r--r--  2.0 unx     1329 b- defN 23-Apr-26 03:58 plato/trainers/optimizers.py
+-rw-r--r--  2.0 unx     2705 b- defN 23-Apr-26 03:58 plato/trainers/pascal_voc.py
+-rw-r--r--  2.0 unx     1640 b- defN 23-Apr-26 03:58 plato/trainers/registry.py
+-rw-r--r--  2.0 unx     2828 b- defN 23-Apr-26 03:58 plato/trainers/tracking.py
+-rw-r--r--  2.0 unx    16487 b- defN 23-Apr-26 03:58 plato/trainers/yolov5.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-26 03:58 plato/trainers/mindspore/__init__.py
+-rw-r--r--  2.0 unx     4481 b- defN 23-Apr-26 03:58 plato/trainers/mindspore/basic.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-26 03:58 plato/utils/__init__.py
+-rw-r--r--  2.0 unx     9326 b- defN 23-Apr-26 03:58 plato/utils/checkpoint_operator.py
+-rw-r--r--  2.0 unx      879 b- defN 23-Apr-26 03:58 plato/utils/count_parameters.py
+-rw-r--r--  2.0 unx      843 b- defN 23-Apr-26 03:58 plato/utils/csv_processor.py
+-rw-r--r--  2.0 unx     5300 b- defN 23-Apr-26 03:58 plato/utils/data_loaders.py
+-rw-r--r--  2.0 unx      590 b- defN 23-Apr-26 03:58 plato/utils/decorators.py
+-rw-r--r--  2.0 unx     1770 b- defN 23-Apr-26 03:58 plato/utils/filename_formatter.py
+-rw-r--r--  2.0 unx      716 b- defN 23-Apr-26 03:58 plato/utils/fonts.py
+-rw-r--r--  2.0 unx     5873 b- defN 23-Apr-26 03:58 plato/utils/homo_enc.py
+-rw-r--r--  2.0 unx     5173 b- defN 23-Apr-26 03:58 plato/utils/rl_env.py
+-rw-r--r--  2.0 unx     5550 b- defN 23-Apr-26 03:58 plato/utils/s3.py
+-rw-r--r--  2.0 unx     1355 b- defN 23-Apr-26 03:58 plato/utils/unary_encoding.py
+-rw-r--r--  2.0 unx    12179 b- defN 23-Apr-26 03:58 plato/utils/visual_augmentations.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-26 03:58 plato/utils/lib_mia/__init__.py
+-rw-r--r--  2.0 unx     4308 b- defN 23-Apr-26 03:58 plato/utils/lib_mia/mia.py
+-rw-r--r--  2.0 unx     1183 b- defN 23-Apr-26 03:58 plato/utils/lib_mia/mia_client.py
+-rw-r--r--  2.0 unx     3617 b- defN 23-Apr-26 03:58 plato/utils/lib_mia/mia_server.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-26 03:58 plato/utils/reinforcement_learning/__init__.py
+-rw-r--r--  2.0 unx     4487 b- defN 23-Apr-26 03:58 plato/utils/reinforcement_learning/rl_agent.py
+-rw-r--r--  2.0 unx     3305 b- defN 23-Apr-26 03:58 plato/utils/reinforcement_learning/rl_server.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-26 03:58 plato/utils/reinforcement_learning/policies/__init__.py
+-rw-r--r--  2.0 unx     5250 b- defN 23-Apr-26 03:58 plato/utils/reinforcement_learning/policies/base.py
+-rw-r--r--  2.0 unx     2816 b- defN 23-Apr-26 03:58 plato/utils/reinforcement_learning/policies/ddpg.py
+-rw-r--r--  2.0 unx      918 b- defN 23-Apr-26 03:58 plato/utils/reinforcement_learning/policies/registry.py
+-rw-r--r--  2.0 unx    12031 b- defN 23-Apr-26 03:58 plato/utils/reinforcement_learning/policies/sac.py
+-rw-r--r--  2.0 unx    19055 b- defN 23-Apr-26 03:58 plato/utils/reinforcement_learning/policies/td3.py
+-rw-r--r--  2.0 unx    11357 b- defN 23-Apr-26 03:59 plato_learn-0.4.9.dist-info/LICENSE
+-rw-r--r--  2.0 unx     1544 b- defN 23-Apr-26 03:59 plato_learn-0.4.9.dist-info/METADATA
+-rw-r--r--  2.0 unx      150 b- defN 23-Apr-26 03:59 plato_learn-0.4.9.dist-info/WHEEL
+-rw-r--r--  2.0 unx        6 b- defN 23-Apr-26 03:59 plato_learn-0.4.9.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx    16150 b- defN 23-Apr-26 03:59 plato_learn-0.4.9.dist-info/RECORD
+183 files, 794460 bytes uncompressed, 216419 bytes compressed:  72.8%
```

## zipnote {}

```diff
@@ -129,14 +129,17 @@
 
 Filename: plato/datasources/referitgame.py
 Comment: 
 
 Filename: plato/datasources/registry.py
 Comment: 
 
+Filename: plato/datasources/stl10.py
+Comment: 
+
 Filename: plato/datasources/texas.py
 Comment: 
 
 Filename: plato/datasources/tiny_imagenet.py
 Comment: 
 
 Filename: plato/datasources/yolo.py
@@ -525,23 +528,23 @@
 
 Filename: plato/utils/reinforcement_learning/policies/sac.py
 Comment: 
 
 Filename: plato/utils/reinforcement_learning/policies/td3.py
 Comment: 
 
-Filename: plato_learn-0.4.8.dist-info/LICENSE
+Filename: plato_learn-0.4.9.dist-info/LICENSE
 Comment: 
 
-Filename: plato_learn-0.4.8.dist-info/METADATA
+Filename: plato_learn-0.4.9.dist-info/METADATA
 Comment: 
 
-Filename: plato_learn-0.4.8.dist-info/WHEEL
+Filename: plato_learn-0.4.9.dist-info/WHEEL
 Comment: 
 
-Filename: plato_learn-0.4.8.dist-info/top_level.txt
+Filename: plato_learn-0.4.9.dist-info/top_level.txt
 Comment: 
 
-Filename: plato_learn-0.4.8.dist-info/RECORD
+Filename: plato_learn-0.4.9.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## plato/__init__.py

```diff
@@ -1 +1 @@
-__version__ = "0.4.8"
+__version__ = "0.4.9"
```

## plato/algorithms/fedavg_partial.py

```diff
@@ -3,50 +3,31 @@
 
 Utilization condition:
     In some scenarios, even given one defined model, the users want to utilize the partial
     sub-modules as the global model in federated learning. Thus, solely these desired
     sub-modules will be extracted and aggregated during the learning process.
     Then, noticing that the names of parameters in one sub-module hold consistent names,
     we propose this piece of code to support the aforementioned feature by setting the
-    hyper-parameter 'global_submodules_name' in the config file.
+    hyper-parameter `global_modules_name` in the config file.
 
-The format of this hyper-parameter should be:
-{submodule1_prefix}__{submodule2_prefix}__{submodule3_prefix}__...
+The format of this hyper-parameter should be a list containing the name of desired layers.
 
-names for different submodules are separated by two consecutive underscores.
 
+For example, when utilizing the "LeNet5" as the target model, the `global_modules_name` can
+be defined as:
 
-For example
- A. Given the defined whole model: encoder + head, the hyper-parameter in the config
-    file 'global_submodules_name' under the 'trainer' can be set to:
-    - whole     : utilizing the whole model as the global model
-    - encoder   : utilizing the encoder as the global model
-    - head      : utilizing the head as the global model
-
-    Demo:
-
-        trainer:
-            global_submodules_name: encoder
-
-
- B. Given the defined whole model: encoder1 + encoder2 + encoder3 + head1 + head2,
-    the hyper-parameter in the config file 'global_submodules_name' under the 'trainer'
-    can be set to
-    - whole                 : utilizing the whole model as the global model
-    - encoder1__encoder2    : utilizing solely encoder1 and encoder2 as the global model
-    - encoder2__head1       : utilizing solely encoder2 and head as the global model
-    - encoder2__head1__head2: utilizing solely encoder2, head1 and head2 as the global model
-
-    Demo:
-
-        trainer:
-            global_submodules_name: encoder1__encoder2
+    global_modules_name:
+        - conv1
+        - conv2
 
+thus, the conv1 and conv2 layers will be used as the global model.
 """
 
+import os
+import string
 import logging
 from typing import List, Optional
 from collections import OrderedDict
 
 import torch
 
 from plato.algorithms import fedavg
@@ -62,53 +43,57 @@
 
         # in this algorithm, the sub-module's name that is used as the global model
         # shared among clients should be set.
         # by default, the whole model will be used as the global model
         # i.e., whole_model_name = "whole"
         self.whole_model_name = "whole"
 
-        # the separator used to combine different names into one
-        # string.
-        # by default, two consecutive underscores are utilized.
-        self.separator = "__"
+    def get_algorithm_holder(self):
+        """Get who holds the defined algorithm."""
+        return (
+            f"server #{os.getpid()}"
+            if self.client_id == 0
+            else f"Client #{self.client_id}"
+        )
 
     def extract_weights(
         self,
         model: Optional[torch.nn.Module] = None,
-        submodules_name: Optional[List[str]] = None,
+        modules_name: Optional[List[str]] = None,
     ):
-        """Extract weights from submodules of the model.
+        """Extract weights from modules of the model.
         By default, weights of the whole model will be extracted."""
-
-        submodules_name = (
-            submodules_name
-            if submodules_name is not None
+        model = self.model if model is None else model
+        modules_name = (
+            modules_name
+            if modules_name is not None
             else (
-                Config().trainer.global_submodules_name.split(self.separator)
-                if hasattr(Config().trainer, "global_submodules_name")
-                else self.whole_model_name.split(self.separator)
+                Config().trainer.global_modules_name
+                if hasattr(Config().trainer, "global_modules_name")
+                else None
             )
         )
-
-        logging.info("Extracting parameters with names %s.", submodules_name)
-
-        model = self.model if model is None else model
-
-        if self.whole_model_name in submodules_name:
+        # when no modules are required,
+        # return the whole model
+        if modules_name is None:
             return model.cpu().state_dict()
+        else:
 
-        full_weights = model.cpu().state_dict()
-        extracted_weights = OrderedDict(
-            [
-                (name, param)
-                for name, param in full_weights.items()
-                if any([param_name in name for param_name in submodules_name])
-            ]
-        )
-        return extracted_weights
+            logging.info(
+                "[%s] Extracting parameters with names %s.",
+                self.get_algorithm_holder(),
+                modules_name,
+            )
+            return OrderedDict(
+                [
+                    (name, param)
+                    for name, param in model.cpu().state_dict().items()
+                    if any([param_name in name for param_name in modules_name])
+                ]
+            )
 
     def is_consistent_weights(self, weights_param_name):
         """Whether the 'weights' holds the parameters' name the same as the self.model."""
 
         model_params_name = self.model.state_dict().keys()
 
         search_func = lambda x, y: [x_i for x_i in x if x_i not in y]
@@ -126,27 +111,39 @@
         weights: dict,
         strict: bool = False,
     ):
         """Load the model weights passed in as a parameter."""
         self.model.load_state_dict(weights, strict=strict)
 
     @staticmethod
-    def extract_submodules_name(parameters_name):
-        """Extracting submodules name from given parameters' names."""
+    def extract_modules_name(parameters_name):
+        """Extracting modules name from given parameters' names."""
 
         extracted_names = []
-
+        # Remove punctuation and split the strings into words and sub-words
+        translator = str.maketrans("", "", string.punctuation)
+        combined_subnames = [
+            [subname.translate(translator).lower() for subname in word.split(".")]
+            for word in parameters_name
+        ]
+
+        # from which subname, the modules name show difference
+        diff_level = 0
+        # Find the point where the strings begin to differ in content
+        for level, subnames in enumerate(zip(*combined_subnames)):
+            if len(set(subnames)) > 1:
+                diff_level = level
+                break
+        # add 1 to begin from 0
+        diff_level += 1
         # the para name is presented as encoder.xxx.xxx
         # that is combined by the key_word "."
         # we aim to extract the encoder
         split_str = "."
         for para_name in parameters_name:
             splitted_names = para_name.split(split_str)
-            core_name = splitted_names[0]
-            # add the obtained prefix to the list, if
-            #   - empty list
-            #   - a new prefix
-            # add to the empty list directly
-            if core_name not in extracted_names:
-                extracted_names.append(core_name)
+            core_names = splitted_names[:diff_level]
+            module_name = f"{split_str}".join(core_names)
+            if module_name not in extracted_names:
+                extracted_names.append(module_name)
 
         return extracted_names
```

## plato/clients/simple_personalized.py

```diff
@@ -9,15 +9,15 @@
 import logging
 from types import SimpleNamespace
 
 from plato.clients import simple
 from plato.config import Config
 from plato.models import registry as models_registry
 from plato.utils import fonts
-from plato.utils.filename_formatter import get_format_name
+from plato.utils.filename_formatter import NameFormatter
 
 
 class Client(simple.Client):
     """A basic personalized federated learning client."""
 
     def __init__(
         self,
@@ -82,15 +82,15 @@
         elif (
             self.personalized_model is None
             and self.custom_personalized_model is not None
         ):
             self.personalized_model = self.custom_personalized_model()
 
         logging.info(
-            "Client[%d] defines the personalized model: %s",
+            "[Client #%d] defines the personalized model: %s",
             self.client_id,
             pers_model_name,
         )
 
         # assign the client's personalized model to its trainer
         # we need to know that in Plato, the personalized model here
         # makes no sense and it is only initialized to hold the model
@@ -114,39 +114,40 @@
 
     def persist_initial_personalized_model(self):
         """Persist the initial model of one client."""
         pers_model_name = Config().trainer.personalized_model_name
         # save the defined personalized model as the initial one
         checkpoint_dir_path = self.trainer.get_checkpoint_dir_path()
 
-        filename = get_format_name(
+        filename = NameFormatter.get_format_name(
             model_name=pers_model_name,
             client_id=self.client_id,
             round_n=0,
             epoch_n=None,
             run_id=None,
             prefix="personalized",
             ext="pth",
         )
         checkpoint_file_path = os.path.join(checkpoint_dir_path, filename)
         # if the personalized model for current client does
         # not exist - this client is selected the first time
         if not os.path.exists(checkpoint_file_path):
             logging.info(
                 fonts.colourize(
-                    "First-time Selection of Client[%d] for personalization.",
+                    "First-time Selection of [Client #%d] for personalization.",
                     colour="blue",
                 ),
                 self.client_id,
             )
             logging.info(
                 fonts.colourize(
-                    "Client[%d]. Creating its unique parameters by resetting weights.",
+                    "[Client #%d] Creating its unique personalized parameters by resetting weights.",
                     colour="blue",
-                )
+                ),
+                self.client_id,
             )
             # reset the personalized model for this client
             # thus, different clients have different init parameters
             self.personalized_model.apply(self.trainer.reset_weight)
             self.trainer.save_personalized_model(
                 filename=filename,
                 location=checkpoint_dir_path,
@@ -168,15 +169,15 @@
         By default,
         1. the personalized model will be loaded from the initialized one.
         2. load the latest persisted personalized model.
         """
         personalized_model_name = Config().trainer.personalized_model_name
         logging.info(
             fonts.colourize(
-                "[Client #%d] loading its personalized model [%s].", colour="blue"
+                "[Client #%d] Loading its personalized model named %s.", colour="blue"
             ),
             self.client_id,
             personalized_model_name,
         )
         # when `persist_personalized_model` is set to be True, it means
         # that each client want to load its latest trained personalzied
         # model instead of using the initial one.
@@ -189,50 +190,51 @@
             # the initial personalized model saved by `self.persist_initial_model`
             # will be loaded. Otherwise, the latest trained personalized model
             # will be loaded
             desired_round = self.current_round - 1
 
             logging.info(
                 fonts.colourize(
-                    "[Client #%d] loads latest personalized model.", colour="blue"
+                    "[Client #%d] Loading latest personalized model.", colour="blue"
                 ),
                 self.client_id,
             )
         else:
             # client does not want to use its trained personalzied model
             # thus, load the initial personalized model saved by
             # `self.persist_initial_personalized_model`
             # i.e., rollback
             desired_round = 0
             logging.info(
                 fonts.colourize(
-                    "[Client #%d] loads initial personalized model.", colour="blue"
+                    "[Client #%d] Loading initial personalized model.", colour="blue"
                 ),
                 self.client_id,
             )
 
         checkpoint_dir_path = self.trainer.get_checkpoint_dir_path()
-        self.trainer.rollback_model(
+        loaded_status = self.trainer.rollback_model(
             model_name=personalized_model_name,
             modelfile_prefix="personalized",
             rollback_round=desired_round,
             location=checkpoint_dir_path,
         )
+        return loaded_status
 
     def _load_payload(self, server_payload) -> None:
         """Load the server model onto this client.
 
         By default, each client will
         1. load the received global model to its trainer's model
         2. load its personalized model locally.
         """
         logging.info(
-            "[Client #%d] Received the model [%s].",
+            "[Client #%d] Received the payload containing modules: %s.",
             self.client_id,
-            Config().trainer.model_name,
+            self.algorithm.extract_modules_name(list(server_payload.keys())),
         )
         # load the model
         self.algorithm.load_weights(server_payload)
 
         if self.is_personalized_learn() and self.personalized_model is not None:
             # This operation is important to the personalized FL
             # under Plato
```

## plato/datasources/registry.py

```diff
@@ -37,14 +37,15 @@
         huggingface,
         pascal_voc,
         tiny_imagenet,
         femnist,
         feature,
         qoenflx,
         celeba,
+        stl10
     )
 
     registered_datasources = {
         "MNIST": mnist,
         "FashionMNIST": fashion_mnist,
         "EMNIST": emnist,
         "CIFAR10": cifar10,
@@ -54,14 +55,15 @@
         "Texas": texas,
         "HuggingFace": huggingface,
         "PASCAL_VOC": pascal_voc,
         "TinyImageNet": tiny_imagenet,
         "Feature": feature,
         "QoENFLX": qoenflx,
         "CelebA": celeba,
+        "STL10": stl10
     }
 
     registered_partitioned_datasources = {"FEMNIST": femnist}
 
 
 def get(client_id: int = 0, **kwargs):
     """Get the data source with the provided name."""
```

## plato/models/huggingface.py

 * *Ordering differences only*

```diff
@@ -20,8 +20,8 @@
 
         config = AutoConfig.from_pretrained(model_name, **config_kwargs)
 
         return AutoModelForCausalLM.from_pretrained(
             model_name,
             config=config,
             cache_dir=Config().params["model_path"] + "/huggingface",
-        )
+        )
```

## plato/samplers/distribution_noniid.py

```diff
@@ -87,15 +87,15 @@
         )
 
         self.client_partition = sampler_utils.create_dirichlet_skew(
             total_size=total_data_size,
             concentration=client_quantity_concentration,
             min_partition_size=None,
             number_partitions=total_clients,
-        )[client_id]
+        )[client_id - 1]
 
         self.client_partition_size = int(total_data_size * self.client_partition)
         self.client_partition_size = max(self.client_partition_size, min_partition_size)
 
         self.client_label_proportions = sampler_utils.create_dirichlet_skew(
             total_size=len(class_list),
             concentration=label_concentration,
```

## plato/samplers/mixed.py

```diff
@@ -7,33 +7,37 @@
 from plato.config import Config
 from plato.samplers import dirichlet
 
 
 class Sampler(dirichlet.Sampler):
     """Create a data sampler for each client to use a divided partition of the dataset,
     either biased across labels according to the Dirichlet distribution, or in an iid fashion."""
+
     def __init__(self, datasource, client_id, testing):
         super().__init__(datasource, client_id, testing)
 
-        assert hasattr(Config().data, 'non_iid_clients')
+        assert hasattr(Config().data, "non_iid_clients")
         non_iid_clients = Config().data.non_iid_clients
 
         if isinstance(non_iid_clients, int):
-            # If only one client's dataset is non-iid
-            self.non_iid_clients_list = [int(non_iid_clients)]
+            # Gived the number of non-iid clients
+            self.non_iid_clients_list = [
+                x + 1 for x in range(int(non_iid_clients))
+            ]  # [int(non_iid_clients)]
         else:
+            # Gived the list of non-iid clients
             self.non_iid_clients_list = [
-                int(x.strip()) for x in non_iid_clients.split(',')
+                int(x.strip()) for x in non_iid_clients.split(",")
             ]
 
         if int(client_id) not in self.non_iid_clients_list:
             if testing:
                 target_list = datasource.get_test_set().targets
             else:
                 target_list = datasource.targets()
             class_list = datasource.classes()
-            self.sample_weights = np.array([
-                1 / len(class_list) for _ in range(len(class_list))
-            ])[target_list]
+            self.sample_weights = np.array(
+                [1 / len(class_list) for _ in range(len(class_list))]
+            )[target_list]
 
             # Different iid clients should have a different random seed for Generator
             self.random_seed = self.random_seed * int(client_id)
```

## plato/servers/base.py

```diff
@@ -20,14 +20,15 @@
 
 from plato.callbacks.handler import CallbackHandler
 from plato.callbacks.server import LogProgressCallback
 from plato.client import run
 from plato.config import Config
 from plato.utils import s3, fonts
 
+
 # pylint: disable=unused-argument, protected-access
 class ServerEvents(socketio.AsyncNamespace):
     """A custom namespace for socketio.AsyncServer."""
 
     def __init__(self, namespace, plato_server):
         super().__init__(namespace)
         self.plato_server = plato_server
@@ -673,15 +674,16 @@
         """
         while True:
             await self._periodic_task()
             await asyncio.sleep(periodic_interval)
 
     async def _periodic_task(self):
         """A periodic task that is executed from time to time, determined by
-        'server:periodic_interval' with a default value of 5 seconds, in the configuration."""
+        'server:periodic_interval' with a default value of 5 seconds, in the configuration.
+        """
         # Call the async function that defines a customized periodic task, if any
         await self.periodic_task()
 
         # If we are operating in asynchronous mode, aggregate the model updates received so far.
         if self.asynchronous_mode and not self.simulate_wall_time:
             # Is there any training clients who are currently training on models that are too
             # `stale,` as defined by the staleness threshold?
```

## plato/servers/fedavg_personalized.py

```diff
@@ -59,22 +59,20 @@
         self.do_personalization_interval = 0
         self.do_personalization_group = "participant"
 
         # these two variables are used for reminder purposes
         self.personalization_status_info = {}
         self.personalization_group_type_info = {}
 
-        # clients that have completed
-        # personalization
-        self.personalization_done_clients_pool = []
-
         # the flag denoting whether the personalization
         # has been started or terminated
         self.performing_personalization = False
-        self.personalization_terminated = False
+        # whether stop the terminate personalization
+        # afterwards
+        self.to_terminate_personalization = False
 
         self.initialize_personalization()
         self.check_hyper_parameters()
 
     def check_hyper_parameters(self):
         """Check whether hyper-parameters are set correctly."""
         loaded_config = Config()
@@ -254,18 +252,38 @@
             self.client_groups_pool["nonparticipant"] = self.nonparticipant_clients_pool
 
         if not self.client_groups_pool["total"]:
             self.client_groups_pool["total"] = self.clients_pool
 
     def perform_normal_training(self, clients_pool: List[int], clients_count: int):
         """Operations to guarantee general federated learning without personalization."""
+        # always set the performing_personalization to close
+        # personalization
+        self.performing_personalization = False
+
+        # reset `clients_per_round` to the predefined hyper-parameter
+        self.clients_per_round = Config().clients.per_round
+
+        # set the clients_pool to be participant_clients_pool
+        clients_pool = self.participant_clients_pool
+
+        # However, as we modified the membership `clients_per_round` previously,
+        # the clients_count here may be the modified `clients_per_round`.
+        # We need to convert it back to `self.clients_per_round`.
+        # For example, if the previous round performs personalization,
+        # the `clients_per_round` was modified to the size of the client group
+        # that performs personalization, making the current round should change it back.
+        clients_count = (
+            clients_count
+            if clients_count <= self.clients_per_round
+            else self.clients_per_round
+        )
 
         # by default, we run the general federated training
         # the clients pool should be participant clients
-        clients_pool = self.participant_clients_pool
         assert clients_count <= len(self.participant_clients_pool)
 
         return clients_pool, clients_count
 
     def perform_intermediate_personalization(
         self, clients_pool: List[int], clients_count: int
     ):
@@ -289,17 +307,18 @@
             # open the personalization status flag
             self.performing_personalization = True
             # set the clients pool based on which group is setup
             # to do personalization
             clients_pool = self.client_groups_pool[
                 self.do_personalization_group.lower()
             ]
-        else:
-            # close the personalization status flag
-            self.performing_personalization = False
+            # change the clients_per_round to be the whole set
+            # of clients for personalization
+            self.clients_per_round = len(clients_pool)
+            clients_count = self.clients_per_round
 
         return clients_pool, clients_count
 
     def perform_final_personalization(
         self, clients_pool: List[int], clients_count: int
     ):
         """Operations to guarantee the personalization in the final."""
@@ -314,50 +333,23 @@
 
             # set the clients pool based on which group is setup
             # to do personalization
             clients_pool = self.client_groups_pool[
                 self.do_personalization_group.lower()
             ]
 
+            # set clients for personalization
+            self.clients_per_round = len(clients_pool)
+            clients_count = self.clients_per_round
+
             # open the personalization status flag
             self.performing_personalization = True
 
-            # reach the final personalization round
-            self.current_round = Config().trainer.rounds
-
-            # the number of clients have not been visited
-            non_visited_clients_count = len(clients_pool) - len(
-                self.personalization_done_clients_pool
-            )
-            if non_visited_clients_count <= clients_count:
-                # if the non visited clients is less than the
-                # required clients per round,
-                # select all left non visited clients
-                # then personalization on all clients has
-                # been terminated
-                clients_count = non_visited_clients_count
-
-                # we must change the clients_per_round to be
-                # the number of clients_count, i.e., how many
-                # clients will be selected in this round.
-                # By doing so, the server can know how many updates
-                # to be received for aggregation.
-                self.clients_per_round = non_visited_clients_count
-
-                # close the personalization flag
-                self.personalization_terminated = True
-            else:
-                self.personalization_terminated = False
-
-            # remove the visited clients from the clients_pool
-            clients_pool = [
-                client_id
-                for client_id in clients_pool
-                if client_id not in self.personalization_done_clients_pool
-            ]
+            # to terminate the personalization afterwards
+            self.to_terminate_personalization = True
 
         return clients_pool, clients_count
 
     def before_clients_sampling(
         self, clients_pool: List[int], clients_count: int, **kwargs
     ):
         """Determine clients pool and clients count before samling clients."""
@@ -376,24 +368,14 @@
         if self.do_personalization_interval > 0:
             clients_pool, clients_count = self.perform_intermediate_personalization(
                 clients_pool, clients_count
             )
 
         return clients_pool, clients_count
 
-    def after_clients_sampling(self, selected_clients: List[int], **kwargs):
-        """Perform operations after clients sampling."""
-        # add clients who has been selected for personalization
-        # to the `personalization_done_clients_pool`
-        # thus, they will not be selected then.
-        if self.performing_personalization:
-            self.personalization_done_clients_pool += selected_clients
-        else:
-            self.personalization_done_clients_pool = []
-
     def choose_clients(self, clients_pool: List[int], clients_count: int):
         """Chooses a subset of the clients to participate in each round.
 
         In plato, this input `clients_pool` contains total clients
         id by default.
         """
         # set required clients pool when possible
@@ -404,16 +386,14 @@
         )
 
         random.setstate(self.prng_state)
 
         # Select clients randomly
         selected_clients = random.sample(clients_pool, clients_count)
 
-        self.after_clients_sampling(selected_clients)
-
         self.prng_state = random.getstate()
         if selected_clients == len(clients_pool):
             logging.info("[%s] Selected all %d clients", self, len(selected_clients))
         else:
             logging.info("[%s] Selected clients: %s", self, selected_clients)
 
         return selected_clients
@@ -441,14 +421,17 @@
         """
 
         self.save_to_checkpoint()
 
         if self.current_round >= Config().trainer.rounds:
             logging.info("Target number of training rounds reached.")
 
-            if self.do_personalization_interval >= 0 or self.personalization_terminated:
+            if (
+                self.do_personalization_interval >= 0
+                or self.to_terminate_personalization
+            ):
 
                 logging.info(
                     "%s Completed.",
                     self.personalization_status_info[self.do_personalization_interval],
                 )
                 await self._close()
```

## plato/trainers/basic_personalized.py

```diff
@@ -33,15 +33,16 @@
 import torch
 from tqdm import tqdm
 
 from plato.config import Config
 from plato.trainers import basic
 from plato.trainers import optimizers, lr_schedulers, loss_criterion, tracking
 from plato.utils import checkpoint_operator
-from plato.utils.filename_formatter import get_format_name
+from plato.utils.filename_formatter import NameFormatter
+from plato.utils import fonts
 
 warnings.simplefilter("ignore")
 
 
 class Trainer(basic.Trainer):
     # pylint:disable=too-many-public-methods
     """A basic federated learning trainer, used by both the client and the server."""
@@ -52,15 +53,18 @@
         # the client's personalized model
         # to perform the evaluation stage of the ssl methods
         # the client must assign its own personalized model
         #  to its trainer
         self.personalized_model = None
         self.personalized_model_state_dict = None
 
-        self._loss_tracker = tracking.LossTracker()
+        self.personalized_train_loader = None
+        self._personalized_loss_criterion = None
+        self.personalized_optimizer = None
+        self.personalized_lr_scheduler = None
 
     def set_client_personalized_model(self, personalized_model):
         """Setting the client's personalized model"""
         self.personalized_model = personalized_model
 
     def get_checkpoint_dir_path(self):
         """Get the checkpoint path for current client."""
@@ -96,15 +100,15 @@
     def get_personalized_lr_scheduler(self, optimizer):
         """Returns the learning rate scheduler, if needed."""
         lr_scheduler = Config().trainer.personalized_lr_scheduler
         lr_params = Config().parameters.personalized_learning_rate._asdict()
 
         return lr_schedulers.get(
             optimizer,
-            len(self.train_loader),
+            len(self.personalized_train_loader),
             lr_scheduler=lr_scheduler,
             lr_params=lr_params,
         )
 
     @staticmethod
     @torch.no_grad()
     def reset_weight(module: torch.nn.Module):
@@ -146,31 +150,34 @@
         # check the file extension
         save_prefix, save_extension = os.path.splitext(filename)
         if save_extension != desired_extenstion:
             filename = save_prefix + desired_extenstion
 
         return location, filename
 
-    def save_personalized_model(self, filename=None, location=None):
+    def save_personalized_model(self, filename=None, location=None, **kwargs):
         """Saving the model to a file."""
         # process the arguments to obtain the to save path
         to_save_dir, filename = self.process_save_path(
             filename,
             location,
             work_model_name="personalized_model_name",
             desired_extenstion=".pth",
         )
         ckpt_oper = checkpoint_operator.CheckpointsOperator(checkpoints_dir=to_save_dir)
         ckpt_oper.save_checkpoint(
             model_state_dict=self.personalized_model.state_dict(),
             checkpoints_name=[filename],
+            **kwargs,
         )
 
         logging.info(
-            "[Client #%d] Personalized Model saved to %s under %s.",
+            fonts.colourize(
+                "[Client #%d] Saved personalized model to %s under %s.", colour="blue"
+            ),
             self.client_id,
             filename,
             to_save_dir,
         )
 
     def load_personalized_model(self, filename=None, location=None):
         """Loading pre-trained model weights from a file."""
@@ -183,24 +190,27 @@
         )
         ckpt_oper = checkpoint_operator.CheckpointsOperator(checkpoints_dir=to_load_dir)
         self.personalized_model.load_state_dict(
             ckpt_oper.load_checkpoint(filename)["model"], strict=True
         )
 
         logging.info(
-            "[Client #%d] Loading a Personalized model from %s under %s.",
+            fonts.colourize(
+                "[Client #%d] Loading a Personalized model from %s under %s.",
+                colour="blue",
+            ),
             self.client_id,
             filename,
             to_load_dir,
         )
 
     def rollback_model(
         self,
         model_name=None,
-        modelfile_prefix=None,
+        modelfile_prefix="personalized",
         rollback_round=None,
         location=None,
     ):
         """Rollback the model to be the previously one.
         By default, this functon rollbacks the personalized model.
 
         """
@@ -223,26 +233,30 @@
             run_id=None,
             epoch=None,
             prefix=modelfile_prefix,
             anchor_metric="round",
             mask_words=["epoch"],
             use_latest=True,
         )
-        loaded_weights = ckpt_oper.load_checkpoint(checkpoint_name=filename)["model"]
+        rollback_status = ckpt_oper.load_checkpoint(checkpoint_name=filename)
+        loaded_weights = rollback_status["model"]
         if modelfile_prefix == "personalized":
-            self.trainer.personalized_model.load_state_dict(loaded_weights, strict=True)
+            self.personalized_model.load_state_dict(loaded_weights, strict=True)
         else:
-            self.trainer.model.load_state_dict(loaded_weights, strict=True)
+            self.model.load_state_dict(loaded_weights, strict=True)
 
         logging.info(
-            "[Client #%d] Rollbacking a model from %s under %s.",
+            "[Client #%d] Rolled back the model from %s under %s.",
             self.client_id,
             filename,
             location,
         )
+        # remove the weights for simplicity
+        del rollback_status["model"]
+        return rollback_status
 
     @staticmethod
     def save_personalized_accuracy(
         accuracy,
         current_round=None,
         epoch=None,
         accuracy_type="test_accuracy",
@@ -299,15 +313,15 @@
 
     def checkpoint_personalized_accuracy(self, accuracy, current_round, epoch, run_id):
         """Save the personaliation accuracy to the results dir."""
         result_path = Config().params["result_path"]
 
         save_location = os.path.join(result_path, "client_" + str(self.client_id))
 
-        filename = get_format_name(
+        filename = NameFormatter.get_format_name(
             client_id=self.client_id, suffix="personalized_accuracy", ext="csv"
         )
         os.makedirs(save_location, exist_ok=True)
         self.save_personalized_accuracy(
             accuracy,
             current_round=current_round,
             epoch=epoch,
@@ -330,15 +344,15 @@
         # process the arguments to obtain the to save path
         to_save_dir, filename = self.process_save_path(
             filename, location, work_model_name="model_name", desired_extenstion=".npy"
         )
         to_save_path = os.path.join(to_save_dir, filename)
         np.save(to_save_path, to_save_narray_data, allow_pickle=True)
         logging.info(
-            "[Client #%d] Saving encoded data to %s.", self.client_id, to_save_path
+            "[Client #%d] Saved encoded data to %s.", self.client_id, to_save_path
         )
 
     def checkpoint_encoded_samples(
         self,
         encoded_samples,
         encoded_labels,
         current_round,
@@ -347,15 +361,15 @@
         encoded_type="trainEncoded",
     ):
         # pylint:disable=too-many-arguments
         """Save the encoded data to the results dir."""
 
         result_path = Config().params["result_path"]
         save_location = os.path.join(result_path, "client_" + str(self.client_id))
-        save_filename = get_format_name(
+        save_filename = NameFormatter.get_format_name(
             client_id=self.client_id,
             round_n=current_round,
             epoch_n=epoch,
             run_id=run_id,
             suffix=encoded_type,
             ext="npy",
         )
@@ -363,87 +377,97 @@
         self.save_encoded_data(
             encoded_data=encoded_samples,
             data_labels=encoded_labels,
             filename=save_filename,
             location=save_location,
         )
 
-    def perform_evaluation_op(self, to_eval_data_loader, defined_model):
+    # pylint: disable=unused-argument
+    def get_personalized_data_loader(self, batch_size, dataset, sampler, **kwargs):
+        """
+        Creates an instance of the trainloader for personalization.
+
+        Arguments:
+        batch_size: the batch size.
+        dataset: the dataset.
+        sampler: the sampler for the trainloader to use.
+        """
+        return torch.utils.data.DataLoader(
+            dataset=dataset, shuffle=False, batch_size=batch_size, sampler=sampler
+        )
+
+    def perform_evaluation(self, data_loader, defined_model=None, **kwargs):
         """The operation of performing the evaluation on the testset with the defined model."""
         # Define the test phase of the eval stage
-        acc_meter = tracking.LossTracker()
+        defined_model = (
+            self.personalized_model if defined_model is None else defined_model
+        )
         defined_model.eval()
         defined_model.to(self.device)
 
         correct = 0
-        encoded_samples = []
-        loaded_labels = []
+        total = 0
 
-        acc_meter.reset()
-        for _, (examples, labels) in enumerate(to_eval_data_loader):
-            examples, labels = examples.to(self.device), labels.to(self.device)
-            with torch.no_grad():
-                preds = defined_model(examples).argmax(dim=1)
-                correct = (preds == labels).sum()
-                acc_meter.update(correct / preds.shape[0], labels.size(0))
-
-                encoded_samples.append(examples)
-                loaded_labels.append(labels)
-
-        accuracy = acc_meter.average
-
-        outputs = {
-            "accuracy": accuracy,
-            "encoded_samples": encoded_samples,
-            "loaded_labels": loaded_labels,
-        }
+        with torch.no_grad():
+            for _, (examples, labels) in enumerate(data_loader):
+                examples, labels = examples.to(self.device), labels.to(self.device)
 
-        return outputs
+                outputs = defined_model(examples)
+
+                outputs = self.process_personalized_outputs(outputs)
+
+                _, predicted = torch.max(outputs.data, 1)
+                total += labels.size(0)
+                correct += (predicted == labels).sum().item()
+
+        accuracy = correct / total
+
+        eval_outputs = {"accuracy": accuracy}
+
+        return eval_outputs
 
     def personalized_train_one_epoch(
         self,
         epoch,
         config,
-        pers_optimizer,
-        lr_schedule,
-        pers_loss_criterion,
-        train_loader,
         epoch_loss_meter,
     ):
         # pylint:disable=too-many-arguments
         """Performing one epoch of learning for the personalization."""
 
         epoch_loss_meter.reset()
         self.personalized_model.train()
         self.personalized_model.to(self.device)
         pers_epochs = config["personalized_epochs"]
 
         local_progress = tqdm(
-            train_loader, desc=f"Epoch {epoch}/{pers_epochs+1}", disable=True
+            self.personalized_train_loader,
+            desc=f"Epoch {epoch}/{pers_epochs+1}",
+            disable=True,
         )
 
         for _, (examples, labels) in enumerate(local_progress):
             examples, labels = examples.to(self.device), labels.to(self.device)
             # Clear the previous gradient
-            pers_optimizer.zero_grad()
+            self.personalized_optimizer.zero_grad()
 
             # Perfrom the training and compute the loss
             preds = self.personalized_model(examples)
-            loss = pers_loss_criterion(preds, labels)
+            loss = self._personalized_loss_criterion(preds, labels)
 
             # Perfrom the optimization
             loss.backward()
-            pers_optimizer.step()
+            self.personalized_optimizer.step()
 
             # Update the epoch loss container
             epoch_loss_meter.update(loss, labels.size(0))
 
             local_progress.set_postfix(
                 {
-                    "lr": lr_schedule,
+                    "lr": self.personalized_lr_scheduler,
                     "loss": epoch_loss_meter.loss_value,
                     "loss_avg": epoch_loss_meter.average,
                 }
             )
 
         return epoch_loss_meter
 
@@ -453,73 +477,67 @@
         trainset,
         sampler,
         **kwargs,
     ):
         # pylint:disable=too-many-locals
         """The default training loop when a custom training loop is not supplied."""
 
-        pers_epochs = config["personalized_epochs"]
-        config["current_round"] = self.current_round
+        personalized_epochs = config["personalized_epochs"]
         batch_size = config["personalized_batch_size"]
 
-        # Initialize accuracy to be returned to -1, so that the client can disconnect
-        # from the server when testing fails
-        accuracy = -1
-
-        assert "testset" in kwargs and "testset_sampler" in kwargs
         testset = kwargs["testset"]
         testset_sampler = kwargs["testset_sampler"]
-        test_loader = torch.utils.data.DataLoader(
-            testset, batch_size=batch_size, shuffle=False, sampler=testset_sampler.get()
+
+        personalized_test_loader = self.get_personalized_data_loader(
+            batch_size, testset, testset_sampler.get()
         )
 
-        self.train_loader = self.get_train_loader(batch_size, trainset, sampler)
+        self.personalized_train_run_start(config, data_loader=personalized_test_loader)
+
+        self.personalized_train_loader = self.get_personalized_data_loader(
+            batch_size, trainset, sampler
+        )
 
         # Initializing the optimizer, lr_schedule, and loss criterion
-        pers_optimizer = self.get_personalized_optimizer(self.personalized_model)
-        pers_lr_scheduler = self.get_personalized_lr_scheduler(pers_optimizer)
-        _pers_loss_criterion = self.get_personalized_loss_criterion()
-
-        self.personalized_train_run_start(
-            config,
-            data_loader=test_loader,
+        self.personalized_optimizer = self.get_personalized_optimizer(
+            self.personalized_model
+        )
+        self.personalized_lr_scheduler = self.get_personalized_lr_scheduler(
+            self.personalized_optimizer
         )
+        self._personalized_loss_criterion = self.get_personalized_loss_criterion()
 
         self.personalized_model.to(self.device)
 
         # epoch loss tracker
         epoch_loss_meter = tracking.LossTracker()
 
         # Start personalization training
         # Note:
-        #   To distanguish the eval training stage with the
-        # previous ssl's training stage. We utilize the progress bar
-        # to demonstrate the training progress details.
+        #   To distanguish the normal training process,
+        #   we utilize the progress bar to demonstrate the
+        #   personalized training process.
         show_str = f"[Client #{self.client_id}] Personalization"
-        global_progress = tqdm(range(1, pers_epochs + 1), desc=show_str)
+        global_progress = tqdm(range(1, personalized_epochs + 1), desc=show_str)
 
         for epoch in global_progress:
             self.personalized_train_epoch_start(config)
 
             epoch_loss_meter = self.personalized_train_one_epoch(
                 epoch=epoch,
                 config=config,
-                pers_optimizer=pers_optimizer,
-                lr_schedule=pers_lr_scheduler,
-                pers_loss_criterion=_pers_loss_criterion,
-                train_loader=self.train_loader,
                 epoch_loss_meter=epoch_loss_meter,
             )
 
-            pers_lr_scheduler.step()
+            self.personalized_lr_scheduler.step()
 
             eval_outputs = self.personalized_train_epoch_end(
                 epoch=epoch,
                 config=config,
-                data_loader=test_loader,
+                data_loader=personalized_test_loader,
                 loss=epoch_loss_meter.average,
             )
 
         # get the accuracy of the client
         accuracy = eval_outputs["accuracy"]
         self.personalized_train_run_end(config)
 
@@ -527,15 +545,15 @@
         # to the model dir of this client
         if "max_concurrency" in config:
 
             current_round = self.current_round
 
             personalized_model_name = config["personalized_model_name"]
             save_location = self.get_checkpoint_dir_path()
-            filename = get_format_name(
+            filename = NameFormatter.get_format_name(
                 client_id=self.client_id,
                 model_name=personalized_model_name,
                 round_n=current_round,
                 run_id=None,
                 prefix="personalized",
                 ext="pth",
             )
@@ -546,15 +564,14 @@
 
             # save the accuracy directly for latter usage
             # in the eval_test(...)
             model_name = config["personalized_model_name"]
             filename = f"{model_name}_{self.client_id}_{config['run_id']}.acc"
             self.save_accuracy(accuracy, filename)
             return None
-        return accuracy
 
     def personalized_train_process(self, config, trainset, sampler, **kwargs):
         """The main training loop in a federated learning workload, run in
           a separate process with a new CUDA context, so that CUDA memory
           can be released after the training completes.
 
         Arguments:
@@ -565,15 +582,18 @@
         kwargs (optional): Additional keyword arguments.
         """
 
         try:
             self.personalized_train_model(config, trainset, sampler.get(), **kwargs)
         except Exception as training_exception:
             logging.info(
-                "Personalization Training on client #%d failed.", self.client_id
+                fonts.colourize(
+                    "Personalization Training on client #%d failed.", colour="blue"
+                ),
+                self.client_id,
             )
             raise training_exception
 
         if "max_concurrency" in config:
             self.personalized_model.cpu()
             model_type = config["personalized_model_name"]
             filename = f"{model_type}_{self.client_id}_{config['run_id']}.pth"
@@ -646,15 +666,15 @@
         """Method called at the start of training run.
 
         By default, we initial personalized model and its performance is recorded.
         """
         current_round = self.current_round
         data_loader = kwargs["data_loader"]
 
-        eval_outputs = self.perform_evaluation_op(
+        eval_outputs = self.perform_evaluation(
             data_loader, defined_model=self.personalized_model
         )
 
         # save the personaliation accuracy to the results dir
         self.checkpoint_personalized_accuracy(
             accuracy=eval_outputs["accuracy"],
             current_round=current_round,
@@ -665,49 +685,59 @@
         return eval_outputs
 
     def personalized_train_run_end(self, config):
         """Method called at the end of a training run."""
 
     def personalized_train_epoch_start(self, config):
         """Method called at the beginning of a personalized training epoch."""
+        self.personalized_model.train()
 
     def personalized_train_epoch_end(
         self,
         epoch,
         config,
         **kwargs,
     ):
         """The customize behavior after performing one epoch of personalized training.
 
         By default, we need to save the encoded data, the accuracy, and the model when possible.
         """
         data_loader = kwargs["data_loader"]
         loss = kwargs["loss"]
-        pers_epochs = config["personalized_epochs"]
+        personalized_epochs = config["personalized_epochs"]
 
         current_round = self.current_round
-        epoch_log_interval = pers_epochs + 1
+        epoch_log_interval = personalized_epochs + 1
 
         eval_outputs = {}
         if "personalized_epoch_log_interval" in config:
             epoch_log_interval = config["personalized_epoch_log_interval"]
 
-        if epoch == 1 or epoch % epoch_log_interval == 0 or epoch == pers_epochs:
+        if (
+            epoch == 1
+            or epoch % epoch_log_interval == 0
+            or epoch == personalized_epochs
+        ):
             logging.info(
                 "[Client #%d] Personalization Training Epoch: [%d/%d]\tLoss: %.6f",
                 self.client_id,
                 epoch,
-                pers_epochs,
+                personalized_epochs,
                 loss,
             )
 
-            eval_outputs = self.perform_evaluation_op(
-                data_loader, self.personalized_model
-            )
+            eval_outputs = self.perform_evaluation(data_loader, self.personalized_model)
             accuracy = eval_outputs["accuracy"]
 
             # save the personaliation accuracy to the results dir
             self.checkpoint_personalized_accuracy(
                 accuracy=accuracy, current_round=current_round, epoch=epoch, run_id=None
             )
 
         return eval_outputs
+
+    @staticmethod
+    def process_personalized_outputs(outputs):
+        """
+        Method called after the model updates have been generated.
+        """
+        return outputs
```

## plato/utils/checkpoint_operator.py

```diff
@@ -3,15 +3,15 @@
 """
 import os
 import re
 from typing import Dict, Optional, List
 
 import torch
 
-from plato.utils.filename_formatter import get_format_name
+from plato.utils.filename_formatter import NameFormatter
 
 
 class CheckpointsOperator:
     """The operations for checkpoints, including pretrained models and checkpoints models.
 
     This class is called CheckpointsOperator, as the pre-trained models can also
     be regarded as one type of checkpoint.
@@ -140,15 +140,15 @@
     client_id: int,
     model_name: str,
     checkpoints_dir: str,
     model_state_dict: Dict[str, torch.Tensor],
     optimizer_state_dict: Optional[dict] = None,
     lr_scheduler_state_dict: Optional[dict] = None,
     learning_dict: Optional[dict] = None,
-    config: dict = {},
+    config: Optional[dict] = None,
     global_epoch: Optional[int] = None,
     local_epoch: Optional[int] = None,
     prefix: Optional[str] = None,
 ) -> str:
     # pylint:disable=too-many-arguments
 
     """Save the checkpoint for sepcific client.
@@ -167,25 +167,26 @@
         include "loss" for example. Default to be None for not saving.
     :param global_epoch: A integer to present the client id.
     :param global_epoch: A integer to present global epoch.
     :param local_epoch: A integer to present local epoch within the client.
     :param prefix: A integer to present the client id.
 
     """
+    config = config if config is not None else {}
     current_round = config["current_round"] if "current_round" in config else None
     # run_id = config['run_id']
     # we have to set the run_id to be None here as the client can
     # have different run id in the whole training process.
     run_id = None
 
     cpk_oper = CheckpointsOperator(checkpoints_dir=checkpoints_dir)
 
     # Before the training, we expect to save the initial
     # model of this round
-    filename = get_format_name(
+    filename = NameFormatter.get_format_name(
         model_name=model_name,
         client_id=client_id,
         round_n=current_round,
         epoch_n=local_epoch,
         run_id=run_id,
         prefix=prefix,
         ext="pth",
@@ -225,15 +226,15 @@
     if mask_words is None:
         mask_words = ["epoch"]
 
     cpk_oper = CheckpointsOperator(checkpoints_dir=checkpoints_dir)
 
     # Before the training, we expect to save the initial
     # model of this round
-    filename = get_format_name(
+    filename = NameFormatter.get_format_name(
         model_name=model_name,
         client_id=client_id,
         round_n=current_round,
         epoch_n=epoch,
         run_id=run_id,
         prefix=prefix,
         ext="pth",
```

## plato/utils/filename_formatter.py

```diff
@@ -2,49 +2,59 @@
 Implementation of arranging filenames for saving and loading.
 
 This is to make sure that the saving file share the same name logic.
 
 """
 from typing import Optional
 
-# pylint:disable=too-many-arguments
-def get_format_name(
-    client_id: int,
-    model_name: Optional[str] = None,
-    round_n: Optional[int] = None,
-    epoch_n: Optional[int] = None,
-    run_id: Optional[str] = None,
-    prefix: Optional[str] = None,
-    suffix: Optional[str] = None,
-    ext: str = "pth",
-):
-    """Arrange the save file name for all saving part of client.
-
-    The desired filename will be:
-
-    {prefix}_{model_name}_client{client_id}_round{round_n}\
-        _epoch{epoch_n}_runid{run_id}_{suffix}.{ext}
-
-    The 'client_id' and 'ext' are two mandatory parts.
-    """
-    file_name = ""
-
-    if prefix is not None:
-        file_name = file_name + f"{prefix}_"
-
-    if model_name is not None:
-        file_name = file_name + f"{model_name}__"
-
-    file_name = file_name + f"client{client_id}"
-
-    if round_n is not None:
-        file_name = file_name + f"_round{round_n}"
-    if epoch_n is not None:
-        file_name = file_name + f"_epoch{epoch_n}"
-    if run_id is not None:
-        file_name = file_name + f"_runid{run_id}"
 
-    if suffix is not None:
-        file_name = file_name + f"_{suffix}"
+class NameFormatter:
+    """The Formatter to force a consistent naming style."""
 
-    file_name = file_name + "." + ext
-    return file_name
+    # pylint:disable=too-many-arguments
+    @staticmethod
+    def get_format_name(
+        client_id: int,
+        model_name: Optional[str] = None,
+        round_n: Optional[int] = None,
+        epoch_n: Optional[int] = None,
+        run_id: Optional[str] = None,
+        prefix: Optional[str] = None,
+        suffix: Optional[str] = None,
+        ext: str = "pth",
+    ):
+        """Arrange the name for all saving/loading part of Plato.
+
+        The desired name format will be:
+
+        {prefix}_{model_name}__client{client_id}_round{round_n}\
+            _epoch{epoch_n}_runid{run_id}_{suffix}.{ext}
+
+        The 'client_id' and 'ext' are two mandatory parts.
+        """
+        full_name = ""
+        name_head = ""
+        if prefix is not None:
+            name_head = name_head + f"{prefix}_"
+
+        if model_name is not None:
+            name_head = name_head + f"{model_name}__"
+
+        full_name = name_head + f"client{client_id}"
+
+        if round_n is not None:
+            full_name = full_name + f"_round{round_n}"
+        if epoch_n is not None:
+            full_name = full_name + f"_epoch{epoch_n}"
+        if run_id is not None:
+            full_name = full_name + f"_runid{run_id}"
+
+        if suffix is not None:
+            full_name = full_name + f"_{suffix}"
+
+        full_name = full_name + "." + ext
+        return full_name
+
+    @staticmethod
+    def extract_name_head(formatted_name):
+        """Extract the head of the formatted name."""
+        return formatted_name.split("__")[0]
```

## Comparing `plato_learn-0.4.8.dist-info/LICENSE` & `plato_learn-0.4.9.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `plato_learn-0.4.8.dist-info/METADATA` & `plato_learn-0.4.9.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: plato-learn
-Version: 0.4.8
+Version: 0.4.9
 Summary: Packaged version of the Plato framework for federated learning research
 Home-page: https://github.com/TL-System/plato
 Author: 
 License: Apache-2.0
 Keywords: machine-learning,deep-learning,edge-learning,federated-learning
 Platform: UNKNOWN
 Classifier: Development Status :: 3 - Alpha
```

## Comparing `plato_learn-0.4.8.dist-info/RECORD` & `plato_learn-0.4.9.dist-info/RECORD`

 * *Files 2% similar despite different names*

```diff
@@ -1,29 +1,29 @@
-plato/__init__.py,sha256=40-PUZPRIakJU2yYWQcwTYvSJA6iewqiG8XylhxuAQk,22
+plato/__init__.py,sha256=LdxLMJM_JXsCQBeSvnxCNyGWmINE0yWfna3DQaT41Vs,22
 plato/client.py,sha256=X9UM2lv6LVqTtgtTf-bsbXmkKL1MxGsIvpZyk4L4YKA,1957
 plato/config.py,sha256=cqkFR0Tey5vuoIEYFPVZt_y9bzsvhwY73n2qCqEMcXE,13592
 plato/algorithms/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 plato/algorithms/base.py,sha256=hT5JXBKRHM-Mm0KaVZEZ1hQ7nQSrwElax2YKs72zmYw,1102
 plato/algorithms/fedavg.py,sha256=bdq-EJfA6RWu6zJ5B2jOwsGZ8mo_tf4NOIWfCOXQ0J8,1576
 plato/algorithms/fedavg_gan.py,sha256=-QFc1ZbCsQYH6NsLFREjyCHO16cH08OUpYXHyJiJtO4,2867
-plato/algorithms/fedavg_partial.py,sha256=hHVSE-ZeEGZZZVegEvx16J11vfyjFOL30-FHItjBJNg,5558
+plato/algorithms/fedavg_partial.py,sha256=lDEIvny_b_tAxUAS28KXbfNw--rZjsWcQddEgf12tuM,5334
 plato/algorithms/mistnet.py,sha256=FqHQxYsJ3SYscBCmNog5ETotzj9r5b_bvTLaTeZYNHg,1476
 plato/algorithms/registry.py,sha256=Szn2GRgGGf2YQmHjZd-fWPCVasWjKdIMG-tzc4u4Cxs,1445
 plato/callbacks/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 plato/callbacks/client.py,sha256=_g3EysmWqMSDp0WytgYd7VAKBR-DLGl2XioKKKsYxFg,1654
 plato/callbacks/handler.py,sha256=-oG_znqN2MPG3ySwQow9Yh-7k03tiv9CdDm8ktGiN7s,2639
 plato/callbacks/server.py,sha256=aV5UASjEyK4z34SpMnthVZyeqMRVylAPU3GO1LYPqjg,4244
 plato/callbacks/trainer.py,sha256=VlM2ts1d4WcWv01nBqs5K7tbUwHHLkTmQXZGPn_EV3I,3804
 plato/clients/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 plato/clients/base.py,sha256=xXWy8rvn-QHbX4lKMq7C1IEdYK6TQw3tBVkam5BOY3U,16728
 plato/clients/edge.py,sha256=vS9eSy4ta4lnMibBbLIn-Ntlcqx1-wSaqgnk69XPk0o,3455
 plato/clients/mistnet.py,sha256=-Sn26WeKPqZy1hCPx4d5IDji06PLHi8bYOpMOWRci8I,1491
 plato/clients/registry.py,sha256=WNUocwgqu0AlvgOxDKAv7yAldid7eXIu8UlFQ7OGKMU,1067
 plato/clients/simple.py,sha256=L51DX53h_rK_mFpQNHwse3nUYK5ozNBUWSehkQlfxK8,8173
-plato/clients/simple_personalized.py,sha256=YDvKuvHmVBRwI6nkTt_VLT9oGcgxfO9k9Sfecumk1-E,13477
+plato/clients/simple_personalized.py,sha256=NOe-ufhZg_tgoyAzX6CaugrXuRmTtHhJvcDeQFiv1dc,13650
 plato/datasources/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 plato/datasources/base.py,sha256=KciXvjkCTokN8ENNOEcwcsYSyo7hJ84SVxhrEkjA4fs,4090
 plato/datasources/celeba.py,sha256=rbfxClR_zk6k-tgXm1E1vwhOCxqA5YXvmABbrAX_bWA,4563
 plato/datasources/cifar10.py,sha256=4rZ_SfBczOnhjLT888Z5INaiI8ylFiu7LuDoedfLZmU,1716
 plato/datasources/cifar100.py,sha256=e-ycH_OUaRzBzvxstxEYLT3r8gFBWygcpGi-c1b-sQI,1720
 plato/datasources/cinic10.py,sha256=jHE2G0PhVzB0oiUAwx46MgrDGPJ_YSx15GI21PrC1Xs,1723
 plato/datasources/coco.py,sha256=2fVIlWnLQewg18ADqXFXuKhOpKMviCinpf6W9EfQ7ww,4507
@@ -38,15 +38,16 @@
 plato/datasources/kinetics.py,sha256=azqWXICnWMqNj5vVaa7LSoqsQy5k3dbrCuziLIhUPoM,23377
 plato/datasources/mnist.py,sha256=vfPe254C-hBbEzSMad0CClo4NBX46sVYdmouysspEoU,1032
 plato/datasources/multimodal_base.py,sha256=zmg62qVoEglScrqJhtDzmcGXVdKiUjezNP8xjUHt5Ns,13106
 plato/datasources/pascal_voc.py,sha256=WaXuOmbp9a3wtUA67q2u9hqW9n-fFgUgzaljtR978Wo,1482
 plato/datasources/purchase.py,sha256=47mNLgVINPtPoNzQXTiY8NnmQWzdrYR7KgE4rPV5VUs,3022
 plato/datasources/qoenflx.py,sha256=cMlucoePd0qmJOVKcT9Nuu2x3EMndD4_XyHFAgsmcXs,4224
 plato/datasources/referitgame.py,sha256=6dEUBQ8H56ArozCjaQJkpTjpgGM8DcgUrEVQhJkJV2s,11322
-plato/datasources/registry.py,sha256=fanXg7LKwyab7qOJNU0MKn6MXPL_nAKp-xpE1r-01Ao,3720
+plato/datasources/registry.py,sha256=feIFr3wyR1HXe2A8yvy_o5VWefynrMPKdEjMPHtlxqg,3757
+plato/datasources/stl10.py,sha256=CU2j4SDBSeBTtqG-ydZsbzytbJF4_9dHm4YqsVZNnUU,3032
 plato/datasources/texas.py,sha256=CaiwL2_f8YpSTRKJKGKxL4gBaKBtbh2mTw-dVEsyhFQ,3189
 plato/datasources/tiny_imagenet.py,sha256=P56GVCKzkqfFy3oNmb6gx5HNsSftLazoYBGdywMh4Ns,1943
 plato/datasources/yolo.py,sha256=o2zFNs1HKgfI61TlFrUG7W1XD0qVE7tBr02I87h_3bY,5189
 plato/datasources/datalib/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 plato/datasources/datalib/audio_extraction_tools.py,sha256=RLosUR0H5bnPDfluJb5b3Si7FRVbNmts-4fBD_79goU,4718
 plato/datasources/datalib/data_utils.py,sha256=N8nl7wgTpDZqrPEgerDZZo4t3hXcTnz445XuZdwAMfE,3816
 plato/datasources/datalib/flickr30kE_utils.py,sha256=vlnd8tdRDslCmIvoVgw09g_2BhcDDwjk_fpUJlk66bQ,12779
@@ -60,15 +61,15 @@
 plato/datasources/datalib/gym_utils/gym_trim.py,sha256=aEyGSIn9hOiRbdwwHmyI4SkfaCpUXVAud3wdkoqn7Q4,6056
 plato/datasources/datalib/refer_utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 plato/datasources/datalib/refer_utils/referitgame_utils.py,sha256=C89asVB6XH9iQnSxhoUwtrJWhQSifmwjP6g553eCSGc,9358
 plato/models/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 plato/models/cnn_encoder.py,sha256=Wbes3LcdRYSA86Mx6ybogWEEgXn-_whH7qm3dkUnW4M,3528
 plato/models/dcgan.py,sha256=DCg10M_yh6JYNEtyBgFKUMy17OKn9X9VWUPEEJHCH0g,3396
 plato/models/general_multilayer.py,sha256=jBX5-X8dW-S7uPm_MY0ToIgWUh17uILnpA6AKu7xCN8,9498
-plato/models/huggingface.py,sha256=cj9B7SSSg1hQbTJS9tilgnFYqeWC5eN3sFgHHRbxt90,750
+plato/models/huggingface.py,sha256=FciV4qoUs3k8QoKv2jSNuk_OVHe_LvmH2Yn6QgchWdA,749
 plato/models/lenet5.py,sha256=eISsdolMK_lSEBYY3OjEjNZJXBcg0O0Hjc4UgmfM2kg,3644
 plato/models/multilayer.py,sha256=Sa_1c4PHNa9L7hs1TNuzjxipLUa1VpKudk7LyDgo_84,2552
 plato/models/registry.py,sha256=uijOIoPVQExIlV8ebzbW3LVnCjg5VnSNANRJE1PzLT0,2497
 plato/models/resnet.py,sha256=VklzvT1LurI40W5AgJjx3Aey_3mT3D3nrv1otsrbjZ8,6442
 plato/models/torch_hub.py,sha256=-3D1gqpKFvBvg_kmhyzHVDQCNpvSltpiMrB53m6Sg8w,445
 plato/models/vgg.py,sha256=Rfkx8yiNIIriaBU9OcK_wQZNtgCJUvqdqzfAU_Jby10,2981
 plato/models/vit.py,sha256=rbhknRdiADM2EpSzBdD_jrXLIId2MGkCM1M_0kvDqXM,5151
@@ -109,57 +110,57 @@
 plato/processors/send_mask.py,sha256=vOx9V-LdDmvI9FerHVOX4Shc7NZuQ7PNXrNvTy5YuHI,1534
 plato/processors/structured_pruning.py,sha256=6idN0ItDzSh5wd059KuOWP482qj4bbHQBLi3CuOofxI,2066
 plato/processors/unstructured_pruning.py,sha256=rQwpER3lAQ8P0zyqpA93LW2oahVqOX7AVBXi7J8L520,1928
 plato/samplers/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 plato/samplers/all_inclusive.py,sha256=jb1NQWeZxvvW7bT91qwC9-bA8tY7p2X2WAJFBoQYVJE,1540
 plato/samplers/base.py,sha256=di1IK_Ch6x9MxyWosFpF2-eBGKSdS9nbkhthg4IuhsU,906
 plato/samplers/dirichlet.py,sha256=VE1p_iRXeVGFI0cH_v2HKkKxmWOzbFoiNYiZnTAfcW8,2703
-plato/samplers/distribution_noniid.py,sha256=PK-EiYdNk_tPKeCkN_J2mTWMpwW-DvTCmzXqCXDEvxw,5184
+plato/samplers/distribution_noniid.py,sha256=gvw31E5MSTK0vLSq98JRkQj0WbUA7wln2pwSp8SHtH8,5188
 plato/samplers/iid.py,sha256=nIc-wCetVPYIL-b57blZV8-L7fRLzppLNaaKYcuxuIg,1738
 plato/samplers/label_quantity_noniid.py,sha256=2ES8YoLPyEOoojmXLbWwiGA8J0t6a8IB2PcQR473pEg,4613
-plato/samplers/mixed.py,sha256=uqB3XYgrR1ltryzSlZ73lGn9tTqLyX79TV8oLqxHGVA,1599
+plato/samplers/mixed.py,sha256=s_nNnr4D_eIuGAw1Xb9SnwurKGGH5IbUzrR1wBTZHcc,1722
 plato/samplers/mixed_label_quantity_noniid.py,sha256=Qyc3TMx0zHIUrSJ7fZYCF0ZY8GSWwVxXqHVsTBDz2ZE,5276
 plato/samplers/modality_iid.py,sha256=Z9EA4wTabVJQWgDZMjRn17GbaoSFO7H35Id0Uuf1KOU,1246
 plato/samplers/modality_quantity_noniid.py,sha256=lIRFZJZx9SlGrsGg9AcHYiliuG5cR2w3LJ1TFC8LCOY,1715
 plato/samplers/orthogonal.py,sha256=3wUZkO7Ie8QuhnE8nEaszBP_8nYspryStBWfnHBnzCU,3461
 plato/samplers/registry.py,sha256=g4SyNFdfidFstZIThSZk1xJny9uMNpaVBQf34nxZXNs,2631
 plato/samplers/sample_quantity_noniid.py,sha256=ZuErJNBZk28P6ifb8v-jwecjfpZlpLtfut6l7gCwU-M,4124
 plato/samplers/sampler_utils.py,sha256=PIek0HG43XOpgjjVe4lvDBJAu7kQbGs1YBr6h7DykF0,7650
 plato/servers/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-plato/servers/base.py,sha256=LOaQ3ccNP-BHcGvgLFkGR4UUA957vRa8K11yuvYywhk,56762
+plato/servers/base.py,sha256=hg2XcaHt8D1CQ02VZMlqdU5aONAOnPtLrx103mMDNVE,56772
 plato/servers/fedavg.py,sha256=7SLi8-ZIUMr7P0enD-Zz2sAOd-y_0F8FQ5laBib7DiM,10236
 plato/servers/fedavg_cs.py,sha256=5G--ZXWs7MqTT6OKzjBq2-UecbhXkSgiJg8frHyvNw4,13169
 plato/servers/fedavg_gan.py,sha256=G_cYDXFoJSXpOSOwVt4SxPU6wY-er-LqtdbkC2_T5JU,2691
 plato/servers/fedavg_he.py,sha256=ygUd6AA7xsmdfpgKq3iicBdqWER3h2rzTcQeSLy5mRg,3952
-plato/servers/fedavg_personalized.py,sha256=tADGPiY82bhYRqAaKOXnXBOhDrfJi8idEH_0R3_n_Sg,16998
+plato/servers/fedavg_personalized.py,sha256=Q-tWMOKhauZtGlkX51sjXhIBDmO-N0CoxoWktQvrG7A,16301
 plato/servers/mistnet.py,sha256=O6QTEQm4kIg7na1iK2qTgSn91CIs_HLCv-X2OkjzYoo,2279
 plato/servers/registry.py,sha256=Vo0mXQ4zjhIVhru-TQl0xxfZXSK0xthrvSOS23uQkrQ,1386
 plato/trainers/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 plato/trainers/base.py,sha256=XUQ7qClPbZBJQp4XD4cgndBrh4rOySf9D6-VWgiIK2k,3128
 plato/trainers/basic.py,sha256=sTNGsvxiU-Cm70yBwQYELfrJWDWIIT297na7mvYMLtQ,22736
-plato/trainers/basic_personalized.py,sha256=ce31jjkXJyDZbtMexgzM7cr9mUKTgyK57b7yMFTZGzo,25810
+plato/trainers/basic_personalized.py,sha256=3rXUruwLfrbaOSrrKnNOmE7ifingBfs5oC16UjQ8uW0,26725
 plato/trainers/diff_privacy.py,sha256=71e4eL0YWICB5p9kO2bfzl4nUMJjHjvePloBwz4RHSs,6789
 plato/trainers/gan.py,sha256=Q99suY8JWI-XMJpTMjBW30IUypyNmfmQvOmgaJBk_p8,12763
 plato/trainers/huggingface.py,sha256=Y1k899CCDb7oxmMnAZTlWbv_Fij9coilSouhzFyS4L8,4901
 plato/trainers/loss_criterion.py,sha256=3IdPrC-5xKBtiVL0i-B5o3q8ph7vo-EeRcU5M_obYxA,1463
 plato/trainers/lr_schedulers.py,sha256=ct6UmLalkegO6zTJCN0nBF7z94ncZ1GuD0N_sPwGRdY,8685
 plato/trainers/optimizers.py,sha256=nCOSE0x3D0568IM2f043fD8eT2oeM9B3r4nG3OxuoXM,1329
 plato/trainers/pascal_voc.py,sha256=H2jtnWkNXRL1Ekpo3Anda7MEPpWnyIgAjj-w3jBoOjM,2705
 plato/trainers/registry.py,sha256=NolrwCpph450NFvKEuebDKZCdDRrNnzQBBC9BZYbK04,1640
 plato/trainers/tracking.py,sha256=686uIQnY7UMXzQ-wSFEwSFl17c0szdv0vsh7bPkq7L0,2828
 plato/trainers/yolov5.py,sha256=lgdy97asSHyqkVg8xbmqOa5QxbYm8vPNuKWhDDIYrpU,16487
 plato/trainers/mindspore/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 plato/trainers/mindspore/basic.py,sha256=-ZsveN9mh02WcxLFgK_lAT4u9LWAA3XmT5ZDxlOSSPc,4481
 plato/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-plato/utils/checkpoint_operator.py,sha256=89aaVOYJAn5uNEKIqGWBfN0or_qWgFufgZnkY6DNVuA,9238
+plato/utils/checkpoint_operator.py,sha256=ZkcUmmmwfgUCMBuWWaoW_OD-IB2ibagBr_xShX5zlzw,9326
 plato/utils/count_parameters.py,sha256=8mJ6tPpkLPqZEm-Ye25nsvo01lkF0Cq_kBT88uaeysE,879
 plato/utils/csv_processor.py,sha256=yquJug5i6JboLSdb1JuPZliTw7M6G1GX76yrmMmmWqA,843
 plato/utils/data_loaders.py,sha256=lzuC9EGSm9B-MCOdmWfEBLkMyTLARqqGbgv8D5XCdCU,5300
 plato/utils/decorators.py,sha256=6k6VoS0zxn49ohwCZXS_gvgIITpW5clv-ApFP_j1TKY,590
-plato/utils/filename_formatter.py,sha256=jFWGFD0bNzn6A7cxpZibVDOM9QKagvKvMLigs43AeUQ,1353
+plato/utils/filename_formatter.py,sha256=583IwXCUDOn9kz_PUNUd_CsJq1d0q6WycHZjBsu0wzw,1770
 plato/utils/fonts.py,sha256=FRrKudb6t1NC70YIdJwnlDoLCw2UX8vyu8SawHmKkoQ,716
 plato/utils/homo_enc.py,sha256=fE2sMU9_6umlvk3rJpjKwnIbKCjGIPEpiOKE5AEkyrI,5873
 plato/utils/rl_env.py,sha256=GYWjjnzujHe52q6zlQSV2kOf83eQyUB5DUx_agvDfy0,5173
 plato/utils/s3.py,sha256=cg_u0WyzhAtzzcEBabEDnnDX5RY71t5TjjjfGLZgi1Y,5550
 plato/utils/unary_encoding.py,sha256=WayDatnPKSUPuJTPO_E__abuQQ7PYa0XgjO8RFG8KkI,1355
 plato/utils/visual_augmentations.py,sha256=5p7SL8XwlnxGlEGAixPruU8y9iM40q6TtV_c_L2-KZ4,12179
 plato/utils/lib_mia/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
@@ -171,12 +172,12 @@
 plato/utils/reinforcement_learning/rl_server.py,sha256=u57yb5jeYVx89cJhV0jEKig3YiTLckCFXQBqisJsi84,3305
 plato/utils/reinforcement_learning/policies/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 plato/utils/reinforcement_learning/policies/base.py,sha256=RSxOe_blx3FnGlQzeFlcAWTVpEWNe34FB_GE6Kv-jmo,5250
 plato/utils/reinforcement_learning/policies/ddpg.py,sha256=MtBsC9gCHiPyrjsU1GDYSsoWHxOLJrVzz36_abOzpZQ,2816
 plato/utils/reinforcement_learning/policies/registry.py,sha256=ecPJRoTIueqGMazShHwXAVJLl9wF2ux6_prL_tR3fhc,918
 plato/utils/reinforcement_learning/policies/sac.py,sha256=XFY5LG1ZZNm6mqaqPrs1EAVNkxgBTMx9YFoo29TgWIY,12031
 plato/utils/reinforcement_learning/policies/td3.py,sha256=NPTMVoXR_aRMVudtd3p47-lriyl0rCs5nQju7cgHyIA,19055
-plato_learn-0.4.8.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
-plato_learn-0.4.8.dist-info/METADATA,sha256=kdQNydTHnKKdDe_CKugTaZYkVo5c4apd8afGOVMs__c,1544
-plato_learn-0.4.8.dist-info/WHEEL,sha256=qsnO3NTfeeJD415SFmgiXHOXV3NPC2x38tNwuaxrYy0,150
-plato_learn-0.4.8.dist-info/top_level.txt,sha256=UQK56B7rROCq2KiENCKB_DrD2Rc6jKfGiMOlWpL_zUc,6
-plato_learn-0.4.8.dist-info/RECORD,,
+plato_learn-0.4.9.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
+plato_learn-0.4.9.dist-info/METADATA,sha256=snxkXjEdMBBRiYe0eO9srkWPv435rof4OttTrejJfhE,1544
+plato_learn-0.4.9.dist-info/WHEEL,sha256=qsnO3NTfeeJD415SFmgiXHOXV3NPC2x38tNwuaxrYy0,150
+plato_learn-0.4.9.dist-info/top_level.txt,sha256=UQK56B7rROCq2KiENCKB_DrD2Rc6jKfGiMOlWpL_zUc,6
+plato_learn-0.4.9.dist-info/RECORD,,
```

